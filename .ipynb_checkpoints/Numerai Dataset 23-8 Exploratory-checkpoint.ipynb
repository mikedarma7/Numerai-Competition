{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from datetime import datetime\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n0003aa52cab36c2</td>\n",
       "      <td>0.48919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n000920ed083903f</td>\n",
       "      <td>0.49109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  prediction\n",
       "0  n0003aa52cab36c2     0.48919\n",
       "1  n000920ed083903f     0.49109"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_pred =  pd.read_csv('example_predictions.csv')\n",
    "s_pred.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             object\n",
       "prediction    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_pred.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1795583, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1795578</th>\n",
       "      <td>nffc033d31ab0d5b</td>\n",
       "      <td>0.51256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795579</th>\n",
       "      <td>nffd58a23ab39438</td>\n",
       "      <td>0.50117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795580</th>\n",
       "      <td>nffd7dba3b5aaddf</td>\n",
       "      <td>0.52394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795581</th>\n",
       "      <td>nffeecece19a627d</td>\n",
       "      <td>0.50393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795582</th>\n",
       "      <td>nfff8bdb0c6c3263</td>\n",
       "      <td>0.51282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  prediction\n",
       "1795578  nffc033d31ab0d5b     0.51256\n",
       "1795579  nffd58a23ab39438     0.50117\n",
       "1795580  nffd7dba3b5aaddf     0.52394\n",
       "1795581  nffeecece19a627d     0.50393\n",
       "1795582  nfff8bdb0c6c3263     0.51282"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_pred.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_function(x):\n",
    "    if x < 0.125:\n",
    "        return 0\n",
    "    elif 0.125<=x<0.375:\n",
    "        return 0.25\n",
    "    elif 0.375<=x<0.625:\n",
    "        return 0.5\n",
    "    elif 0.625<=x<0.875:\n",
    "        return 0.75\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n0003aa52cab36c2</td>\n",
       "      <td>0.48919</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n000920ed083903f</td>\n",
       "      <td>0.49109</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n0038e640522c4a6</td>\n",
       "      <td>0.53275</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n004ac94a87dc54b</td>\n",
       "      <td>0.50717</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n0052fe97ea0c05f</td>\n",
       "      <td>0.50383</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  prediction  target\n",
       "0  n0003aa52cab36c2     0.48919     0.5\n",
       "1  n000920ed083903f     0.49109     0.5\n",
       "2  n0038e640522c4a6     0.53275     0.5\n",
       "3  n004ac94a87dc54b     0.50717     0.5\n",
       "4  n0052fe97ea0c05f     0.50383     0.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_pred['target'] = s_pred.prediction.apply(bin_function)\n",
    "s_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5    1795583\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_pred.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('numerai_tournament_data.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>era</th>\n",
       "      <th>data_type</th>\n",
       "      <th>feature_intelligence1</th>\n",
       "      <th>feature_intelligence2</th>\n",
       "      <th>feature_intelligence3</th>\n",
       "      <th>feature_intelligence4</th>\n",
       "      <th>feature_intelligence5</th>\n",
       "      <th>feature_intelligence6</th>\n",
       "      <th>feature_intelligence7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_wisdom38</th>\n",
       "      <th>feature_wisdom39</th>\n",
       "      <th>feature_wisdom40</th>\n",
       "      <th>feature_wisdom41</th>\n",
       "      <th>feature_wisdom42</th>\n",
       "      <th>feature_wisdom43</th>\n",
       "      <th>feature_wisdom44</th>\n",
       "      <th>feature_wisdom45</th>\n",
       "      <th>feature_wisdom46</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n000315175b67977</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n0014af834a96cdd</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n001c93979ac41d4</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n0034e4143f22a13</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n00679d1a636062f</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id   era data_type  feature_intelligence1  \\\n",
       "0  n000315175b67977  era1     train                   0.00   \n",
       "1  n0014af834a96cdd  era1     train                   0.00   \n",
       "2  n001c93979ac41d4  era1     train                   0.25   \n",
       "3  n0034e4143f22a13  era1     train                   1.00   \n",
       "4  n00679d1a636062f  era1     train                   0.25   \n",
       "\n",
       "   feature_intelligence2  feature_intelligence3  feature_intelligence4  \\\n",
       "0                   0.50                   0.25                   0.00   \n",
       "1                   0.00                   0.00                   0.25   \n",
       "2                   0.50                   0.25                   0.25   \n",
       "3                   0.00                   0.00                   0.50   \n",
       "4                   0.25                   0.25                   0.25   \n",
       "\n",
       "   feature_intelligence5  feature_intelligence6  feature_intelligence7  ...  \\\n",
       "0                    0.5                   0.25                   0.25  ...   \n",
       "1                    0.5                   0.00                   0.00  ...   \n",
       "2                    1.0                   0.75                   0.75  ...   \n",
       "3                    0.5                   0.25                   0.25  ...   \n",
       "4                    0.0                   0.25                   0.50  ...   \n",
       "\n",
       "   feature_wisdom38  feature_wisdom39  feature_wisdom40  feature_wisdom41  \\\n",
       "0              1.00              1.00              0.75              0.50   \n",
       "1              1.00              1.00              0.00              0.00   \n",
       "2              0.25              0.50              0.00              0.00   \n",
       "3              1.00              1.00              0.75              0.75   \n",
       "4              0.75              0.75              0.25              0.50   \n",
       "\n",
       "   feature_wisdom42  feature_wisdom43  feature_wisdom44  feature_wisdom45  \\\n",
       "0              0.75              0.50              1.00              0.50   \n",
       "1              0.75              0.25              0.00              0.25   \n",
       "2              0.50              1.00              0.00              0.25   \n",
       "3              1.00              1.00              0.75              1.00   \n",
       "4              0.75              0.00              0.50              0.25   \n",
       "\n",
       "   feature_wisdom46  target  \n",
       "0              0.75    0.50  \n",
       "1              1.00    0.25  \n",
       "2              0.75    0.25  \n",
       "3              1.00    0.25  \n",
       "4              0.75    0.75  \n",
       "\n",
       "[5 rows x 314 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data = pd.read_csv('numerai_training_data.csv')\n",
    "#train_data.to_parquet('train_data.gzip')\n",
    "\n",
    "train_data = pd.read_parquet('train_data.gzip')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_parquet('train_data.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        object\n",
       "era                       object\n",
       "data_type                 object\n",
       "feature_intelligence1    float64\n",
       "feature_intelligence2    float64\n",
       "                          ...   \n",
       "feature_wisdom43         float64\n",
       "feature_wisdom44         float64\n",
       "feature_wisdom45         float64\n",
       "feature_wisdom46         float64\n",
       "target                   float64\n",
       "Length: 314, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         n000315175b67977\n",
       "era                                    era1\n",
       "data_type                             train\n",
       "feature_intelligence1                     0\n",
       "feature_intelligence2                   0.5\n",
       "feature_intelligence3                  0.25\n",
       "feature_intelligence4                     0\n",
       "feature_intelligence5                   0.5\n",
       "feature_intelligence6                  0.25\n",
       "feature_intelligence7                  0.25\n",
       "feature_intelligence8                  0.25\n",
       "feature_intelligence9                  0.75\n",
       "feature_intelligence10                 0.75\n",
       "feature_intelligence11                 0.25\n",
       "feature_intelligence12                 0.25\n",
       "feature_charisma1                         1\n",
       "feature_charisma2                      0.75\n",
       "feature_charisma3                       0.5\n",
       "feature_charisma4                         1\n",
       "feature_charisma5                       0.5\n",
       "feature_charisma6                         0\n",
       "feature_charisma7                       0.5\n",
       "feature_charisma8                       0.5\n",
       "feature_charisma9                         0\n",
       "feature_charisma10                        0\n",
       "feature_charisma11                        0\n",
       "feature_charisma12                        1\n",
       "feature_charisma13                     0.25\n",
       "feature_charisma14                        0\n",
       "feature_charisma15                      0.5\n",
       "feature_charisma16                     0.25\n",
       "feature_charisma17                     0.75\n",
       "feature_charisma18                      0.5\n",
       "feature_charisma19                        1\n",
       "feature_charisma20                     0.75\n",
       "feature_charisma21                     0.75\n",
       "feature_charisma22                      0.5\n",
       "feature_charisma23                      0.5\n",
       "feature_charisma24                     0.75\n",
       "feature_charisma25                      0.5\n",
       "feature_charisma26                     0.25\n",
       "feature_charisma27                     0.75\n",
       "feature_charisma28                     0.75\n",
       "feature_charisma29                      0.5\n",
       "feature_charisma30                     0.25\n",
       "feature_charisma31                     0.25\n",
       "feature_charisma32                      0.5\n",
       "feature_charisma33                     0.25\n",
       "feature_charisma34                      0.5\n",
       "feature_charisma35                     0.25\n",
       "feature_charisma36                     0.75\n",
       "feature_charisma37                     0.25\n",
       "feature_charisma38                     0.25\n",
       "feature_charisma39                      0.5\n",
       "feature_charisma40                      0.5\n",
       "feature_charisma41                     0.75\n",
       "feature_charisma42                     0.25\n",
       "feature_charisma43                      0.5\n",
       "feature_charisma44                     0.25\n",
       "feature_charisma45                      0.5\n",
       "feature_charisma46                     0.25\n",
       "feature_charisma47                      0.5\n",
       "feature_charisma48                      0.5\n",
       "feature_charisma49                      0.5\n",
       "feature_charisma50                     0.25\n",
       "feature_charisma51                      0.5\n",
       "feature_charisma52                     0.25\n",
       "feature_charisma53                     0.75\n",
       "feature_charisma54                        0\n",
       "feature_charisma55                     0.25\n",
       "feature_charisma56                      0.5\n",
       "feature_charisma57                        0\n",
       "feature_charisma58                        0\n",
       "feature_charisma59                     0.75\n",
       "feature_charisma60                      0.5\n",
       "feature_charisma61                      0.5\n",
       "feature_charisma62                     0.25\n",
       "feature_charisma63                      0.5\n",
       "feature_charisma64                      0.5\n",
       "feature_charisma65                      0.5\n",
       "feature_charisma66                     0.25\n",
       "feature_charisma67                     0.25\n",
       "feature_charisma68                     0.25\n",
       "feature_charisma69                        0\n",
       "feature_charisma70                      0.5\n",
       "feature_charisma71                      0.5\n",
       "feature_charisma72                      0.5\n",
       "feature_charisma73                      0.5\n",
       "feature_charisma74                        0\n",
       "feature_charisma75                      0.5\n",
       "feature_charisma76                      0.5\n",
       "feature_charisma77                     0.75\n",
       "feature_charisma78                        0\n",
       "feature_charisma79                      0.5\n",
       "feature_charisma80                     0.75\n",
       "feature_charisma81                      0.5\n",
       "feature_charisma82                      0.5\n",
       "feature_charisma83                        0\n",
       "feature_charisma84                     0.75\n",
       "feature_charisma85                      0.5\n",
       "feature_charisma86                      0.5\n",
       "feature_strength1                         0\n",
       "feature_strength2                      0.75\n",
       "feature_strength3                         0\n",
       "feature_strength4                      0.25\n",
       "feature_strength5                      0.75\n",
       "feature_strength6                      0.25\n",
       "feature_strength7                       0.5\n",
       "feature_strength8                         1\n",
       "feature_strength9                      0.75\n",
       "feature_strength10                      0.5\n",
       "feature_strength11                        0\n",
       "feature_strength12                      0.5\n",
       "feature_strength13                     0.75\n",
       "feature_strength14                      0.5\n",
       "feature_strength15                        0\n",
       "feature_strength16                     0.75\n",
       "feature_strength17                      0.5\n",
       "feature_strength18                     0.75\n",
       "feature_strength19                        0\n",
       "feature_strength20                      0.5\n",
       "feature_strength21                        0\n",
       "feature_strength22                     0.75\n",
       "feature_strength23                     0.75\n",
       "feature_strength24                     0.25\n",
       "feature_strength25                      0.5\n",
       "feature_strength26                      0.5\n",
       "feature_strength27                        0\n",
       "feature_strength28                        1\n",
       "feature_strength29                     0.25\n",
       "feature_strength30                      0.5\n",
       "feature_strength31                     0.75\n",
       "feature_strength32                     0.75\n",
       "feature_strength33                      0.5\n",
       "feature_strength34                     0.75\n",
       "feature_strength35                      0.5\n",
       "feature_strength36                      0.5\n",
       "feature_strength37                      0.5\n",
       "feature_strength38                      0.5\n",
       "feature_dexterity1                     0.75\n",
       "feature_dexterity2                     0.75\n",
       "feature_dexterity3                      0.5\n",
       "feature_dexterity4                        1\n",
       "feature_dexterity5                     0.75\n",
       "feature_dexterity6                     0.75\n",
       "feature_dexterity7                        1\n",
       "feature_dexterity8                      0.5\n",
       "feature_dexterity9                     0.75\n",
       "feature_dexterity10                    0.75\n",
       "feature_dexterity11                    0.75\n",
       "feature_dexterity12                    0.25\n",
       "feature_dexterity13                    0.75\n",
       "feature_dexterity14                     0.5\n",
       "feature_constitution1                  0.25\n",
       "feature_constitution2                   0.5\n",
       "feature_constitution3                   0.5\n",
       "feature_constitution4                  0.75\n",
       "feature_constitution5                     0\n",
       "feature_constitution6                     0\n",
       "feature_constitution7                   0.5\n",
       "feature_constitution8                  0.75\n",
       "feature_constitution9                  0.25\n",
       "feature_constitution10                 0.25\n",
       "feature_constitution11                 0.75\n",
       "feature_constitution12                  0.5\n",
       "feature_constitution13                  0.5\n",
       "feature_constitution14                  0.5\n",
       "feature_constitution15                    0\n",
       "feature_constitution16                    1\n",
       "feature_constitution17                 0.75\n",
       "feature_constitution18                 0.25\n",
       "feature_constitution19                 0.75\n",
       "feature_constitution20                 0.25\n",
       "feature_constitution21                 0.75\n",
       "feature_constitution22                    0\n",
       "feature_constitution23                  0.5\n",
       "feature_constitution24                    0\n",
       "feature_constitution25                 0.25\n",
       "feature_constitution26                  0.5\n",
       "feature_constitution27                 0.25\n",
       "feature_constitution28                  0.5\n",
       "feature_constitution29                 0.25\n",
       "feature_constitution30                  0.5\n",
       "feature_constitution31                    1\n",
       "feature_constitution32                    0\n",
       "feature_constitution33                 0.25\n",
       "feature_constitution34                  0.5\n",
       "feature_constitution35                 0.75\n",
       "feature_constitution36                  0.5\n",
       "feature_constitution37                 0.25\n",
       "feature_constitution38                    0\n",
       "feature_constitution39                 0.25\n",
       "feature_constitution40                 0.75\n",
       "feature_constitution41                  0.5\n",
       "feature_constitution42                 0.25\n",
       "feature_constitution43                 0.25\n",
       "feature_constitution44                  0.5\n",
       "feature_constitution45                  0.5\n",
       "feature_constitution46                 0.75\n",
       "feature_constitution47                 0.75\n",
       "feature_constitution48                    0\n",
       "feature_constitution49                  0.5\n",
       "feature_constitution50                 0.25\n",
       "feature_constitution51                  0.5\n",
       "feature_constitution52                    0\n",
       "feature_constitution53                  0.5\n",
       "feature_constitution54                    1\n",
       "feature_constitution55                  0.5\n",
       "feature_constitution56                  0.5\n",
       "feature_constitution57                    0\n",
       "feature_constitution58                    1\n",
       "feature_constitution59                 0.25\n",
       "feature_constitution60                  0.5\n",
       "feature_constitution61                  0.5\n",
       "feature_constitution62                 0.25\n",
       "feature_constitution63                  0.5\n",
       "feature_constitution64                 0.75\n",
       "feature_constitution65                    0\n",
       "feature_constitution66                  0.5\n",
       "feature_constitution67                 0.25\n",
       "feature_constitution68                    1\n",
       "feature_constitution69                 0.25\n",
       "feature_constitution70                 0.75\n",
       "feature_constitution71                  0.5\n",
       "feature_constitution72                 0.25\n",
       "feature_constitution73                 0.25\n",
       "feature_constitution74                    0\n",
       "feature_constitution75                    0\n",
       "feature_constitution76                 0.75\n",
       "feature_constitution77                    0\n",
       "feature_constitution78                  0.5\n",
       "feature_constitution79                 0.25\n",
       "feature_constitution80                 0.25\n",
       "feature_constitution81                 0.25\n",
       "feature_constitution82                 0.25\n",
       "feature_constitution83                    1\n",
       "feature_constitution84                 0.25\n",
       "feature_constitution85                  0.5\n",
       "feature_constitution86                    0\n",
       "feature_constitution87                  0.5\n",
       "feature_constitution88                 0.75\n",
       "feature_constitution89                  0.5\n",
       "feature_constitution90                 0.75\n",
       "feature_constitution91                 0.25\n",
       "feature_constitution92                  0.5\n",
       "feature_constitution93                  0.5\n",
       "feature_constitution94                    0\n",
       "feature_constitution95                    1\n",
       "feature_constitution96                 0.25\n",
       "feature_constitution97                 0.25\n",
       "feature_constitution98                  0.5\n",
       "feature_constitution99                  0.5\n",
       "feature_constitution100                0.75\n",
       "feature_constitution101                 0.5\n",
       "feature_constitution102                 0.5\n",
       "feature_constitution103                0.25\n",
       "feature_constitution104                   1\n",
       "feature_constitution105                0.75\n",
       "feature_constitution106                0.25\n",
       "feature_constitution107                0.25\n",
       "feature_constitution108                 0.5\n",
       "feature_constitution109                 0.5\n",
       "feature_constitution110                0.25\n",
       "feature_constitution111                0.25\n",
       "feature_constitution112                 0.5\n",
       "feature_constitution113                 0.5\n",
       "feature_constitution114                0.25\n",
       "feature_wisdom1                        0.25\n",
       "feature_wisdom2                           1\n",
       "feature_wisdom3                        0.75\n",
       "feature_wisdom4                         0.5\n",
       "feature_wisdom5                        0.75\n",
       "feature_wisdom6                        0.75\n",
       "feature_wisdom7                        0.75\n",
       "feature_wisdom8                        0.75\n",
       "feature_wisdom9                        0.75\n",
       "feature_wisdom10                       0.75\n",
       "feature_wisdom11                        0.5\n",
       "feature_wisdom12                          1\n",
       "feature_wisdom13                          1\n",
       "feature_wisdom14                        0.5\n",
       "feature_wisdom15                       0.75\n",
       "feature_wisdom16                        0.5\n",
       "feature_wisdom17                       0.25\n",
       "feature_wisdom18                       0.25\n",
       "feature_wisdom19                       0.75\n",
       "feature_wisdom20                        0.5\n",
       "feature_wisdom21                          1\n",
       "feature_wisdom22                        0.5\n",
       "feature_wisdom23                       0.75\n",
       "feature_wisdom24                       0.75\n",
       "feature_wisdom25                       0.25\n",
       "feature_wisdom26                        0.5\n",
       "feature_wisdom27                          1\n",
       "feature_wisdom28                       0.75\n",
       "feature_wisdom29                        0.5\n",
       "feature_wisdom30                        0.5\n",
       "feature_wisdom31                          1\n",
       "feature_wisdom32                       0.25\n",
       "feature_wisdom33                        0.5\n",
       "feature_wisdom34                        0.5\n",
       "feature_wisdom35                        0.5\n",
       "feature_wisdom36                       0.75\n",
       "feature_wisdom37                          1\n",
       "feature_wisdom38                          1\n",
       "feature_wisdom39                          1\n",
       "feature_wisdom40                       0.75\n",
       "feature_wisdom41                        0.5\n",
       "feature_wisdom42                       0.75\n",
       "feature_wisdom43                        0.5\n",
       "feature_wisdom44                          1\n",
       "feature_wisdom45                        0.5\n",
       "feature_wisdom46                       0.75\n",
       "target                                  0.5\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "era55    4893\n",
       "era58    4893\n",
       "era54    4887\n",
       "era56    4879\n",
       "era57    4870\n",
       "         ... \n",
       "era5     2679\n",
       "era4     2543\n",
       "era3     2424\n",
       "era1     2408\n",
       "era2     2371\n",
       "Name: era, Length: 120, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.era.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501808, 314)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50    251677\n",
       "0.25    100053\n",
       "0.75    100045\n",
       "1.00     25017\n",
       "0.00     25016\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check proportion of target values\n",
    "train_data.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform dataframe slicing based on target value\n",
    "target_000_df = train_data[train_data.target == 0]\n",
    "target_025_df = train_data[train_data.target == 0.25]\n",
    "target_050_df = train_data[train_data.target == 0.50]\n",
    "target_075_df = train_data[train_data.target == 0.75]\n",
    "target_100_df = train_data[train_data.target == 1]\n",
    "\n",
    "#Capture the indexes containing respective target value\n",
    "target_000_idx = target_000_df.index.tolist()\n",
    "target_025_idx = target_025_df.index.tolist()\n",
    "target_050_idx = target_050_df.index.tolist()\n",
    "target_075_idx = target_075_df.index.tolist()\n",
    "target_100_idx = target_100_df.index.tolist()\n",
    "\n",
    "#Reducing size of dataframe from 500k to 50k with equal proportion\n",
    "target_000_idx = target_000_idx[0:2500]\n",
    "target_025_idx = target_025_idx[0:10000]\n",
    "target_050_idx = target_050_idx[0:25000]\n",
    "target_075_idx = target_075_idx[0:10000]\n",
    "target_100_idx = target_100_idx[0:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>era</th>\n",
       "      <th>data_type</th>\n",
       "      <th>feature_intelligence1</th>\n",
       "      <th>feature_intelligence2</th>\n",
       "      <th>feature_intelligence3</th>\n",
       "      <th>feature_intelligence4</th>\n",
       "      <th>feature_intelligence5</th>\n",
       "      <th>feature_intelligence6</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_wisdom38</th>\n",
       "      <th>feature_wisdom39</th>\n",
       "      <th>feature_wisdom40</th>\n",
       "      <th>feature_wisdom41</th>\n",
       "      <th>feature_wisdom42</th>\n",
       "      <th>feature_wisdom43</th>\n",
       "      <th>feature_wisdom44</th>\n",
       "      <th>feature_wisdom45</th>\n",
       "      <th>feature_wisdom46</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>n00d8f184e5b24e8</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>n02ad35bb1903b21</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>n03a4981030f4016</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>n03a9cdbd79304b8</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68</td>\n",
       "      <td>n0555024b98f9229</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 315 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                id   era data_type  feature_intelligence1  \\\n",
       "0     12  n00d8f184e5b24e8  era1     train                   1.00   \n",
       "1     33  n02ad35bb1903b21  era1     train                   0.75   \n",
       "2     44  n03a4981030f4016  era1     train                   0.75   \n",
       "3     45  n03a9cdbd79304b8  era1     train                   1.00   \n",
       "4     68  n0555024b98f9229  era1     train                   0.75   \n",
       "\n",
       "   feature_intelligence2  feature_intelligence3  feature_intelligence4  \\\n",
       "0                   0.00                   0.00                   1.00   \n",
       "1                   0.50                   0.50                   0.75   \n",
       "2                   0.50                   0.50                   0.75   \n",
       "3                   0.00                   0.00                   1.00   \n",
       "4                   0.25                   0.25                   0.75   \n",
       "\n",
       "   feature_intelligence5  feature_intelligence6  ...  feature_wisdom38  \\\n",
       "0                   0.25                   0.50  ...              0.75   \n",
       "1                   0.00                   1.00  ...              1.00   \n",
       "2                   1.00                   0.75  ...              1.00   \n",
       "3                   0.75                   0.75  ...              0.00   \n",
       "4                   0.25                   0.50  ...              1.00   \n",
       "\n",
       "   feature_wisdom39  feature_wisdom40  feature_wisdom41  feature_wisdom42  \\\n",
       "0              0.75              0.25               0.5              1.00   \n",
       "1              1.00              0.25               0.0              1.00   \n",
       "2              0.75              1.00               1.0              0.75   \n",
       "3              0.00              0.50               1.0              0.75   \n",
       "4              0.75              1.00               1.0              0.00   \n",
       "\n",
       "   feature_wisdom43  feature_wisdom44  feature_wisdom45  feature_wisdom46  \\\n",
       "0              0.25              0.25              1.00              1.00   \n",
       "1              0.75              0.25              0.50              0.25   \n",
       "2              1.00              1.00              0.50              0.75   \n",
       "3              1.00              0.50              0.25              0.50   \n",
       "4              0.50              1.00              0.50              0.25   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "\n",
       "[5 rows x 315 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Joining the truncated row datasets\n",
    "df = pd.concat([train_data.iloc[target_000_idx], train_data.iloc[target_025_idx], \\\n",
    "                train_data.iloc[target_050_idx], train_data.iloc[target_075_idx], \\\n",
    "               train_data.iloc[target_100_idx]],axis=0)\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "df.to_parquet('train_data_10%.gzip')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 314)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (37500, 310)\n",
      "X_test:  (12500, 310)\n",
      "y_train:  (37500,)\n",
      "y_test:  (12500,)\n"
     ]
    }
   ],
   "source": [
    "#Train test split for feature importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X = df.drop(['id','era','data_type','target'],axis=1)\n",
    "X = df.drop(['index','id','era','data_type','target'],axis=1)\n",
    "y = df.target\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "\n",
    "X_train.to_parquet('X_train_10%_025.gzip')\n",
    "X_test.to_parquet('X_test_10%_025.gzip')\n",
    "y_train.to_pickle('y_train_10%_025.pkl')\n",
    "y_test.to_pickle('y_test_10%_025.pkl')\n",
    "\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.01464\n",
      "Feature: 1, Score: 0.00413\n",
      "Feature: 2, Score: -0.02016\n",
      "Feature: 3, Score: 0.00179\n",
      "Feature: 4, Score: 0.01276\n",
      "Feature: 5, Score: -0.00087\n",
      "Feature: 6, Score: 0.00790\n",
      "Feature: 7, Score: -0.01716\n",
      "Feature: 8, Score: -0.01948\n",
      "Feature: 9, Score: 0.01490\n",
      "Feature: 10, Score: -0.00842\n",
      "Feature: 11, Score: -0.00451\n",
      "Feature: 12, Score: -0.00298\n",
      "Feature: 13, Score: 0.00101\n",
      "Feature: 14, Score: 0.00714\n",
      "Feature: 15, Score: 0.01239\n",
      "Feature: 16, Score: 0.00259\n",
      "Feature: 17, Score: -0.01600\n",
      "Feature: 18, Score: 0.00770\n",
      "Feature: 19, Score: -0.00042\n",
      "Feature: 20, Score: 0.00084\n",
      "Feature: 21, Score: 0.00288\n",
      "Feature: 22, Score: -0.00164\n",
      "Feature: 23, Score: -0.00547\n",
      "Feature: 24, Score: 0.03364\n",
      "Feature: 25, Score: -0.00802\n",
      "Feature: 26, Score: -0.00401\n",
      "Feature: 27, Score: 0.00867\n",
      "Feature: 28, Score: -0.00565\n",
      "Feature: 29, Score: -0.00642\n",
      "Feature: 30, Score: -0.00274\n",
      "Feature: 31, Score: -0.01082\n",
      "Feature: 32, Score: 0.02000\n",
      "Feature: 33, Score: 0.02045\n",
      "Feature: 34, Score: -0.00045\n",
      "Feature: 35, Score: -0.00216\n",
      "Feature: 36, Score: -0.00172\n",
      "Feature: 37, Score: -0.00349\n",
      "Feature: 38, Score: -0.00331\n",
      "Feature: 39, Score: 0.00649\n",
      "Feature: 40, Score: -0.01614\n",
      "Feature: 41, Score: 0.00206\n",
      "Feature: 42, Score: 0.00726\n",
      "Feature: 43, Score: 0.00821\n",
      "Feature: 44, Score: 0.01181\n",
      "Feature: 45, Score: -0.00131\n",
      "Feature: 46, Score: -0.01466\n",
      "Feature: 47, Score: -0.01553\n",
      "Feature: 48, Score: -0.00032\n",
      "Feature: 49, Score: 0.00292\n",
      "Feature: 50, Score: -0.00106\n",
      "Feature: 51, Score: 0.00207\n",
      "Feature: 52, Score: 0.01223\n",
      "Feature: 53, Score: -0.01216\n",
      "Feature: 54, Score: -0.01158\n",
      "Feature: 55, Score: -0.00218\n",
      "Feature: 56, Score: -0.00951\n",
      "Feature: 57, Score: 0.01287\n",
      "Feature: 58, Score: 0.00987\n",
      "Feature: 59, Score: -0.01117\n",
      "Feature: 60, Score: -0.00280\n",
      "Feature: 61, Score: -0.02185\n",
      "Feature: 62, Score: -0.01428\n",
      "Feature: 63, Score: 0.00216\n",
      "Feature: 64, Score: -0.00561\n",
      "Feature: 65, Score: 0.02591\n",
      "Feature: 66, Score: -0.00701\n",
      "Feature: 67, Score: -0.00980\n",
      "Feature: 68, Score: 0.00546\n",
      "Feature: 69, Score: 0.00195\n",
      "Feature: 70, Score: -0.00715\n",
      "Feature: 71, Score: -0.01204\n",
      "Feature: 72, Score: 0.00756\n",
      "Feature: 73, Score: -0.00913\n",
      "Feature: 74, Score: 0.00923\n",
      "Feature: 75, Score: 0.00968\n",
      "Feature: 76, Score: -0.00028\n",
      "Feature: 77, Score: -0.00744\n",
      "Feature: 78, Score: 0.01298\n",
      "Feature: 79, Score: -0.01676\n",
      "Feature: 80, Score: -0.01543\n",
      "Feature: 81, Score: 0.01870\n",
      "Feature: 82, Score: 0.01150\n",
      "Feature: 83, Score: -0.00301\n",
      "Feature: 84, Score: 0.00649\n",
      "Feature: 85, Score: 0.00207\n",
      "Feature: 86, Score: 0.01732\n",
      "Feature: 87, Score: 0.00217\n",
      "Feature: 88, Score: 0.00640\n",
      "Feature: 89, Score: 0.00334\n",
      "Feature: 90, Score: 0.00151\n",
      "Feature: 91, Score: 0.00451\n",
      "Feature: 92, Score: 0.01048\n",
      "Feature: 93, Score: 0.01786\n",
      "Feature: 94, Score: -0.00794\n",
      "Feature: 95, Score: -0.01667\n",
      "Feature: 96, Score: 0.00125\n",
      "Feature: 97, Score: 0.01665\n",
      "Feature: 98, Score: 0.01603\n",
      "Feature: 99, Score: -0.00161\n",
      "Feature: 100, Score: 0.00706\n",
      "Feature: 101, Score: -0.00552\n",
      "Feature: 102, Score: -0.01372\n",
      "Feature: 103, Score: 0.00457\n",
      "Feature: 104, Score: -0.02335\n",
      "Feature: 105, Score: 0.00180\n",
      "Feature: 106, Score: -0.01323\n",
      "Feature: 107, Score: 0.00420\n",
      "Feature: 108, Score: -0.00340\n",
      "Feature: 109, Score: 0.01582\n",
      "Feature: 110, Score: 0.01092\n",
      "Feature: 111, Score: 0.01477\n",
      "Feature: 112, Score: -0.00798\n",
      "Feature: 113, Score: -0.00504\n",
      "Feature: 114, Score: -0.01152\n",
      "Feature: 115, Score: 0.00743\n",
      "Feature: 116, Score: -0.00245\n",
      "Feature: 117, Score: 0.04443\n",
      "Feature: 118, Score: 0.00079\n",
      "Feature: 119, Score: 0.00667\n",
      "Feature: 120, Score: 0.00499\n",
      "Feature: 121, Score: 0.00895\n",
      "Feature: 122, Score: 0.01292\n",
      "Feature: 123, Score: 0.01587\n",
      "Feature: 124, Score: 0.00170\n",
      "Feature: 125, Score: -0.01201\n",
      "Feature: 126, Score: -0.00275\n",
      "Feature: 127, Score: -0.01297\n",
      "Feature: 128, Score: -0.00810\n",
      "Feature: 129, Score: -0.00551\n",
      "Feature: 130, Score: -0.01703\n",
      "Feature: 131, Score: 0.00039\n",
      "Feature: 132, Score: 0.02262\n",
      "Feature: 133, Score: 0.00340\n",
      "Feature: 134, Score: -0.01002\n",
      "Feature: 135, Score: -0.03414\n",
      "Feature: 136, Score: 0.02985\n",
      "Feature: 137, Score: -0.03029\n",
      "Feature: 138, Score: 0.00151\n",
      "Feature: 139, Score: -0.02287\n",
      "Feature: 140, Score: 0.02106\n",
      "Feature: 141, Score: -0.01880\n",
      "Feature: 142, Score: -0.00223\n",
      "Feature: 143, Score: 0.00280\n",
      "Feature: 144, Score: -0.00042\n",
      "Feature: 145, Score: 0.01009\n",
      "Feature: 146, Score: 0.01015\n",
      "Feature: 147, Score: -0.00082\n",
      "Feature: 148, Score: -0.00366\n",
      "Feature: 149, Score: -0.02149\n",
      "Feature: 150, Score: 0.01196\n",
      "Feature: 151, Score: -0.00640\n",
      "Feature: 152, Score: 0.00547\n",
      "Feature: 153, Score: 0.00305\n",
      "Feature: 154, Score: 0.03123\n",
      "Feature: 155, Score: -0.00903\n",
      "Feature: 156, Score: -0.01284\n",
      "Feature: 157, Score: 0.01370\n",
      "Feature: 158, Score: -0.00105\n",
      "Feature: 159, Score: -0.01424\n",
      "Feature: 160, Score: 0.00750\n",
      "Feature: 161, Score: 0.00843\n",
      "Feature: 162, Score: -0.01794\n",
      "Feature: 163, Score: 0.02410\n",
      "Feature: 164, Score: 0.00898\n",
      "Feature: 165, Score: -0.00586\n",
      "Feature: 166, Score: -0.00935\n",
      "Feature: 167, Score: 0.00543\n",
      "Feature: 168, Score: 0.00688\n",
      "Feature: 169, Score: -0.00254\n",
      "Feature: 170, Score: 0.00477\n",
      "Feature: 171, Score: -0.00587\n",
      "Feature: 172, Score: -0.00622\n",
      "Feature: 173, Score: -0.00179\n",
      "Feature: 174, Score: 0.01780\n",
      "Feature: 175, Score: -0.00291\n",
      "Feature: 176, Score: 0.01294\n",
      "Feature: 177, Score: -0.01042\n",
      "Feature: 178, Score: -0.00341\n",
      "Feature: 179, Score: 0.01525\n",
      "Feature: 180, Score: -0.00609\n",
      "Feature: 181, Score: 0.00006\n",
      "Feature: 182, Score: -0.00872\n",
      "Feature: 183, Score: -0.00097\n",
      "Feature: 184, Score: -0.00829\n",
      "Feature: 185, Score: 0.00299\n",
      "Feature: 186, Score: -0.00967\n",
      "Feature: 187, Score: 0.00811\n",
      "Feature: 188, Score: -0.00784\n",
      "Feature: 189, Score: 0.00091\n",
      "Feature: 190, Score: -0.00820\n",
      "Feature: 191, Score: -0.01036\n",
      "Feature: 192, Score: -0.00741\n",
      "Feature: 193, Score: -0.01391\n",
      "Feature: 194, Score: -0.00485\n",
      "Feature: 195, Score: 0.00750\n",
      "Feature: 196, Score: -0.00245\n",
      "Feature: 197, Score: -0.00781\n",
      "Feature: 198, Score: 0.00256\n",
      "Feature: 199, Score: -0.01034\n",
      "Feature: 200, Score: -0.02005\n",
      "Feature: 201, Score: 0.00110\n",
      "Feature: 202, Score: 0.00211\n",
      "Feature: 203, Score: -0.01260\n",
      "Feature: 204, Score: 0.02337\n",
      "Feature: 205, Score: -0.02951\n",
      "Feature: 206, Score: 0.00165\n",
      "Feature: 207, Score: -0.00691\n",
      "Feature: 208, Score: -0.01199\n",
      "Feature: 209, Score: -0.01833\n",
      "Feature: 210, Score: 0.00727\n",
      "Feature: 211, Score: 0.01276\n",
      "Feature: 212, Score: 0.00254\n",
      "Feature: 213, Score: -0.00166\n",
      "Feature: 214, Score: -0.00702\n",
      "Feature: 215, Score: 0.00166\n",
      "Feature: 216, Score: 0.00855\n",
      "Feature: 217, Score: 0.01319\n",
      "Feature: 218, Score: -0.00227\n",
      "Feature: 219, Score: -0.01004\n",
      "Feature: 220, Score: 0.00997\n",
      "Feature: 221, Score: 0.01133\n",
      "Feature: 222, Score: 0.00082\n",
      "Feature: 223, Score: -0.00601\n",
      "Feature: 224, Score: -0.00856\n",
      "Feature: 225, Score: -0.00006\n",
      "Feature: 226, Score: 0.02069\n",
      "Feature: 227, Score: -0.00981\n",
      "Feature: 228, Score: 0.00914\n",
      "Feature: 229, Score: -0.02267\n",
      "Feature: 230, Score: 0.01714\n",
      "Feature: 231, Score: -0.00341\n",
      "Feature: 232, Score: 0.00901\n",
      "Feature: 233, Score: 0.01569\n",
      "Feature: 234, Score: -0.00567\n",
      "Feature: 235, Score: 0.00856\n",
      "Feature: 236, Score: 0.01282\n",
      "Feature: 237, Score: -0.00580\n",
      "Feature: 238, Score: 0.00120\n",
      "Feature: 239, Score: -0.00801\n",
      "Feature: 240, Score: -0.02248\n",
      "Feature: 241, Score: 0.01173\n",
      "Feature: 242, Score: -0.01553\n",
      "Feature: 243, Score: -0.00577\n",
      "Feature: 244, Score: 0.00922\n",
      "Feature: 245, Score: -0.01130\n",
      "Feature: 246, Score: 0.00544\n",
      "Feature: 247, Score: -0.00923\n",
      "Feature: 248, Score: 0.00530\n",
      "Feature: 249, Score: -0.00423\n",
      "Feature: 250, Score: 0.01094\n",
      "Feature: 251, Score: 0.01768\n",
      "Feature: 252, Score: 0.00945\n",
      "Feature: 253, Score: 0.01065\n",
      "Feature: 254, Score: -0.01184\n",
      "Feature: 255, Score: -0.01661\n",
      "Feature: 256, Score: -0.00304\n",
      "Feature: 257, Score: 0.01362\n",
      "Feature: 258, Score: 0.02756\n",
      "Feature: 259, Score: 0.02786\n",
      "Feature: 260, Score: -0.02345\n",
      "Feature: 261, Score: -0.02292\n",
      "Feature: 262, Score: 0.00730\n",
      "Feature: 263, Score: 0.00357\n",
      "Feature: 264, Score: -0.01446\n",
      "Feature: 265, Score: 0.03523\n",
      "Feature: 266, Score: -0.00771\n",
      "Feature: 267, Score: -0.00477\n",
      "Feature: 268, Score: -0.00720\n",
      "Feature: 269, Score: -0.00925\n",
      "Feature: 270, Score: 0.00197\n",
      "Feature: 271, Score: -0.00681\n",
      "Feature: 272, Score: 0.00858\n",
      "Feature: 273, Score: -0.00363\n",
      "Feature: 274, Score: 0.01263\n",
      "Feature: 275, Score: -0.02935\n",
      "Feature: 276, Score: -0.00449\n",
      "Feature: 277, Score: 0.01482\n",
      "Feature: 278, Score: -0.00290\n",
      "Feature: 279, Score: 0.01565\n",
      "Feature: 280, Score: -0.00787\n",
      "Feature: 281, Score: 0.01045\n",
      "Feature: 282, Score: 0.01394\n",
      "Feature: 283, Score: 0.00073\n",
      "Feature: 284, Score: 0.00936\n",
      "Feature: 285, Score: 0.00418\n",
      "Feature: 286, Score: 0.00059\n",
      "Feature: 287, Score: -0.00224\n",
      "Feature: 288, Score: -0.01984\n",
      "Feature: 289, Score: 0.00187\n",
      "Feature: 290, Score: 0.00311\n",
      "Feature: 291, Score: -0.00454\n",
      "Feature: 292, Score: 0.00751\n",
      "Feature: 293, Score: 0.00844\n",
      "Feature: 294, Score: -0.00435\n",
      "Feature: 295, Score: -0.00091\n",
      "Feature: 296, Score: 0.01584\n",
      "Feature: 297, Score: 0.00542\n",
      "Feature: 298, Score: -0.00015\n",
      "Feature: 299, Score: 0.00068\n",
      "Feature: 300, Score: 0.01146\n",
      "Feature: 301, Score: -0.01299\n",
      "Feature: 302, Score: 0.01807\n",
      "Feature: 303, Score: -0.01258\n",
      "Feature: 304, Score: 0.00664\n",
      "Feature: 305, Score: 0.00434\n",
      "Feature: 306, Score: 0.00111\n",
      "Feature: 307, Score: 0.01565\n",
      "Feature: 308, Score: -0.01895\n",
      "Feature: 309, Score: -0.02828\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# linear regression feature importance\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# get importance\n",
    "importance = lr_model.coef_\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01463597,  0.00412608, -0.02015911])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodness of Fit of Model \tTrain Dataset\n",
      "Explained Variance (R^2) \t: 0.014476341847839413\n",
      "Mean Squared Error (MSE) \t: 0.04960759370834516\n",
      "\n",
      "Goodness of Fit of Model \tTest Dataset\n",
      "Explained Variance (R^2) \t: -0.0020643781173814713\n",
      "Mean Squared Error (MSE) \t: 0.04906759539172853\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_train_pred = lr_model.predict(X_train)\n",
    "y_test_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", lr_model.score(X_train, y_train))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_train, y_train_pred))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", lr_model.score(X_test, y_test))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_test, y_test_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6105     0.25\n",
       "9940     0.25\n",
       "45421    0.75\n",
       "42236    0.75\n",
       "15382    0.50\n",
       "26882    0.50\n",
       "12465    0.25\n",
       "27658    0.50\n",
       "7336     0.25\n",
       "46500    0.75\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment on all training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "#TRAIN TEST SPLITTING AND SAVING INTO SMALLER FILE\n",
    "##################################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_parquet('train_data.gzip')\n",
    "\n",
    "X = df.drop(['id','era','data_type','target'],axis=1)\n",
    "y = df.target\n",
    "\n",
    "#X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "#X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=123)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.8,random_state=123)\n",
    "\n",
    "#X_train.to_parquet('X_train_025.gzip')\n",
    "#X_test.to_parquet('X_test_025.gzip')\n",
    "#y_train.to_pickle('y_train_025.pkl')\n",
    "#y_test.to_pickle('y_test_025.pkl')\n",
    "\n",
    "#X_train.to_parquet('X_train_020.gzip')\n",
    "#X_test.to_parquet('X_test_020.gzip')\n",
    "#y_train.to_pickle('y_train_020.pkl')\n",
    "#y_test.to_pickle('y_test_020.pkl')\n",
    "\n",
    "X_train.to_parquet('X_train_080.gzip')\n",
    "X_test.to_parquet('X_test_080.gzip')\n",
    "y_train.to_pickle('y_train_080.pkl')\n",
    "y_test.to_pickle('y_test_080.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#LOADING THE TRAIN TEST DATA\n",
    "############################\n",
    "\n",
    "# X_train = pd.read_parquet('X_train_025.gzip')\n",
    "# X_test = pd.read_parquet('X_test_025.gzip')\n",
    "# y_train = pd.read_pickle('y_train_025.pkl')\n",
    "# y_test = pd.read_pickle('y_test_025.pkl')\n",
    "\n",
    "X_train = pd.read_parquet('X_train_020.gzip')\n",
    "X_test = pd.read_parquet('X_test_020.gzip')\n",
    "y_train = pd.read_pickle('y_train_020.pkl')\n",
    "y_test = pd.read_pickle('y_test_020.pkl')\n",
    "\n",
    "# X_train = pd.read_parquet('X_train_080.gzip')\n",
    "# X_test = pd.read_parquet('X_test_080.gzip')\n",
    "# y_train = pd.read_pickle('y_train_080.pkl')\n",
    "# y_test = pd.read_pickle('y_test_080.pkl')\n",
    "\n",
    "y_train = y_train.map({0.00:0, 0.25:1,0.50:2,0.75:3,1.00:4})\n",
    "y_test = y_test.map({0.00:0, 0.25:1,0.50:2,0.75:3,1.00:4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred[1].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFC Hyperparam Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc_pred(param,X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for depth in param:\n",
    "        model = RandomForestClassifier(n_estimators=100,max_depth=depth,class_weight=\"balanced\",random_state=123)\n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train) \n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        y_train_pred = pd.Series(y_train_pred)\n",
    "        y_test_pred = pd.Series(y_test_pred)\n",
    "\n",
    "        y_train_copy = y_train.copy()\n",
    "        y_test_copy = y_test.copy()\n",
    "        y_train_copy.reset_index(drop=True,inplace=True)\n",
    "        y_test_copy.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        result.append([depth, round(model.score(X_train,y_train),4),round(model.score(X_test,y_test),4),\\\n",
    "                       round(y_train_pred.corr(y_train_copy),4),round(y_test_pred.corr(y_test_copy),4)])\n",
    "\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "df = pd.read_parquet('train_data.gzip')\n",
    "\n",
    "X = df.drop(['id','era','data_type','target'],axis=1)\n",
    "y = df.target\n",
    "\n",
    "y = y.map({0.00:0, 0.25:1,0.50:2,0.75:3,1.00:4})\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100,max_depth=9,class_weight=\"balanced\",random_state=123)\n",
    "cv = StratifiedKFold(n_splits=5, random_state=123, shuffle=True)\n",
    "\n",
    "results=[]\n",
    "\n",
    "for (train, test), i in zip(cv.split(X, y), range(5)):\n",
    "    X_train = X.iloc[train]\n",
    "    y_train = y.iloc[train]\n",
    "    X_test = X.iloc[test]\n",
    "    y_test = y.iloc[test]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_train_pred = pd.Series(y_train_pred)\n",
    "    y_test_pred = pd.Series(y_test_pred)\n",
    "\n",
    "    y_train_copy = y_train.copy()\n",
    "    y_test_copy = y_test.copy()\n",
    "    y_train_copy.reset_index(drop=True,inplace=True)\n",
    "    y_test_copy.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    results.append([i,round(model.score(X_train,y_train),5),round(model.score(X_test,y_test),5),\\\n",
    "                       round(y_train_pred.corr(y_train_copy),5),round(y_test_pred.corr(y_test_copy),5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_pickle('rfc_results_all_020_maxdepth.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kfold</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_corr</th>\n",
       "      <th>test_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.39542</td>\n",
       "      <td>0.38785</td>\n",
       "      <td>0.19235</td>\n",
       "      <td>0.15662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.39449</td>\n",
       "      <td>0.38694</td>\n",
       "      <td>0.19119</td>\n",
       "      <td>0.15811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.39554</td>\n",
       "      <td>0.38789</td>\n",
       "      <td>0.18472</td>\n",
       "      <td>0.15077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.39668</td>\n",
       "      <td>0.38929</td>\n",
       "      <td>0.19214</td>\n",
       "      <td>0.15801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.39661</td>\n",
       "      <td>0.38842</td>\n",
       "      <td>0.18816</td>\n",
       "      <td>0.15467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kfold  train_score  test_score  train_corr  test_corr\n",
       "0      0      0.39542     0.38785     0.19235    0.15662\n",
       "1      1      0.39449     0.38694     0.19119    0.15811\n",
       "2      2      0.39554     0.38789     0.18472    0.15077\n",
       "3      3      0.39668     0.38929     0.19214    0.15801\n",
       "4      4      0.39661     0.38842     0.18816    0.15467"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(data=results,columns=[\"kfold\",\"train_score\",\"test_score\",\"train_corr\",\"test_corr\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_pickle('rfc_kfold5_all_020_depth9.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_corr</th>\n",
       "      <th>test_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.3758</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.3751</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.3716</td>\n",
       "      <td>0.3697</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.0168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.3701</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.0182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.3729</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.0170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.0215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0.3961</td>\n",
       "      <td>0.3583</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>0.0217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.4197</td>\n",
       "      <td>0.3579</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>0.0153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>0.4618</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.3320</td>\n",
       "      <td>0.0214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.3663</td>\n",
       "      <td>0.4209</td>\n",
       "      <td>0.0216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>0.6162</td>\n",
       "      <td>0.3763</td>\n",
       "      <td>0.5246</td>\n",
       "      <td>0.0192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>0.7210</td>\n",
       "      <td>0.3914</td>\n",
       "      <td>0.6380</td>\n",
       "      <td>0.0114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>0.8136</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.7514</td>\n",
       "      <td>0.0089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  train_score  test_score  train_corr  test_corr\n",
       "0           3       0.3758      0.3765      0.0094     0.0069\n",
       "1           4       0.3751      0.3750      0.0167     0.0143\n",
       "2           5       0.3716      0.3697      0.0308     0.0168\n",
       "3           6       0.3701      0.3636      0.0552     0.0182\n",
       "4           7       0.3729      0.3596      0.0870     0.0170\n",
       "5           8       0.3825      0.3612      0.1340     0.0215\n",
       "6           9       0.3961      0.3583      0.1892     0.0217\n",
       "7          10       0.4197      0.3579      0.2560     0.0153\n",
       "8          11       0.4618      0.3612      0.3320     0.0214\n",
       "9          12       0.5263      0.3663      0.4209     0.0216\n",
       "10         13       0.6162      0.3763      0.5246     0.0192\n",
       "0          14       0.7210      0.3914      0.6380     0.0114\n",
       "1          15       0.8136      0.4087      0.7514     0.0089"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.read_pickle('rfc_results_all_020_maxdepth.pkl')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=123, shuffle=True)\n",
    "\n",
    "for (train, test), i in zip(cv.split(X, y), range(1)):\n",
    "    x_train = train\n",
    "    x_test = test\n",
    "    \n",
    "#     X_train = X.iloc[train]\n",
    "#     y_train = y.iloc[train]\n",
    "#     X_test = X.iloc[~train]\n",
    "#     y_test = y.iloc[~train]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     1,      2,      3, ..., 501804, 501805, 501807])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      9,     20, ..., 501802, 501803, 501806])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_intelligence1</th>\n",
       "      <th>feature_intelligence2</th>\n",
       "      <th>feature_intelligence3</th>\n",
       "      <th>feature_intelligence4</th>\n",
       "      <th>feature_intelligence5</th>\n",
       "      <th>feature_intelligence6</th>\n",
       "      <th>feature_intelligence7</th>\n",
       "      <th>feature_intelligence8</th>\n",
       "      <th>feature_intelligence9</th>\n",
       "      <th>feature_intelligence10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_wisdom37</th>\n",
       "      <th>feature_wisdom38</th>\n",
       "      <th>feature_wisdom39</th>\n",
       "      <th>feature_wisdom40</th>\n",
       "      <th>feature_wisdom41</th>\n",
       "      <th>feature_wisdom42</th>\n",
       "      <th>feature_wisdom43</th>\n",
       "      <th>feature_wisdom44</th>\n",
       "      <th>feature_wisdom45</th>\n",
       "      <th>feature_wisdom46</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501800</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501801</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501804</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501805</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501807</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401446 rows × 310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_intelligence1  feature_intelligence2  feature_intelligence3  \\\n",
       "1                        0.00                   0.00                   0.00   \n",
       "2                        0.25                   0.50                   0.25   \n",
       "3                        1.00                   0.00                   0.00   \n",
       "4                        0.25                   0.25                   0.25   \n",
       "5                        0.50                   0.50                   0.25   \n",
       "...                       ...                    ...                    ...   \n",
       "501800                   0.00                   1.00                   1.00   \n",
       "501801                   0.25                   0.75                   0.75   \n",
       "501804                   1.00                   0.00                   0.00   \n",
       "501805                   0.75                   0.50                   0.50   \n",
       "501807                   0.75                   0.50                   0.50   \n",
       "\n",
       "        feature_intelligence4  feature_intelligence5  feature_intelligence6  \\\n",
       "1                        0.25                   0.50                   0.00   \n",
       "2                        0.25                   1.00                   0.75   \n",
       "3                        0.50                   0.50                   0.25   \n",
       "4                        0.25                   0.00                   0.25   \n",
       "5                        0.25                   0.75                   0.75   \n",
       "...                       ...                    ...                    ...   \n",
       "501800                   0.25                   0.50                   0.00   \n",
       "501801                   0.00                   1.00                   1.00   \n",
       "501804                   1.00                   0.50                   0.75   \n",
       "501805                   0.50                   0.25                   0.50   \n",
       "501807                   0.75                   0.75                   0.00   \n",
       "\n",
       "        feature_intelligence7  feature_intelligence8  feature_intelligence9  \\\n",
       "1                        0.00                   0.25                   0.50   \n",
       "2                        0.75                   0.25                   0.00   \n",
       "3                        0.25                   0.75                   0.25   \n",
       "4                        0.50                   0.25                   0.25   \n",
       "5                        0.75                   0.50                   0.25   \n",
       "...                       ...                    ...                    ...   \n",
       "501800                   0.25                   0.00                   1.00   \n",
       "501801                   1.00                   0.00                   1.00   \n",
       "501804                   0.75                   1.00                   0.00   \n",
       "501805                   0.25                   0.50                   0.25   \n",
       "501807                   0.00                   0.75                   0.00   \n",
       "\n",
       "        feature_intelligence10  ...  feature_wisdom37  feature_wisdom38  \\\n",
       "1                         0.50  ...              0.75              1.00   \n",
       "2                         0.25  ...              0.50              0.25   \n",
       "3                         0.50  ...              0.75              1.00   \n",
       "4                         0.50  ...              0.50              0.75   \n",
       "5                         0.50  ...              0.75              0.75   \n",
       "...                        ...  ...               ...               ...   \n",
       "501800                    1.00  ...              0.25              0.50   \n",
       "501801                    1.00  ...              0.50              0.50   \n",
       "501804                    0.00  ...              1.00              1.00   \n",
       "501805                    0.25  ...              1.00              1.00   \n",
       "501807                    0.00  ...              0.50              0.50   \n",
       "\n",
       "        feature_wisdom39  feature_wisdom40  feature_wisdom41  \\\n",
       "1                   1.00              0.00              0.00   \n",
       "2                   0.50              0.00              0.00   \n",
       "3                   1.00              0.75              0.75   \n",
       "4                   0.75              0.25              0.50   \n",
       "5                   0.75              0.00              0.00   \n",
       "...                  ...               ...               ...   \n",
       "501800              0.50              0.50              0.25   \n",
       "501801              0.25              0.25              0.25   \n",
       "501804              1.00              1.00              1.00   \n",
       "501805              0.75              0.25              1.00   \n",
       "501807              0.50              0.25              0.50   \n",
       "\n",
       "        feature_wisdom42  feature_wisdom43  feature_wisdom44  \\\n",
       "1                   0.75              0.25              0.00   \n",
       "2                   0.50              1.00              0.00   \n",
       "3                   1.00              1.00              0.75   \n",
       "4                   0.75              0.00              0.50   \n",
       "5                   0.75              0.50              0.00   \n",
       "...                  ...               ...               ...   \n",
       "501800              0.25              0.00              0.75   \n",
       "501801              0.25              0.25              0.25   \n",
       "501804              1.00              0.00              0.75   \n",
       "501805              1.00              1.00              0.25   \n",
       "501807              0.75              1.00              0.25   \n",
       "\n",
       "        feature_wisdom45  feature_wisdom46  \n",
       "1                   0.25              1.00  \n",
       "2                   0.25              0.75  \n",
       "3                   1.00              1.00  \n",
       "4                   0.25              0.75  \n",
       "5                   0.25              0.00  \n",
       "...                  ...               ...  \n",
       "501800              0.50              0.25  \n",
       "501801              1.00              0.75  \n",
       "501804              1.00              1.00  \n",
       "501805              0.00              0.00  \n",
       "501807              0.75              0.50  \n",
       "\n",
       "[401446 rows x 310 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_intelligence1</th>\n",
       "      <th>feature_intelligence2</th>\n",
       "      <th>feature_intelligence3</th>\n",
       "      <th>feature_intelligence4</th>\n",
       "      <th>feature_intelligence5</th>\n",
       "      <th>feature_intelligence6</th>\n",
       "      <th>feature_intelligence7</th>\n",
       "      <th>feature_intelligence8</th>\n",
       "      <th>feature_intelligence9</th>\n",
       "      <th>feature_intelligence10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_wisdom37</th>\n",
       "      <th>feature_wisdom38</th>\n",
       "      <th>feature_wisdom39</th>\n",
       "      <th>feature_wisdom40</th>\n",
       "      <th>feature_wisdom41</th>\n",
       "      <th>feature_wisdom42</th>\n",
       "      <th>feature_wisdom43</th>\n",
       "      <th>feature_wisdom44</th>\n",
       "      <th>feature_wisdom45</th>\n",
       "      <th>feature_wisdom46</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501794</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501799</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501802</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501803</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501806</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100362 rows × 310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_intelligence1  feature_intelligence2  feature_intelligence3  \\\n",
       "0                        0.00                   0.50                   0.25   \n",
       "9                        0.50                   1.00                   1.00   \n",
       "20                       0.75                   1.00                   1.00   \n",
       "21                       1.00                   0.00                   0.00   \n",
       "22                       0.50                   0.75                   0.75   \n",
       "...                       ...                    ...                    ...   \n",
       "501794                   1.00                   1.00                   1.00   \n",
       "501799                   0.75                   0.75                   0.75   \n",
       "501802                   1.00                   0.50                   0.50   \n",
       "501803                   0.50                   0.50                   0.25   \n",
       "501806                   0.25                   0.25                   0.25   \n",
       "\n",
       "        feature_intelligence4  feature_intelligence5  feature_intelligence6  \\\n",
       "0                        0.00                   0.50                   0.25   \n",
       "9                        0.25                   0.75                   0.25   \n",
       "20                       1.00                   0.50                   0.75   \n",
       "21                       0.75                   0.00                   1.00   \n",
       "22                       0.50                   1.00                   1.00   \n",
       "...                       ...                    ...                    ...   \n",
       "501794                   1.00                   0.00                   1.00   \n",
       "501799                   0.50                   0.00                   0.25   \n",
       "501802                   0.50                   0.25                   0.00   \n",
       "501803                   0.00                   0.00                   0.50   \n",
       "501806                   0.50                   0.00                   1.00   \n",
       "\n",
       "        feature_intelligence7  feature_intelligence8  feature_intelligence9  \\\n",
       "0                        0.25                   0.25                   0.75   \n",
       "9                        0.25                   0.75                   0.50   \n",
       "20                       1.00                   0.25                   0.75   \n",
       "21                       1.00                   0.75                   0.25   \n",
       "22                       1.00                   0.25                   0.75   \n",
       "...                       ...                    ...                    ...   \n",
       "501794                   1.00                   1.00                   0.00   \n",
       "501799                   0.25                   0.50                   0.50   \n",
       "501802                   0.00                   1.00                   0.50   \n",
       "501803                   0.75                   0.00                   0.75   \n",
       "501806                   1.00                   0.50                   0.25   \n",
       "\n",
       "        feature_intelligence10  ...  feature_wisdom37  feature_wisdom38  \\\n",
       "0                         0.75  ...              1.00              1.00   \n",
       "9                         0.50  ...              0.00              0.00   \n",
       "20                        1.00  ...              0.50              0.50   \n",
       "21                        0.25  ...              1.00              1.00   \n",
       "22                        0.75  ...              0.25              0.50   \n",
       "...                        ...  ...               ...               ...   \n",
       "501794                    0.00  ...              0.00              0.00   \n",
       "501799                    0.50  ...              0.25              0.75   \n",
       "501802                    0.25  ...              1.00              0.75   \n",
       "501803                    0.75  ...              0.75              0.50   \n",
       "501806                    0.25  ...              0.50              0.75   \n",
       "\n",
       "        feature_wisdom39  feature_wisdom40  feature_wisdom41  \\\n",
       "0                   1.00              0.75              0.50   \n",
       "9                   0.00              1.00              1.00   \n",
       "20                  0.50              0.75              0.50   \n",
       "21                  1.00              0.50              0.25   \n",
       "22                  0.50              0.00              0.00   \n",
       "...                  ...               ...               ...   \n",
       "501794              0.00              0.00              0.00   \n",
       "501799              0.75              0.25              0.50   \n",
       "501802              0.75              1.00              1.00   \n",
       "501803              0.50              0.75              0.50   \n",
       "501806              0.75              0.75              0.75   \n",
       "\n",
       "        feature_wisdom42  feature_wisdom43  feature_wisdom44  \\\n",
       "0                   0.75              0.50              1.00   \n",
       "9                   0.75              0.50              1.00   \n",
       "20                  0.50              0.50              1.00   \n",
       "21                  1.00              1.00              0.50   \n",
       "22                  0.50              0.25              0.00   \n",
       "...                  ...               ...               ...   \n",
       "501794              0.00              0.75              0.00   \n",
       "501799              0.75              1.00              0.50   \n",
       "501802              1.00              0.75              1.00   \n",
       "501803              0.50              0.75              0.25   \n",
       "501806              0.75              0.50              0.50   \n",
       "\n",
       "        feature_wisdom45  feature_wisdom46  \n",
       "0                   0.50              0.75  \n",
       "9                   1.00              0.75  \n",
       "20                  0.50              0.25  \n",
       "21                  0.75              0.50  \n",
       "22                  0.25              0.25  \n",
       "...                  ...               ...  \n",
       "501794              0.50              0.00  \n",
       "501799              0.00              0.00  \n",
       "501802              1.00              0.75  \n",
       "501803              0.25              0.25  \n",
       "501806              0.25              0.75  \n",
       "\n",
       "[100362 rows x 310 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_pred(X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    result = []\n",
    "\n",
    "    model = XGBClassifier(eta=0.4, max_depth=7, min_child_weight = 1, random_state=0,\\\n",
    "                          grow_policy = \"lossguide\", eval_metric = \"mlogloss\", objective=\"multi:softmax\",\\\n",
    "                          num_class=5)\n",
    "\n",
    "#         sample_type='weighted',feature_selector='cyclic',\\\n",
    "\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    y_train_pred = model.predict_proba(X_train) #will give an output of probability of each classes\n",
    "    y_test_pred = model.predict_proba(X_test)\n",
    "\n",
    "    y_train_pred_adj = []\n",
    "    y_test_pred_adj = []\n",
    "\n",
    "    for i in range(len(y_train_pred)):\n",
    "        if y_train_pred[i].argmax() == 0:\n",
    "            y_train_pred_adj.append(0.00)\n",
    "        elif y_train_pred[i].argmax() == 1:\n",
    "            y_train_pred_adj.append(0.25)\n",
    "        elif y_train_pred[i].argmax() == 2:\n",
    "            y_train_pred_adj.append(0.50)\n",
    "        elif y_train_pred[i].argmax() == 3:\n",
    "            y_train_pred_adj.append(0.75)\n",
    "        else:\n",
    "            y_train_pred_adj.append(1.00)\n",
    "\n",
    "    for i in range(len(y_test_pred)):\n",
    "        if y_test_pred[i].argmax() == 0:\n",
    "            y_test_pred_adj.append(0.00)\n",
    "        elif y_test_pred[i].argmax() == 1:\n",
    "            y_test_pred_adj.append(0.25)\n",
    "        elif y_test_pred[i].argmax() == 2:\n",
    "            y_test_pred_adj.append(0.50)\n",
    "        elif y_test_pred[i].argmax() == 3:\n",
    "            y_test_pred_adj.append(0.75)\n",
    "        else:\n",
    "            y_test_pred_adj.append(1.00)\n",
    "\n",
    "    y_train_pred_adj = pd.Series(y_train_pred_adj)\n",
    "    y_test_pred_adj = pd.Series(y_test_pred_adj)\n",
    "\n",
    "    y_train_copy = y_train.copy()\n",
    "    y_test_copy = y_test.copy()\n",
    "    y_train_copy.reset_index(drop=True,inplace=True)\n",
    "    y_test_copy.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    result.append([y_train_pred_adj.corr(y_train_copy),y_test_pred_adj.corr(y_test_copy)])\n",
    "\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.8843671908371065, 0.009117203548223547]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_pred(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 0.5263259687906177, 0.008092431623198205]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_pred(model,6,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = [[0.35,0.8523608025312785, 0.004537041897319825],\n",
    " [0.375,0.8718657277426665, 0.006132192101997824],\n",
    " [0.425,0.9020533314569592, 0.006048008970637242],\n",
    " [0.45,0.9099207601325763, 0.007321830973244737]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 0.8085115469825217, 0.008696752441807207]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_pred(model,7,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eta</th>\n",
       "      <th>train_corr</th>\n",
       "      <th>test_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.852361</td>\n",
       "      <td>0.004537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.375</td>\n",
       "      <td>0.871866</td>\n",
       "      <td>0.006132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.425</td>\n",
       "      <td>0.902053</td>\n",
       "      <td>0.006048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.450</td>\n",
       "      <td>0.909921</td>\n",
       "      <td>0.007322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     eta  train_corr  test_corr\n",
       "0  0.350    0.852361   0.004537\n",
       "1  0.375    0.871866   0.006132\n",
       "2  0.425    0.902053   0.006048\n",
       "3  0.450    0.909921   0.007322"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df2= pd.DataFrame(data=result2,columns=['eta','train_corr','test_corr'])\n",
    "result_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eta</th>\n",
       "      <th>train_corr</th>\n",
       "      <th>test_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.342341</td>\n",
       "      <td>0.002698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.654593</td>\n",
       "      <td>0.005782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.808512</td>\n",
       "      <td>0.008697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.852361</td>\n",
       "      <td>0.004537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.375</td>\n",
       "      <td>0.871866</td>\n",
       "      <td>0.006132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.400</td>\n",
       "      <td>0.884367</td>\n",
       "      <td>0.009117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.425</td>\n",
       "      <td>0.902053</td>\n",
       "      <td>0.006048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.450</td>\n",
       "      <td>0.909921</td>\n",
       "      <td>0.007322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.929699</td>\n",
       "      <td>0.004356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     eta  train_corr  test_corr\n",
       "0  0.100    0.342341   0.002698\n",
       "1  0.200    0.654593   0.005782\n",
       "2  0.300    0.808512   0.008697\n",
       "5  0.350    0.852361   0.004537\n",
       "6  0.375    0.871866   0.006132\n",
       "3  0.400    0.884367   0.009117\n",
       "7  0.425    0.902053   0.006048\n",
       "8  0.450    0.909921   0.007322\n",
       "4  0.500    0.929699   0.004356"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df3 = pd.concat([result_df,result_df2],axis=0)\n",
    "result_df3.reset_index(drop=True,inplace=True)\n",
    "result_df3.sort_values('eta',inplace=True)\n",
    "result_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eta</th>\n",
       "      <th>train_corr</th>\n",
       "      <th>test_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.342341</td>\n",
       "      <td>0.002698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.654593</td>\n",
       "      <td>0.005782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.808512</td>\n",
       "      <td>0.008697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.884367</td>\n",
       "      <td>0.009117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.929699</td>\n",
       "      <td>0.004356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eta  train_corr  test_corr\n",
       "0  0.1    0.342341   0.002698\n",
       "1  0.2    0.654593   0.005782\n",
       "2  0.3    0.808512   0.008697\n",
       "3  0.4    0.884367   0.009117\n",
       "4  0.5    0.929699   0.004356"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(data=result,columns=['eta','train_corr','test_corr'])\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_result.to_pickle('rf_corr_table_025.pkl')\n",
    "#add_result.to_pickle('rf_corr_table_020.pkl')\n",
    "#result_df.to_pickle('rf_corr_table_080.pkl')\n",
    "# result_df.to_pickle('xgb_corr_table_080_maxdepth.pkl')\n",
    "# result_df.to_pickle('xgb_corr_table_080_minchildweight.pkl')\n",
    "result_df3.to_pickle('xgb_corr_table_080_eta.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_corr</th>\n",
       "      <th>test_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.381576</td>\n",
       "      <td>0.359040</td>\n",
       "      <td>0.133667</td>\n",
       "      <td>0.020160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0.395523</td>\n",
       "      <td>0.358572</td>\n",
       "      <td>0.190574</td>\n",
       "      <td>0.024570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.419523</td>\n",
       "      <td>0.358153</td>\n",
       "      <td>0.256405</td>\n",
       "      <td>0.024152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0.461860</td>\n",
       "      <td>0.360316</td>\n",
       "      <td>0.330718</td>\n",
       "      <td>0.015533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0.527511</td>\n",
       "      <td>0.366493</td>\n",
       "      <td>0.419656</td>\n",
       "      <td>0.017252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  train_score  test_score  train_corr  test_corr\n",
       "0          8     0.381576    0.359040    0.133667   0.020160\n",
       "1          9     0.395523    0.358572    0.190574   0.024570\n",
       "2         10     0.419523    0.358153    0.256405   0.024152\n",
       "3         11     0.461860    0.360316    0.330718   0.015533\n",
       "4         12     0.527511    0.366493    0.419656   0.017252"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.read_pickle('rf_corr_table_020.pkl')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_corr</th>\n",
       "      <th>test_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.388687</td>\n",
       "      <td>0.388699</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>0.000660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.381602</td>\n",
       "      <td>0.381199</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.002725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.377408</td>\n",
       "      <td>0.375093</td>\n",
       "      <td>0.017472</td>\n",
       "      <td>0.002856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.369070</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.375465</td>\n",
       "      <td>0.363336</td>\n",
       "      <td>0.081009</td>\n",
       "      <td>0.012347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.384034</td>\n",
       "      <td>0.360603</td>\n",
       "      <td>0.132268</td>\n",
       "      <td>0.010425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.396937</td>\n",
       "      <td>0.358304</td>\n",
       "      <td>0.196531</td>\n",
       "      <td>0.014845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.421987</td>\n",
       "      <td>0.356458</td>\n",
       "      <td>0.271718</td>\n",
       "      <td>0.015232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.466137</td>\n",
       "      <td>0.358055</td>\n",
       "      <td>0.353878</td>\n",
       "      <td>0.013371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.534959</td>\n",
       "      <td>0.362723</td>\n",
       "      <td>0.443199</td>\n",
       "      <td>0.015523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.646556</td>\n",
       "      <td>0.377253</td>\n",
       "      <td>0.568877</td>\n",
       "      <td>0.012616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.767649</td>\n",
       "      <td>0.396859</td>\n",
       "      <td>0.708569</td>\n",
       "      <td>0.010778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.869870</td>\n",
       "      <td>0.418561</td>\n",
       "      <td>0.840433</td>\n",
       "      <td>0.010043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.932165</td>\n",
       "      <td>0.441381</td>\n",
       "      <td>0.927195</td>\n",
       "      <td>0.004075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  train_score  test_score  train_corr  test_corr\n",
       "0           1     0.388687    0.388699    0.002363   0.000660\n",
       "1           2     0.381602    0.381199    0.009205   0.002725\n",
       "2           3     0.377408    0.375093    0.017472   0.002856\n",
       "3           4     0.374508    0.369070    0.037760   0.008131\n",
       "4           5     0.375465    0.363336    0.081009   0.012347\n",
       "5           6     0.384034    0.360603    0.132268   0.010425\n",
       "6           7     0.396937    0.358304    0.196531   0.014845\n",
       "7           8     0.421987    0.356458    0.271718   0.015232\n",
       "8           9     0.466137    0.358055    0.353878   0.013371\n",
       "9          10     0.534959    0.362723    0.443199   0.015523\n",
       "10         11     0.646556    0.377253    0.568877   0.012616\n",
       "11         12     0.767649    0.396859    0.708569   0.010778\n",
       "12         13     0.869870    0.418561    0.840433   0.010043\n",
       "13         14     0.932165    0.441381    0.927195   0.004075"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.read_pickle('rf_corr_table_080.pkl')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Removing less important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>era</th>\n",
       "      <th>data_type</th>\n",
       "      <th>feature_intelligence1</th>\n",
       "      <th>feature_intelligence2</th>\n",
       "      <th>feature_intelligence3</th>\n",
       "      <th>feature_intelligence4</th>\n",
       "      <th>feature_intelligence5</th>\n",
       "      <th>feature_intelligence6</th>\n",
       "      <th>feature_intelligence7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_wisdom38</th>\n",
       "      <th>feature_wisdom39</th>\n",
       "      <th>feature_wisdom40</th>\n",
       "      <th>feature_wisdom41</th>\n",
       "      <th>feature_wisdom42</th>\n",
       "      <th>feature_wisdom43</th>\n",
       "      <th>feature_wisdom44</th>\n",
       "      <th>feature_wisdom45</th>\n",
       "      <th>feature_wisdom46</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n000315175b67977</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n0014af834a96cdd</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id   era data_type  feature_intelligence1  \\\n",
       "0  n000315175b67977  era1     train                    0.0   \n",
       "1  n0014af834a96cdd  era1     train                    0.0   \n",
       "\n",
       "   feature_intelligence2  feature_intelligence3  feature_intelligence4  \\\n",
       "0                    0.5                   0.25                   0.00   \n",
       "1                    0.0                   0.00                   0.25   \n",
       "\n",
       "   feature_intelligence5  feature_intelligence6  feature_intelligence7  ...  \\\n",
       "0                    0.5                   0.25                   0.25  ...   \n",
       "1                    0.5                   0.00                   0.00  ...   \n",
       "\n",
       "   feature_wisdom38  feature_wisdom39  feature_wisdom40  feature_wisdom41  \\\n",
       "0               1.0               1.0              0.75               0.5   \n",
       "1               1.0               1.0              0.00               0.0   \n",
       "\n",
       "   feature_wisdom42  feature_wisdom43  feature_wisdom44  feature_wisdom45  \\\n",
       "0              0.75              0.50               1.0              0.50   \n",
       "1              0.75              0.25               0.0              0.25   \n",
       "\n",
       "   feature_wisdom46  target  \n",
       "0              0.75    0.50  \n",
       "1              1.00    0.25  \n",
       "\n",
       "[2 rows x 314 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_data.copy()\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cnt = []\n",
    "for col in range(3,len(X.columns)):\n",
    "    x = X[X.columns[col]].value_counts().reset_index().sort_values('index')\n",
    "    val_cnt.append([X.columns[col],x.iloc[0,1],x.iloc[1,1],x.iloc[2,1],x.iloc[3,1],x.iloc[4,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>0.00</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feature_intelligence1</td>\n",
       "      <td>100407</td>\n",
       "      <td>100338</td>\n",
       "      <td>100337</td>\n",
       "      <td>100338</td>\n",
       "      <td>100388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feature_intelligence2</td>\n",
       "      <td>100406</td>\n",
       "      <td>100337</td>\n",
       "      <td>100343</td>\n",
       "      <td>100337</td>\n",
       "      <td>100385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feature_intelligence3</td>\n",
       "      <td>100406</td>\n",
       "      <td>100337</td>\n",
       "      <td>100343</td>\n",
       "      <td>100337</td>\n",
       "      <td>100385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature_intelligence4</td>\n",
       "      <td>100407</td>\n",
       "      <td>100338</td>\n",
       "      <td>100337</td>\n",
       "      <td>100338</td>\n",
       "      <td>100388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feature_intelligence5</td>\n",
       "      <td>100404</td>\n",
       "      <td>100333</td>\n",
       "      <td>100357</td>\n",
       "      <td>100333</td>\n",
       "      <td>100381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feature_intelligence6</td>\n",
       "      <td>100404</td>\n",
       "      <td>100333</td>\n",
       "      <td>100357</td>\n",
       "      <td>100333</td>\n",
       "      <td>100381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>feature_intelligence7</td>\n",
       "      <td>100404</td>\n",
       "      <td>100333</td>\n",
       "      <td>100357</td>\n",
       "      <td>100333</td>\n",
       "      <td>100381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>feature_intelligence8</td>\n",
       "      <td>100407</td>\n",
       "      <td>100338</td>\n",
       "      <td>100337</td>\n",
       "      <td>100338</td>\n",
       "      <td>100388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>feature_intelligence9</td>\n",
       "      <td>99558</td>\n",
       "      <td>99496</td>\n",
       "      <td>103720</td>\n",
       "      <td>99496</td>\n",
       "      <td>99538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>feature_intelligence10</td>\n",
       "      <td>99558</td>\n",
       "      <td>99496</td>\n",
       "      <td>103720</td>\n",
       "      <td>99496</td>\n",
       "      <td>99538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>feature_intelligence11</td>\n",
       "      <td>100407</td>\n",
       "      <td>100338</td>\n",
       "      <td>100337</td>\n",
       "      <td>100338</td>\n",
       "      <td>100388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>feature_intelligence12</td>\n",
       "      <td>100404</td>\n",
       "      <td>100333</td>\n",
       "      <td>100357</td>\n",
       "      <td>100333</td>\n",
       "      <td>100381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>feature_charisma1</td>\n",
       "      <td>100066</td>\n",
       "      <td>99997</td>\n",
       "      <td>101714</td>\n",
       "      <td>99997</td>\n",
       "      <td>100034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>feature_charisma2</td>\n",
       "      <td>90119</td>\n",
       "      <td>90058</td>\n",
       "      <td>141478</td>\n",
       "      <td>90058</td>\n",
       "      <td>90095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>feature_charisma3</td>\n",
       "      <td>91446</td>\n",
       "      <td>91369</td>\n",
       "      <td>136204</td>\n",
       "      <td>91369</td>\n",
       "      <td>91420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>feature_charisma4</td>\n",
       "      <td>92051</td>\n",
       "      <td>91981</td>\n",
       "      <td>133767</td>\n",
       "      <td>91981</td>\n",
       "      <td>92028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>feature_charisma5</td>\n",
       "      <td>78943</td>\n",
       "      <td>78862</td>\n",
       "      <td>186222</td>\n",
       "      <td>78862</td>\n",
       "      <td>78919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>feature_charisma6</td>\n",
       "      <td>100082</td>\n",
       "      <td>100006</td>\n",
       "      <td>101661</td>\n",
       "      <td>100006</td>\n",
       "      <td>100053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>feature_charisma7</td>\n",
       "      <td>82751</td>\n",
       "      <td>82681</td>\n",
       "      <td>170970</td>\n",
       "      <td>82681</td>\n",
       "      <td>82725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>feature_charisma8</td>\n",
       "      <td>68183</td>\n",
       "      <td>68112</td>\n",
       "      <td>229244</td>\n",
       "      <td>68112</td>\n",
       "      <td>68157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>feature_charisma9</td>\n",
       "      <td>100334</td>\n",
       "      <td>100272</td>\n",
       "      <td>100610</td>\n",
       "      <td>100272</td>\n",
       "      <td>100320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>feature_charisma10</td>\n",
       "      <td>97491</td>\n",
       "      <td>97412</td>\n",
       "      <td>112025</td>\n",
       "      <td>97412</td>\n",
       "      <td>97468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>feature_charisma11</td>\n",
       "      <td>94493</td>\n",
       "      <td>94430</td>\n",
       "      <td>123983</td>\n",
       "      <td>94430</td>\n",
       "      <td>94472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>feature_charisma12</td>\n",
       "      <td>94705</td>\n",
       "      <td>94639</td>\n",
       "      <td>123140</td>\n",
       "      <td>94639</td>\n",
       "      <td>94685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>feature_charisma13</td>\n",
       "      <td>92874</td>\n",
       "      <td>92802</td>\n",
       "      <td>130479</td>\n",
       "      <td>92802</td>\n",
       "      <td>92851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>feature_charisma14</td>\n",
       "      <td>91050</td>\n",
       "      <td>90982</td>\n",
       "      <td>137772</td>\n",
       "      <td>90982</td>\n",
       "      <td>91022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>feature_charisma15</td>\n",
       "      <td>68183</td>\n",
       "      <td>68112</td>\n",
       "      <td>229244</td>\n",
       "      <td>68112</td>\n",
       "      <td>68157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>feature_charisma16</td>\n",
       "      <td>91446</td>\n",
       "      <td>91376</td>\n",
       "      <td>136187</td>\n",
       "      <td>91376</td>\n",
       "      <td>91423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>feature_charisma17</td>\n",
       "      <td>92051</td>\n",
       "      <td>91981</td>\n",
       "      <td>133767</td>\n",
       "      <td>91981</td>\n",
       "      <td>92028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>feature_charisma18</td>\n",
       "      <td>100108</td>\n",
       "      <td>100027</td>\n",
       "      <td>101564</td>\n",
       "      <td>100027</td>\n",
       "      <td>100082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>feature_charisma19</td>\n",
       "      <td>100066</td>\n",
       "      <td>99997</td>\n",
       "      <td>101714</td>\n",
       "      <td>99997</td>\n",
       "      <td>100034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>feature_charisma20</td>\n",
       "      <td>94561</td>\n",
       "      <td>94493</td>\n",
       "      <td>123719</td>\n",
       "      <td>94493</td>\n",
       "      <td>94542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>feature_charisma21</td>\n",
       "      <td>93928</td>\n",
       "      <td>93862</td>\n",
       "      <td>126245</td>\n",
       "      <td>93862</td>\n",
       "      <td>93911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>feature_charisma22</td>\n",
       "      <td>66675</td>\n",
       "      <td>66600</td>\n",
       "      <td>235279</td>\n",
       "      <td>66600</td>\n",
       "      <td>66654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>feature_charisma23</td>\n",
       "      <td>89447</td>\n",
       "      <td>89378</td>\n",
       "      <td>144181</td>\n",
       "      <td>89378</td>\n",
       "      <td>89424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>feature_charisma24</td>\n",
       "      <td>90119</td>\n",
       "      <td>90058</td>\n",
       "      <td>141478</td>\n",
       "      <td>90058</td>\n",
       "      <td>90095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>feature_charisma25</td>\n",
       "      <td>56561</td>\n",
       "      <td>56498</td>\n",
       "      <td>275708</td>\n",
       "      <td>56498</td>\n",
       "      <td>56543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>feature_charisma26</td>\n",
       "      <td>92679</td>\n",
       "      <td>92606</td>\n",
       "      <td>131257</td>\n",
       "      <td>92606</td>\n",
       "      <td>92660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>feature_charisma27</td>\n",
       "      <td>66754</td>\n",
       "      <td>66689</td>\n",
       "      <td>234946</td>\n",
       "      <td>66689</td>\n",
       "      <td>66730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>feature_charisma28</td>\n",
       "      <td>95331</td>\n",
       "      <td>95258</td>\n",
       "      <td>120654</td>\n",
       "      <td>95258</td>\n",
       "      <td>95307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>feature_charisma29</td>\n",
       "      <td>93023</td>\n",
       "      <td>92953</td>\n",
       "      <td>129878</td>\n",
       "      <td>92953</td>\n",
       "      <td>93001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>feature_charisma30</td>\n",
       "      <td>95168</td>\n",
       "      <td>95092</td>\n",
       "      <td>121315</td>\n",
       "      <td>95092</td>\n",
       "      <td>95141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>feature_charisma31</td>\n",
       "      <td>99547</td>\n",
       "      <td>99475</td>\n",
       "      <td>103787</td>\n",
       "      <td>99475</td>\n",
       "      <td>99524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>feature_charisma32</td>\n",
       "      <td>76228</td>\n",
       "      <td>76156</td>\n",
       "      <td>197062</td>\n",
       "      <td>76156</td>\n",
       "      <td>76206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>feature_charisma33</td>\n",
       "      <td>91050</td>\n",
       "      <td>90982</td>\n",
       "      <td>137772</td>\n",
       "      <td>90982</td>\n",
       "      <td>91022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>feature_charisma34</td>\n",
       "      <td>100035</td>\n",
       "      <td>99962</td>\n",
       "      <td>101839</td>\n",
       "      <td>99962</td>\n",
       "      <td>100010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>feature_charisma35</td>\n",
       "      <td>91446</td>\n",
       "      <td>91376</td>\n",
       "      <td>136187</td>\n",
       "      <td>91376</td>\n",
       "      <td>91423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>feature_charisma36</td>\n",
       "      <td>93928</td>\n",
       "      <td>93862</td>\n",
       "      <td>126245</td>\n",
       "      <td>93862</td>\n",
       "      <td>93911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>feature_charisma37</td>\n",
       "      <td>98019</td>\n",
       "      <td>97947</td>\n",
       "      <td>109905</td>\n",
       "      <td>97947</td>\n",
       "      <td>97990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>feature_charisma38</td>\n",
       "      <td>95168</td>\n",
       "      <td>95092</td>\n",
       "      <td>121315</td>\n",
       "      <td>95092</td>\n",
       "      <td>95141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>feature_charisma39</td>\n",
       "      <td>89447</td>\n",
       "      <td>89378</td>\n",
       "      <td>144181</td>\n",
       "      <td>89378</td>\n",
       "      <td>89424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>feature_charisma40</td>\n",
       "      <td>100108</td>\n",
       "      <td>100040</td>\n",
       "      <td>101535</td>\n",
       "      <td>100040</td>\n",
       "      <td>100085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>feature_charisma41</td>\n",
       "      <td>72756</td>\n",
       "      <td>72682</td>\n",
       "      <td>210957</td>\n",
       "      <td>72682</td>\n",
       "      <td>72731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>feature_charisma42</td>\n",
       "      <td>91735</td>\n",
       "      <td>91668</td>\n",
       "      <td>135024</td>\n",
       "      <td>91668</td>\n",
       "      <td>91713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>feature_charisma43</td>\n",
       "      <td>99479</td>\n",
       "      <td>99414</td>\n",
       "      <td>104043</td>\n",
       "      <td>99414</td>\n",
       "      <td>99458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>feature_charisma44</td>\n",
       "      <td>98059</td>\n",
       "      <td>97986</td>\n",
       "      <td>109742</td>\n",
       "      <td>97986</td>\n",
       "      <td>98035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>feature_charisma45</td>\n",
       "      <td>91446</td>\n",
       "      <td>91369</td>\n",
       "      <td>136204</td>\n",
       "      <td>91369</td>\n",
       "      <td>91420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>feature_charisma46</td>\n",
       "      <td>99816</td>\n",
       "      <td>99753</td>\n",
       "      <td>102699</td>\n",
       "      <td>99753</td>\n",
       "      <td>99787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>feature_charisma47</td>\n",
       "      <td>56561</td>\n",
       "      <td>56498</td>\n",
       "      <td>275708</td>\n",
       "      <td>56498</td>\n",
       "      <td>56543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>feature_charisma48</td>\n",
       "      <td>76228</td>\n",
       "      <td>76156</td>\n",
       "      <td>197062</td>\n",
       "      <td>76156</td>\n",
       "      <td>76206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>feature_charisma49</td>\n",
       "      <td>66604</td>\n",
       "      <td>66531</td>\n",
       "      <td>235563</td>\n",
       "      <td>66531</td>\n",
       "      <td>66579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>feature_charisma50</td>\n",
       "      <td>92874</td>\n",
       "      <td>92802</td>\n",
       "      <td>130479</td>\n",
       "      <td>92802</td>\n",
       "      <td>92851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>feature_charisma51</td>\n",
       "      <td>99547</td>\n",
       "      <td>99475</td>\n",
       "      <td>103787</td>\n",
       "      <td>99475</td>\n",
       "      <td>99524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>feature_charisma52</td>\n",
       "      <td>91620</td>\n",
       "      <td>91546</td>\n",
       "      <td>135502</td>\n",
       "      <td>91546</td>\n",
       "      <td>91594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>feature_charisma53</td>\n",
       "      <td>95331</td>\n",
       "      <td>95258</td>\n",
       "      <td>120654</td>\n",
       "      <td>95258</td>\n",
       "      <td>95307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>feature_charisma54</td>\n",
       "      <td>100082</td>\n",
       "      <td>100006</td>\n",
       "      <td>101661</td>\n",
       "      <td>100006</td>\n",
       "      <td>100053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>feature_charisma55</td>\n",
       "      <td>100035</td>\n",
       "      <td>99962</td>\n",
       "      <td>101839</td>\n",
       "      <td>99962</td>\n",
       "      <td>100010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>feature_charisma56</td>\n",
       "      <td>67508</td>\n",
       "      <td>67446</td>\n",
       "      <td>231924</td>\n",
       "      <td>67446</td>\n",
       "      <td>67484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>feature_charisma57</td>\n",
       "      <td>100407</td>\n",
       "      <td>100338</td>\n",
       "      <td>100337</td>\n",
       "      <td>100338</td>\n",
       "      <td>100388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>feature_charisma58</td>\n",
       "      <td>94493</td>\n",
       "      <td>94430</td>\n",
       "      <td>123983</td>\n",
       "      <td>94430</td>\n",
       "      <td>94472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>feature_charisma59</td>\n",
       "      <td>72756</td>\n",
       "      <td>72682</td>\n",
       "      <td>210957</td>\n",
       "      <td>72682</td>\n",
       "      <td>72731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>feature_charisma60</td>\n",
       "      <td>66675</td>\n",
       "      <td>66600</td>\n",
       "      <td>235279</td>\n",
       "      <td>66600</td>\n",
       "      <td>66654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>feature_charisma61</td>\n",
       "      <td>100108</td>\n",
       "      <td>100040</td>\n",
       "      <td>101535</td>\n",
       "      <td>100040</td>\n",
       "      <td>100085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>feature_charisma62</td>\n",
       "      <td>91620</td>\n",
       "      <td>91546</td>\n",
       "      <td>135502</td>\n",
       "      <td>91546</td>\n",
       "      <td>91594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>feature_charisma63</td>\n",
       "      <td>99982</td>\n",
       "      <td>99907</td>\n",
       "      <td>102054</td>\n",
       "      <td>99907</td>\n",
       "      <td>99958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>feature_charisma64</td>\n",
       "      <td>94561</td>\n",
       "      <td>94493</td>\n",
       "      <td>123719</td>\n",
       "      <td>94493</td>\n",
       "      <td>94542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>feature_charisma65</td>\n",
       "      <td>67508</td>\n",
       "      <td>67446</td>\n",
       "      <td>231924</td>\n",
       "      <td>67446</td>\n",
       "      <td>67484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>feature_charisma66</td>\n",
       "      <td>99816</td>\n",
       "      <td>99753</td>\n",
       "      <td>102699</td>\n",
       "      <td>99753</td>\n",
       "      <td>99787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>feature_charisma67</td>\n",
       "      <td>92679</td>\n",
       "      <td>92606</td>\n",
       "      <td>131257</td>\n",
       "      <td>92606</td>\n",
       "      <td>92660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>feature_charisma68</td>\n",
       "      <td>88528</td>\n",
       "      <td>88450</td>\n",
       "      <td>147885</td>\n",
       "      <td>88450</td>\n",
       "      <td>88495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>feature_charisma69</td>\n",
       "      <td>100334</td>\n",
       "      <td>100272</td>\n",
       "      <td>100610</td>\n",
       "      <td>100272</td>\n",
       "      <td>100320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>feature_charisma70</td>\n",
       "      <td>99479</td>\n",
       "      <td>99414</td>\n",
       "      <td>104043</td>\n",
       "      <td>99414</td>\n",
       "      <td>99458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>feature_charisma71</td>\n",
       "      <td>93023</td>\n",
       "      <td>92953</td>\n",
       "      <td>129878</td>\n",
       "      <td>92953</td>\n",
       "      <td>93001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>feature_charisma72</td>\n",
       "      <td>82751</td>\n",
       "      <td>82681</td>\n",
       "      <td>170970</td>\n",
       "      <td>82681</td>\n",
       "      <td>82725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>feature_charisma73</td>\n",
       "      <td>66604</td>\n",
       "      <td>66531</td>\n",
       "      <td>235563</td>\n",
       "      <td>66531</td>\n",
       "      <td>66579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>feature_charisma74</td>\n",
       "      <td>98059</td>\n",
       "      <td>97986</td>\n",
       "      <td>109742</td>\n",
       "      <td>97986</td>\n",
       "      <td>98035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>feature_charisma75</td>\n",
       "      <td>91735</td>\n",
       "      <td>91668</td>\n",
       "      <td>135024</td>\n",
       "      <td>91668</td>\n",
       "      <td>91713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>feature_charisma76</td>\n",
       "      <td>100108</td>\n",
       "      <td>100027</td>\n",
       "      <td>101564</td>\n",
       "      <td>100027</td>\n",
       "      <td>100082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>feature_charisma77</td>\n",
       "      <td>66754</td>\n",
       "      <td>66689</td>\n",
       "      <td>234946</td>\n",
       "      <td>66689</td>\n",
       "      <td>66730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>feature_charisma78</td>\n",
       "      <td>97491</td>\n",
       "      <td>97412</td>\n",
       "      <td>112025</td>\n",
       "      <td>97412</td>\n",
       "      <td>97468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>feature_charisma79</td>\n",
       "      <td>78943</td>\n",
       "      <td>78862</td>\n",
       "      <td>186222</td>\n",
       "      <td>78862</td>\n",
       "      <td>78919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>feature_charisma80</td>\n",
       "      <td>94705</td>\n",
       "      <td>94639</td>\n",
       "      <td>123140</td>\n",
       "      <td>94639</td>\n",
       "      <td>94685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>feature_charisma81</td>\n",
       "      <td>98019</td>\n",
       "      <td>97947</td>\n",
       "      <td>109905</td>\n",
       "      <td>97947</td>\n",
       "      <td>97990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>feature_charisma82</td>\n",
       "      <td>88528</td>\n",
       "      <td>88450</td>\n",
       "      <td>147885</td>\n",
       "      <td>88450</td>\n",
       "      <td>88495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>feature_charisma83</td>\n",
       "      <td>100407</td>\n",
       "      <td>100338</td>\n",
       "      <td>100337</td>\n",
       "      <td>100338</td>\n",
       "      <td>100388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>feature_charisma84</td>\n",
       "      <td>95291</td>\n",
       "      <td>95220</td>\n",
       "      <td>120810</td>\n",
       "      <td>95220</td>\n",
       "      <td>95267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>feature_charisma85</td>\n",
       "      <td>99982</td>\n",
       "      <td>99907</td>\n",
       "      <td>102054</td>\n",
       "      <td>99907</td>\n",
       "      <td>99958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>feature_charisma86</td>\n",
       "      <td>95291</td>\n",
       "      <td>95220</td>\n",
       "      <td>120810</td>\n",
       "      <td>95220</td>\n",
       "      <td>95267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>feature_strength1</td>\n",
       "      <td>99871</td>\n",
       "      <td>99807</td>\n",
       "      <td>102474</td>\n",
       "      <td>99807</td>\n",
       "      <td>99849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>feature_strength2</td>\n",
       "      <td>91505</td>\n",
       "      <td>91432</td>\n",
       "      <td>135960</td>\n",
       "      <td>91432</td>\n",
       "      <td>91479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>feature_strength3</td>\n",
       "      <td>100145</td>\n",
       "      <td>100078</td>\n",
       "      <td>101383</td>\n",
       "      <td>100078</td>\n",
       "      <td>100124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>feature_strength4</td>\n",
       "      <td>99871</td>\n",
       "      <td>99807</td>\n",
       "      <td>102474</td>\n",
       "      <td>99807</td>\n",
       "      <td>99849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>feature_strength5</td>\n",
       "      <td>92103</td>\n",
       "      <td>92031</td>\n",
       "      <td>133560</td>\n",
       "      <td>92031</td>\n",
       "      <td>92083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>feature_strength6</td>\n",
       "      <td>64881</td>\n",
       "      <td>64815</td>\n",
       "      <td>242436</td>\n",
       "      <td>64815</td>\n",
       "      <td>64861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>feature_strength7</td>\n",
       "      <td>71990</td>\n",
       "      <td>71911</td>\n",
       "      <td>214029</td>\n",
       "      <td>71911</td>\n",
       "      <td>71967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>feature_strength8</td>\n",
       "      <td>99897</td>\n",
       "      <td>99816</td>\n",
       "      <td>102411</td>\n",
       "      <td>99816</td>\n",
       "      <td>99868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>feature_strength9</td>\n",
       "      <td>99750</td>\n",
       "      <td>99690</td>\n",
       "      <td>102949</td>\n",
       "      <td>99690</td>\n",
       "      <td>99729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>feature_strength10</td>\n",
       "      <td>100094</td>\n",
       "      <td>100016</td>\n",
       "      <td>101621</td>\n",
       "      <td>100016</td>\n",
       "      <td>100061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>feature_strength11</td>\n",
       "      <td>98250</td>\n",
       "      <td>98172</td>\n",
       "      <td>108986</td>\n",
       "      <td>98172</td>\n",
       "      <td>98228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>feature_strength12</td>\n",
       "      <td>92710</td>\n",
       "      <td>92633</td>\n",
       "      <td>131145</td>\n",
       "      <td>92633</td>\n",
       "      <td>92687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>feature_strength13</td>\n",
       "      <td>92103</td>\n",
       "      <td>92031</td>\n",
       "      <td>133560</td>\n",
       "      <td>92031</td>\n",
       "      <td>92083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>feature_strength14</td>\n",
       "      <td>99233</td>\n",
       "      <td>99160</td>\n",
       "      <td>105051</td>\n",
       "      <td>99160</td>\n",
       "      <td>99204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>feature_strength15</td>\n",
       "      <td>99850</td>\n",
       "      <td>99767</td>\n",
       "      <td>102597</td>\n",
       "      <td>99767</td>\n",
       "      <td>99827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>feature_strength16</td>\n",
       "      <td>98008</td>\n",
       "      <td>97941</td>\n",
       "      <td>109930</td>\n",
       "      <td>97941</td>\n",
       "      <td>97988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>feature_strength17</td>\n",
       "      <td>64881</td>\n",
       "      <td>64815</td>\n",
       "      <td>242436</td>\n",
       "      <td>64815</td>\n",
       "      <td>64861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>feature_strength18</td>\n",
       "      <td>86431</td>\n",
       "      <td>86352</td>\n",
       "      <td>156272</td>\n",
       "      <td>86352</td>\n",
       "      <td>86401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>feature_strength19</td>\n",
       "      <td>100145</td>\n",
       "      <td>100078</td>\n",
       "      <td>101383</td>\n",
       "      <td>100078</td>\n",
       "      <td>100124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>feature_strength20</td>\n",
       "      <td>26153</td>\n",
       "      <td>26069</td>\n",
       "      <td>397393</td>\n",
       "      <td>26069</td>\n",
       "      <td>26124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>feature_strength21</td>\n",
       "      <td>98250</td>\n",
       "      <td>98172</td>\n",
       "      <td>108986</td>\n",
       "      <td>98172</td>\n",
       "      <td>98228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>feature_strength22</td>\n",
       "      <td>99750</td>\n",
       "      <td>99690</td>\n",
       "      <td>102949</td>\n",
       "      <td>99690</td>\n",
       "      <td>99729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>feature_strength23</td>\n",
       "      <td>98008</td>\n",
       "      <td>97941</td>\n",
       "      <td>109930</td>\n",
       "      <td>97941</td>\n",
       "      <td>97988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>feature_strength24</td>\n",
       "      <td>89026</td>\n",
       "      <td>88963</td>\n",
       "      <td>145854</td>\n",
       "      <td>88963</td>\n",
       "      <td>89002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>feature_strength25</td>\n",
       "      <td>93012</td>\n",
       "      <td>92951</td>\n",
       "      <td>129902</td>\n",
       "      <td>92951</td>\n",
       "      <td>92992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>feature_strength26</td>\n",
       "      <td>73888</td>\n",
       "      <td>73814</td>\n",
       "      <td>206429</td>\n",
       "      <td>73814</td>\n",
       "      <td>73863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>feature_strength27</td>\n",
       "      <td>99850</td>\n",
       "      <td>99767</td>\n",
       "      <td>102597</td>\n",
       "      <td>99767</td>\n",
       "      <td>99827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>feature_strength28</td>\n",
       "      <td>99897</td>\n",
       "      <td>99816</td>\n",
       "      <td>102411</td>\n",
       "      <td>99816</td>\n",
       "      <td>99868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>feature_strength29</td>\n",
       "      <td>89026</td>\n",
       "      <td>88963</td>\n",
       "      <td>145854</td>\n",
       "      <td>88963</td>\n",
       "      <td>89002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>feature_strength30</td>\n",
       "      <td>92710</td>\n",
       "      <td>92633</td>\n",
       "      <td>131145</td>\n",
       "      <td>92633</td>\n",
       "      <td>92687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>feature_strength31</td>\n",
       "      <td>93012</td>\n",
       "      <td>92951</td>\n",
       "      <td>129902</td>\n",
       "      <td>92951</td>\n",
       "      <td>92992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>feature_strength32</td>\n",
       "      <td>91505</td>\n",
       "      <td>91432</td>\n",
       "      <td>135960</td>\n",
       "      <td>91432</td>\n",
       "      <td>91479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>feature_strength33</td>\n",
       "      <td>73888</td>\n",
       "      <td>73814</td>\n",
       "      <td>206429</td>\n",
       "      <td>73814</td>\n",
       "      <td>73863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>feature_strength34</td>\n",
       "      <td>99233</td>\n",
       "      <td>99160</td>\n",
       "      <td>105051</td>\n",
       "      <td>99160</td>\n",
       "      <td>99204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>feature_strength35</td>\n",
       "      <td>71990</td>\n",
       "      <td>71911</td>\n",
       "      <td>214029</td>\n",
       "      <td>71911</td>\n",
       "      <td>71967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>feature_strength36</td>\n",
       "      <td>100094</td>\n",
       "      <td>100016</td>\n",
       "      <td>101621</td>\n",
       "      <td>100016</td>\n",
       "      <td>100061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>feature_strength37</td>\n",
       "      <td>86431</td>\n",
       "      <td>86352</td>\n",
       "      <td>156272</td>\n",
       "      <td>86352</td>\n",
       "      <td>86401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>feature_strength38</td>\n",
       "      <td>26153</td>\n",
       "      <td>26069</td>\n",
       "      <td>397393</td>\n",
       "      <td>26069</td>\n",
       "      <td>26124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>feature_dexterity1</td>\n",
       "      <td>99814</td>\n",
       "      <td>99737</td>\n",
       "      <td>102730</td>\n",
       "      <td>99737</td>\n",
       "      <td>99790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>feature_dexterity2</td>\n",
       "      <td>99860</td>\n",
       "      <td>99791</td>\n",
       "      <td>102526</td>\n",
       "      <td>99791</td>\n",
       "      <td>99840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>feature_dexterity3</td>\n",
       "      <td>100406</td>\n",
       "      <td>100337</td>\n",
       "      <td>100342</td>\n",
       "      <td>100337</td>\n",
       "      <td>100386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>feature_dexterity4</td>\n",
       "      <td>100407</td>\n",
       "      <td>100338</td>\n",
       "      <td>100337</td>\n",
       "      <td>100338</td>\n",
       "      <td>100388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>feature_dexterity5</td>\n",
       "      <td>100405</td>\n",
       "      <td>100333</td>\n",
       "      <td>100356</td>\n",
       "      <td>100333</td>\n",
       "      <td>100381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>feature_dexterity6</td>\n",
       "      <td>100404</td>\n",
       "      <td>100333</td>\n",
       "      <td>100357</td>\n",
       "      <td>100333</td>\n",
       "      <td>100381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>feature_dexterity7</td>\n",
       "      <td>100407</td>\n",
       "      <td>100338</td>\n",
       "      <td>100337</td>\n",
       "      <td>100338</td>\n",
       "      <td>100388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>feature_dexterity8</td>\n",
       "      <td>100406</td>\n",
       "      <td>100337</td>\n",
       "      <td>100342</td>\n",
       "      <td>100337</td>\n",
       "      <td>100386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>feature_dexterity9</td>\n",
       "      <td>99814</td>\n",
       "      <td>99737</td>\n",
       "      <td>102730</td>\n",
       "      <td>99737</td>\n",
       "      <td>99790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>feature_dexterity10</td>\n",
       "      <td>99860</td>\n",
       "      <td>99791</td>\n",
       "      <td>102526</td>\n",
       "      <td>99791</td>\n",
       "      <td>99840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>feature_dexterity11</td>\n",
       "      <td>100404</td>\n",
       "      <td>100333</td>\n",
       "      <td>100357</td>\n",
       "      <td>100333</td>\n",
       "      <td>100381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>feature_dexterity12</td>\n",
       "      <td>100404</td>\n",
       "      <td>100333</td>\n",
       "      <td>100357</td>\n",
       "      <td>100333</td>\n",
       "      <td>100381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>feature_dexterity13</td>\n",
       "      <td>100405</td>\n",
       "      <td>100333</td>\n",
       "      <td>100356</td>\n",
       "      <td>100333</td>\n",
       "      <td>100381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>feature_dexterity14</td>\n",
       "      <td>100404</td>\n",
       "      <td>100333</td>\n",
       "      <td>100357</td>\n",
       "      <td>100333</td>\n",
       "      <td>100381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>feature_constitution1</td>\n",
       "      <td>94282</td>\n",
       "      <td>94203</td>\n",
       "      <td>124870</td>\n",
       "      <td>94203</td>\n",
       "      <td>94250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>feature_constitution2</td>\n",
       "      <td>95936</td>\n",
       "      <td>95868</td>\n",
       "      <td>118220</td>\n",
       "      <td>95868</td>\n",
       "      <td>95916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>feature_constitution3</td>\n",
       "      <td>96073</td>\n",
       "      <td>96001</td>\n",
       "      <td>117682</td>\n",
       "      <td>96001</td>\n",
       "      <td>96051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>feature_constitution4</td>\n",
       "      <td>100005</td>\n",
       "      <td>99932</td>\n",
       "      <td>101956</td>\n",
       "      <td>99932</td>\n",
       "      <td>99983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>feature_constitution5</td>\n",
       "      <td>92401</td>\n",
       "      <td>92328</td>\n",
       "      <td>132373</td>\n",
       "      <td>92328</td>\n",
       "      <td>92378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>feature_constitution6</td>\n",
       "      <td>92006</td>\n",
       "      <td>91926</td>\n",
       "      <td>133971</td>\n",
       "      <td>91926</td>\n",
       "      <td>91979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>feature_constitution7</td>\n",
       "      <td>99942</td>\n",
       "      <td>99866</td>\n",
       "      <td>102219</td>\n",
       "      <td>99866</td>\n",
       "      <td>99915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>feature_constitution8</td>\n",
       "      <td>92805</td>\n",
       "      <td>92731</td>\n",
       "      <td>130766</td>\n",
       "      <td>92731</td>\n",
       "      <td>92775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>feature_constitution9</td>\n",
       "      <td>99944</td>\n",
       "      <td>99869</td>\n",
       "      <td>102206</td>\n",
       "      <td>99869</td>\n",
       "      <td>99920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>feature_constitution10</td>\n",
       "      <td>92006</td>\n",
       "      <td>91926</td>\n",
       "      <td>133971</td>\n",
       "      <td>91926</td>\n",
       "      <td>91979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>feature_constitution11</td>\n",
       "      <td>96134</td>\n",
       "      <td>96064</td>\n",
       "      <td>117441</td>\n",
       "      <td>96064</td>\n",
       "      <td>96105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>feature_constitution12</td>\n",
       "      <td>100160</td>\n",
       "      <td>100090</td>\n",
       "      <td>101331</td>\n",
       "      <td>100090</td>\n",
       "      <td>100137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>feature_constitution13</td>\n",
       "      <td>99340</td>\n",
       "      <td>99265</td>\n",
       "      <td>104614</td>\n",
       "      <td>99265</td>\n",
       "      <td>99324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>feature_constitution14</td>\n",
       "      <td>92583</td>\n",
       "      <td>92507</td>\n",
       "      <td>131660</td>\n",
       "      <td>92507</td>\n",
       "      <td>92551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>feature_constitution15</td>\n",
       "      <td>95249</td>\n",
       "      <td>95184</td>\n",
       "      <td>120972</td>\n",
       "      <td>95184</td>\n",
       "      <td>95219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>feature_constitution16</td>\n",
       "      <td>98965</td>\n",
       "      <td>98899</td>\n",
       "      <td>106103</td>\n",
       "      <td>98899</td>\n",
       "      <td>98942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>feature_constitution17</td>\n",
       "      <td>92805</td>\n",
       "      <td>92731</td>\n",
       "      <td>130766</td>\n",
       "      <td>92731</td>\n",
       "      <td>92775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>feature_constitution18</td>\n",
       "      <td>92276</td>\n",
       "      <td>92202</td>\n",
       "      <td>132879</td>\n",
       "      <td>92202</td>\n",
       "      <td>92249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>feature_constitution19</td>\n",
       "      <td>92938</td>\n",
       "      <td>92863</td>\n",
       "      <td>130235</td>\n",
       "      <td>92863</td>\n",
       "      <td>92909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>feature_constitution20</td>\n",
       "      <td>95756</td>\n",
       "      <td>95687</td>\n",
       "      <td>118944</td>\n",
       "      <td>95687</td>\n",
       "      <td>95734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>feature_constitution21</td>\n",
       "      <td>88738</td>\n",
       "      <td>88665</td>\n",
       "      <td>147025</td>\n",
       "      <td>88665</td>\n",
       "      <td>88715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>feature_constitution22</td>\n",
       "      <td>100015</td>\n",
       "      <td>99942</td>\n",
       "      <td>101918</td>\n",
       "      <td>99942</td>\n",
       "      <td>99991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>feature_constitution23</td>\n",
       "      <td>96073</td>\n",
       "      <td>96001</td>\n",
       "      <td>117682</td>\n",
       "      <td>96001</td>\n",
       "      <td>96051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>feature_constitution24</td>\n",
       "      <td>99972</td>\n",
       "      <td>99893</td>\n",
       "      <td>102108</td>\n",
       "      <td>99893</td>\n",
       "      <td>99942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>feature_constitution25</td>\n",
       "      <td>100015</td>\n",
       "      <td>99942</td>\n",
       "      <td>101918</td>\n",
       "      <td>99942</td>\n",
       "      <td>99991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>feature_constitution26</td>\n",
       "      <td>95756</td>\n",
       "      <td>95687</td>\n",
       "      <td>118944</td>\n",
       "      <td>95687</td>\n",
       "      <td>95734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>feature_constitution27</td>\n",
       "      <td>99942</td>\n",
       "      <td>99866</td>\n",
       "      <td>102219</td>\n",
       "      <td>99866</td>\n",
       "      <td>99915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>feature_constitution28</td>\n",
       "      <td>96134</td>\n",
       "      <td>96064</td>\n",
       "      <td>117441</td>\n",
       "      <td>96064</td>\n",
       "      <td>96105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>feature_constitution29</td>\n",
       "      <td>100160</td>\n",
       "      <td>100090</td>\n",
       "      <td>101331</td>\n",
       "      <td>100090</td>\n",
       "      <td>100137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>feature_constitution30</td>\n",
       "      <td>89726</td>\n",
       "      <td>89655</td>\n",
       "      <td>143062</td>\n",
       "      <td>89655</td>\n",
       "      <td>89710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>feature_constitution31</td>\n",
       "      <td>91585</td>\n",
       "      <td>91512</td>\n",
       "      <td>135648</td>\n",
       "      <td>91512</td>\n",
       "      <td>91551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>feature_constitution32</td>\n",
       "      <td>99827</td>\n",
       "      <td>99759</td>\n",
       "      <td>102658</td>\n",
       "      <td>99759</td>\n",
       "      <td>99805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>feature_constitution33</td>\n",
       "      <td>99944</td>\n",
       "      <td>99869</td>\n",
       "      <td>102206</td>\n",
       "      <td>99869</td>\n",
       "      <td>99920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>feature_constitution34</td>\n",
       "      <td>100247</td>\n",
       "      <td>100170</td>\n",
       "      <td>101002</td>\n",
       "      <td>100170</td>\n",
       "      <td>100219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>feature_constitution35</td>\n",
       "      <td>99979</td>\n",
       "      <td>99907</td>\n",
       "      <td>102048</td>\n",
       "      <td>99907</td>\n",
       "      <td>99967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>feature_constitution36</td>\n",
       "      <td>100247</td>\n",
       "      <td>100170</td>\n",
       "      <td>101002</td>\n",
       "      <td>100170</td>\n",
       "      <td>100219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>feature_constitution37</td>\n",
       "      <td>95249</td>\n",
       "      <td>95184</td>\n",
       "      <td>120972</td>\n",
       "      <td>95184</td>\n",
       "      <td>95219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>feature_constitution38</td>\n",
       "      <td>98853</td>\n",
       "      <td>98790</td>\n",
       "      <td>106542</td>\n",
       "      <td>98790</td>\n",
       "      <td>98833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>feature_constitution39</td>\n",
       "      <td>92276</td>\n",
       "      <td>92202</td>\n",
       "      <td>132879</td>\n",
       "      <td>92202</td>\n",
       "      <td>92249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>feature_constitution40</td>\n",
       "      <td>98965</td>\n",
       "      <td>98899</td>\n",
       "      <td>106103</td>\n",
       "      <td>98899</td>\n",
       "      <td>98942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>feature_constitution41</td>\n",
       "      <td>91528</td>\n",
       "      <td>91465</td>\n",
       "      <td>135839</td>\n",
       "      <td>91465</td>\n",
       "      <td>91511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>feature_constitution42</td>\n",
       "      <td>89726</td>\n",
       "      <td>89655</td>\n",
       "      <td>143062</td>\n",
       "      <td>89655</td>\n",
       "      <td>89710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>feature_constitution43</td>\n",
       "      <td>100262</td>\n",
       "      <td>100190</td>\n",
       "      <td>100932</td>\n",
       "      <td>100190</td>\n",
       "      <td>100234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>feature_constitution44</td>\n",
       "      <td>89404</td>\n",
       "      <td>89337</td>\n",
       "      <td>144354</td>\n",
       "      <td>89337</td>\n",
       "      <td>89376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>feature_constitution45</td>\n",
       "      <td>100213</td>\n",
       "      <td>100138</td>\n",
       "      <td>101119</td>\n",
       "      <td>100138</td>\n",
       "      <td>100200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>feature_constitution46</td>\n",
       "      <td>99278</td>\n",
       "      <td>99206</td>\n",
       "      <td>104862</td>\n",
       "      <td>99206</td>\n",
       "      <td>99256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>feature_constitution47</td>\n",
       "      <td>100213</td>\n",
       "      <td>100138</td>\n",
       "      <td>101119</td>\n",
       "      <td>100138</td>\n",
       "      <td>100200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>feature_constitution48</td>\n",
       "      <td>100014</td>\n",
       "      <td>99938</td>\n",
       "      <td>101928</td>\n",
       "      <td>99938</td>\n",
       "      <td>99990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>feature_constitution49</td>\n",
       "      <td>100005</td>\n",
       "      <td>99932</td>\n",
       "      <td>101956</td>\n",
       "      <td>99932</td>\n",
       "      <td>99983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>feature_constitution50</td>\n",
       "      <td>100160</td>\n",
       "      <td>100090</td>\n",
       "      <td>101331</td>\n",
       "      <td>100090</td>\n",
       "      <td>100137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>feature_constitution51</td>\n",
       "      <td>92583</td>\n",
       "      <td>92507</td>\n",
       "      <td>131660</td>\n",
       "      <td>92507</td>\n",
       "      <td>92551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>feature_constitution52</td>\n",
       "      <td>100149</td>\n",
       "      <td>100078</td>\n",
       "      <td>101385</td>\n",
       "      <td>100078</td>\n",
       "      <td>100118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>feature_constitution53</td>\n",
       "      <td>99426</td>\n",
       "      <td>99354</td>\n",
       "      <td>104271</td>\n",
       "      <td>99354</td>\n",
       "      <td>99403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>feature_constitution54</td>\n",
       "      <td>100265</td>\n",
       "      <td>100204</td>\n",
       "      <td>100888</td>\n",
       "      <td>100204</td>\n",
       "      <td>100247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>feature_constitution55</td>\n",
       "      <td>89404</td>\n",
       "      <td>89337</td>\n",
       "      <td>144354</td>\n",
       "      <td>89337</td>\n",
       "      <td>89376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>feature_constitution56</td>\n",
       "      <td>100182</td>\n",
       "      <td>100111</td>\n",
       "      <td>101251</td>\n",
       "      <td>100111</td>\n",
       "      <td>100153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>feature_constitution57</td>\n",
       "      <td>99827</td>\n",
       "      <td>99759</td>\n",
       "      <td>102658</td>\n",
       "      <td>99759</td>\n",
       "      <td>99805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>feature_constitution58</td>\n",
       "      <td>99881</td>\n",
       "      <td>99809</td>\n",
       "      <td>102451</td>\n",
       "      <td>99809</td>\n",
       "      <td>99858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>feature_constitution59</td>\n",
       "      <td>99172</td>\n",
       "      <td>99103</td>\n",
       "      <td>105284</td>\n",
       "      <td>99103</td>\n",
       "      <td>99146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>feature_constitution60</td>\n",
       "      <td>95770</td>\n",
       "      <td>95687</td>\n",
       "      <td>118918</td>\n",
       "      <td>95687</td>\n",
       "      <td>95746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>feature_constitution61</td>\n",
       "      <td>92193</td>\n",
       "      <td>92130</td>\n",
       "      <td>133187</td>\n",
       "      <td>92130</td>\n",
       "      <td>92168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>feature_constitution62</td>\n",
       "      <td>94282</td>\n",
       "      <td>94203</td>\n",
       "      <td>124872</td>\n",
       "      <td>94203</td>\n",
       "      <td>94248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>feature_constitution63</td>\n",
       "      <td>99288</td>\n",
       "      <td>99225</td>\n",
       "      <td>104805</td>\n",
       "      <td>99225</td>\n",
       "      <td>99265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>feature_constitution64</td>\n",
       "      <td>100018</td>\n",
       "      <td>99946</td>\n",
       "      <td>101902</td>\n",
       "      <td>99946</td>\n",
       "      <td>99996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>feature_constitution65</td>\n",
       "      <td>99288</td>\n",
       "      <td>99225</td>\n",
       "      <td>104805</td>\n",
       "      <td>99225</td>\n",
       "      <td>99265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>feature_constitution66</td>\n",
       "      <td>89443</td>\n",
       "      <td>89365</td>\n",
       "      <td>144221</td>\n",
       "      <td>89365</td>\n",
       "      <td>89414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>feature_constitution67</td>\n",
       "      <td>98676</td>\n",
       "      <td>98611</td>\n",
       "      <td>107258</td>\n",
       "      <td>98611</td>\n",
       "      <td>98652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>feature_constitution68</td>\n",
       "      <td>99881</td>\n",
       "      <td>99809</td>\n",
       "      <td>102451</td>\n",
       "      <td>99809</td>\n",
       "      <td>99858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>feature_constitution69</td>\n",
       "      <td>100149</td>\n",
       "      <td>100078</td>\n",
       "      <td>101385</td>\n",
       "      <td>100078</td>\n",
       "      <td>100118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>feature_constitution70</td>\n",
       "      <td>88738</td>\n",
       "      <td>88665</td>\n",
       "      <td>147025</td>\n",
       "      <td>88665</td>\n",
       "      <td>88715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>feature_constitution71</td>\n",
       "      <td>99426</td>\n",
       "      <td>99354</td>\n",
       "      <td>104271</td>\n",
       "      <td>99354</td>\n",
       "      <td>99403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>feature_constitution72</td>\n",
       "      <td>92075</td>\n",
       "      <td>92003</td>\n",
       "      <td>133672</td>\n",
       "      <td>92003</td>\n",
       "      <td>92055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>feature_constitution73</td>\n",
       "      <td>95936</td>\n",
       "      <td>95868</td>\n",
       "      <td>118220</td>\n",
       "      <td>95868</td>\n",
       "      <td>95916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>feature_constitution74</td>\n",
       "      <td>92401</td>\n",
       "      <td>92328</td>\n",
       "      <td>132373</td>\n",
       "      <td>92328</td>\n",
       "      <td>92378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>feature_constitution75</td>\n",
       "      <td>100182</td>\n",
       "      <td>100109</td>\n",
       "      <td>101255</td>\n",
       "      <td>100109</td>\n",
       "      <td>100153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>feature_constitution76</td>\n",
       "      <td>98949</td>\n",
       "      <td>98885</td>\n",
       "      <td>106157</td>\n",
       "      <td>98885</td>\n",
       "      <td>98932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>feature_constitution77</td>\n",
       "      <td>100014</td>\n",
       "      <td>99938</td>\n",
       "      <td>101928</td>\n",
       "      <td>99938</td>\n",
       "      <td>99990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>feature_constitution78</td>\n",
       "      <td>92938</td>\n",
       "      <td>92863</td>\n",
       "      <td>130235</td>\n",
       "      <td>92863</td>\n",
       "      <td>92909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>feature_constitution79</td>\n",
       "      <td>99340</td>\n",
       "      <td>99265</td>\n",
       "      <td>104614</td>\n",
       "      <td>99265</td>\n",
       "      <td>99324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>feature_constitution80</td>\n",
       "      <td>94282</td>\n",
       "      <td>94203</td>\n",
       "      <td>124870</td>\n",
       "      <td>94203</td>\n",
       "      <td>94250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>feature_constitution81</td>\n",
       "      <td>99172</td>\n",
       "      <td>99103</td>\n",
       "      <td>105284</td>\n",
       "      <td>99103</td>\n",
       "      <td>99146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>feature_constitution82</td>\n",
       "      <td>99972</td>\n",
       "      <td>99893</td>\n",
       "      <td>102108</td>\n",
       "      <td>99893</td>\n",
       "      <td>99942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>feature_constitution83</td>\n",
       "      <td>98966</td>\n",
       "      <td>98901</td>\n",
       "      <td>106092</td>\n",
       "      <td>98901</td>\n",
       "      <td>98948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>feature_constitution84</td>\n",
       "      <td>94282</td>\n",
       "      <td>94203</td>\n",
       "      <td>124872</td>\n",
       "      <td>94203</td>\n",
       "      <td>94248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>feature_constitution85</td>\n",
       "      <td>100262</td>\n",
       "      <td>100190</td>\n",
       "      <td>100932</td>\n",
       "      <td>100190</td>\n",
       "      <td>100234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>feature_constitution86</td>\n",
       "      <td>98119</td>\n",
       "      <td>98045</td>\n",
       "      <td>109511</td>\n",
       "      <td>98045</td>\n",
       "      <td>98088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>feature_constitution87</td>\n",
       "      <td>95770</td>\n",
       "      <td>95687</td>\n",
       "      <td>118918</td>\n",
       "      <td>95687</td>\n",
       "      <td>95746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>feature_constitution88</td>\n",
       "      <td>92519</td>\n",
       "      <td>92456</td>\n",
       "      <td>131877</td>\n",
       "      <td>92456</td>\n",
       "      <td>92500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>feature_constitution89</td>\n",
       "      <td>98949</td>\n",
       "      <td>98885</td>\n",
       "      <td>106157</td>\n",
       "      <td>98885</td>\n",
       "      <td>98932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>feature_constitution90</td>\n",
       "      <td>92519</td>\n",
       "      <td>92456</td>\n",
       "      <td>131877</td>\n",
       "      <td>92456</td>\n",
       "      <td>92500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>feature_constitution91</td>\n",
       "      <td>99250</td>\n",
       "      <td>99172</td>\n",
       "      <td>104986</td>\n",
       "      <td>99172</td>\n",
       "      <td>99228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>feature_constitution92</td>\n",
       "      <td>99824</td>\n",
       "      <td>99749</td>\n",
       "      <td>102688</td>\n",
       "      <td>99749</td>\n",
       "      <td>99798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>feature_constitution93</td>\n",
       "      <td>89443</td>\n",
       "      <td>89365</td>\n",
       "      <td>144221</td>\n",
       "      <td>89365</td>\n",
       "      <td>89414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>feature_constitution94</td>\n",
       "      <td>98119</td>\n",
       "      <td>98045</td>\n",
       "      <td>109511</td>\n",
       "      <td>98045</td>\n",
       "      <td>98088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>feature_constitution95</td>\n",
       "      <td>100265</td>\n",
       "      <td>100204</td>\n",
       "      <td>100888</td>\n",
       "      <td>100204</td>\n",
       "      <td>100247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>feature_constitution96</td>\n",
       "      <td>92193</td>\n",
       "      <td>92130</td>\n",
       "      <td>133187</td>\n",
       "      <td>92130</td>\n",
       "      <td>92168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>feature_constitution97</td>\n",
       "      <td>91871</td>\n",
       "      <td>91801</td>\n",
       "      <td>134481</td>\n",
       "      <td>91801</td>\n",
       "      <td>91854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>feature_constitution98</td>\n",
       "      <td>100018</td>\n",
       "      <td>99946</td>\n",
       "      <td>101902</td>\n",
       "      <td>99946</td>\n",
       "      <td>99996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>feature_constitution99</td>\n",
       "      <td>99824</td>\n",
       "      <td>99749</td>\n",
       "      <td>102688</td>\n",
       "      <td>99749</td>\n",
       "      <td>99798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>feature_constitution100</td>\n",
       "      <td>98966</td>\n",
       "      <td>98901</td>\n",
       "      <td>106092</td>\n",
       "      <td>98901</td>\n",
       "      <td>98948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>feature_constitution101</td>\n",
       "      <td>100160</td>\n",
       "      <td>100090</td>\n",
       "      <td>101331</td>\n",
       "      <td>100090</td>\n",
       "      <td>100137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>feature_constitution102</td>\n",
       "      <td>99250</td>\n",
       "      <td>99172</td>\n",
       "      <td>104986</td>\n",
       "      <td>99172</td>\n",
       "      <td>99228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>feature_constitution103</td>\n",
       "      <td>92075</td>\n",
       "      <td>92003</td>\n",
       "      <td>133672</td>\n",
       "      <td>92003</td>\n",
       "      <td>92055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>feature_constitution104</td>\n",
       "      <td>91585</td>\n",
       "      <td>91512</td>\n",
       "      <td>135648</td>\n",
       "      <td>91512</td>\n",
       "      <td>91551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>feature_constitution105</td>\n",
       "      <td>99979</td>\n",
       "      <td>99907</td>\n",
       "      <td>102048</td>\n",
       "      <td>99907</td>\n",
       "      <td>99967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>feature_constitution106</td>\n",
       "      <td>100182</td>\n",
       "      <td>100109</td>\n",
       "      <td>101255</td>\n",
       "      <td>100109</td>\n",
       "      <td>100153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>feature_constitution107</td>\n",
       "      <td>91871</td>\n",
       "      <td>91801</td>\n",
       "      <td>134481</td>\n",
       "      <td>91801</td>\n",
       "      <td>91854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>feature_constitution108</td>\n",
       "      <td>91528</td>\n",
       "      <td>91465</td>\n",
       "      <td>135839</td>\n",
       "      <td>91465</td>\n",
       "      <td>91511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>feature_constitution109</td>\n",
       "      <td>98046</td>\n",
       "      <td>97968</td>\n",
       "      <td>109802</td>\n",
       "      <td>97968</td>\n",
       "      <td>98024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>feature_constitution110</td>\n",
       "      <td>100182</td>\n",
       "      <td>100111</td>\n",
       "      <td>101251</td>\n",
       "      <td>100111</td>\n",
       "      <td>100153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>feature_constitution111</td>\n",
       "      <td>98676</td>\n",
       "      <td>98611</td>\n",
       "      <td>107258</td>\n",
       "      <td>98611</td>\n",
       "      <td>98652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>feature_constitution112</td>\n",
       "      <td>99278</td>\n",
       "      <td>99206</td>\n",
       "      <td>104862</td>\n",
       "      <td>99206</td>\n",
       "      <td>99256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>feature_constitution113</td>\n",
       "      <td>98046</td>\n",
       "      <td>97968</td>\n",
       "      <td>109802</td>\n",
       "      <td>97968</td>\n",
       "      <td>98024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>feature_constitution114</td>\n",
       "      <td>98853</td>\n",
       "      <td>98790</td>\n",
       "      <td>106542</td>\n",
       "      <td>98790</td>\n",
       "      <td>98833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>feature_wisdom1</td>\n",
       "      <td>100407</td>\n",
       "      <td>100338</td>\n",
       "      <td>100337</td>\n",
       "      <td>100338</td>\n",
       "      <td>100388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>feature_wisdom2</td>\n",
       "      <td>99813</td>\n",
       "      <td>99738</td>\n",
       "      <td>102731</td>\n",
       "      <td>99738</td>\n",
       "      <td>99788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>feature_wisdom3</td>\n",
       "      <td>100049</td>\n",
       "      <td>99981</td>\n",
       "      <td>101768</td>\n",
       "      <td>99981</td>\n",
       "      <td>100029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>feature_wisdom4</td>\n",
       "      <td>97081</td>\n",
       "      <td>97015</td>\n",
       "      <td>113637</td>\n",
       "      <td>97015</td>\n",
       "      <td>97060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>feature_wisdom5</td>\n",
       "      <td>98750</td>\n",
       "      <td>98674</td>\n",
       "      <td>106980</td>\n",
       "      <td>98674</td>\n",
       "      <td>98730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>feature_wisdom6</td>\n",
       "      <td>89026</td>\n",
       "      <td>88962</td>\n",
       "      <td>145856</td>\n",
       "      <td>88962</td>\n",
       "      <td>89002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>feature_wisdom7</td>\n",
       "      <td>99813</td>\n",
       "      <td>99738</td>\n",
       "      <td>102731</td>\n",
       "      <td>99738</td>\n",
       "      <td>99788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>feature_wisdom8</td>\n",
       "      <td>98840</td>\n",
       "      <td>98764</td>\n",
       "      <td>106618</td>\n",
       "      <td>98764</td>\n",
       "      <td>98822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>feature_wisdom9</td>\n",
       "      <td>100349</td>\n",
       "      <td>100270</td>\n",
       "      <td>100597</td>\n",
       "      <td>100270</td>\n",
       "      <td>100322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>feature_wisdom10</td>\n",
       "      <td>98119</td>\n",
       "      <td>98045</td>\n",
       "      <td>109511</td>\n",
       "      <td>98045</td>\n",
       "      <td>98088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>feature_wisdom11</td>\n",
       "      <td>89026</td>\n",
       "      <td>88962</td>\n",
       "      <td>145856</td>\n",
       "      <td>88962</td>\n",
       "      <td>89002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>feature_wisdom12</td>\n",
       "      <td>100310</td>\n",
       "      <td>100244</td>\n",
       "      <td>100729</td>\n",
       "      <td>100244</td>\n",
       "      <td>100281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>feature_wisdom13</td>\n",
       "      <td>95404</td>\n",
       "      <td>95340</td>\n",
       "      <td>120342</td>\n",
       "      <td>95340</td>\n",
       "      <td>95382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>feature_wisdom14</td>\n",
       "      <td>100407</td>\n",
       "      <td>100338</td>\n",
       "      <td>100337</td>\n",
       "      <td>100338</td>\n",
       "      <td>100388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>feature_wisdom15</td>\n",
       "      <td>100150</td>\n",
       "      <td>100085</td>\n",
       "      <td>101359</td>\n",
       "      <td>100085</td>\n",
       "      <td>100129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>feature_wisdom16</td>\n",
       "      <td>97081</td>\n",
       "      <td>97015</td>\n",
       "      <td>113637</td>\n",
       "      <td>97015</td>\n",
       "      <td>97060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>feature_wisdom17</td>\n",
       "      <td>100407</td>\n",
       "      <td>100338</td>\n",
       "      <td>100337</td>\n",
       "      <td>100338</td>\n",
       "      <td>100388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>feature_wisdom18</td>\n",
       "      <td>99178</td>\n",
       "      <td>99099</td>\n",
       "      <td>105285</td>\n",
       "      <td>99099</td>\n",
       "      <td>99147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>feature_wisdom19</td>\n",
       "      <td>98119</td>\n",
       "      <td>98045</td>\n",
       "      <td>109511</td>\n",
       "      <td>98045</td>\n",
       "      <td>98088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>feature_wisdom20</td>\n",
       "      <td>100407</td>\n",
       "      <td>100338</td>\n",
       "      <td>100337</td>\n",
       "      <td>100338</td>\n",
       "      <td>100388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>feature_wisdom21</td>\n",
       "      <td>97693</td>\n",
       "      <td>97623</td>\n",
       "      <td>111202</td>\n",
       "      <td>97623</td>\n",
       "      <td>97667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>feature_wisdom22</td>\n",
       "      <td>100349</td>\n",
       "      <td>100270</td>\n",
       "      <td>100597</td>\n",
       "      <td>100270</td>\n",
       "      <td>100322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>feature_wisdom23</td>\n",
       "      <td>73440</td>\n",
       "      <td>73369</td>\n",
       "      <td>208214</td>\n",
       "      <td>73369</td>\n",
       "      <td>73416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>feature_wisdom24</td>\n",
       "      <td>93744</td>\n",
       "      <td>93665</td>\n",
       "      <td>127016</td>\n",
       "      <td>93665</td>\n",
       "      <td>93718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>feature_wisdom25</td>\n",
       "      <td>99178</td>\n",
       "      <td>99099</td>\n",
       "      <td>105285</td>\n",
       "      <td>99099</td>\n",
       "      <td>99147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>feature_wisdom26</td>\n",
       "      <td>98840</td>\n",
       "      <td>98764</td>\n",
       "      <td>106618</td>\n",
       "      <td>98764</td>\n",
       "      <td>98822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>feature_wisdom27</td>\n",
       "      <td>100150</td>\n",
       "      <td>100085</td>\n",
       "      <td>101359</td>\n",
       "      <td>100085</td>\n",
       "      <td>100129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>feature_wisdom28</td>\n",
       "      <td>97693</td>\n",
       "      <td>97623</td>\n",
       "      <td>111202</td>\n",
       "      <td>97623</td>\n",
       "      <td>97667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>feature_wisdom29</td>\n",
       "      <td>100407</td>\n",
       "      <td>100338</td>\n",
       "      <td>100337</td>\n",
       "      <td>100338</td>\n",
       "      <td>100388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>feature_wisdom30</td>\n",
       "      <td>97081</td>\n",
       "      <td>97015</td>\n",
       "      <td>113637</td>\n",
       "      <td>97015</td>\n",
       "      <td>97060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>feature_wisdom31</td>\n",
       "      <td>99941</td>\n",
       "      <td>99869</td>\n",
       "      <td>102209</td>\n",
       "      <td>99869</td>\n",
       "      <td>99920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>feature_wisdom32</td>\n",
       "      <td>73440</td>\n",
       "      <td>73369</td>\n",
       "      <td>208214</td>\n",
       "      <td>73369</td>\n",
       "      <td>73416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>feature_wisdom33</td>\n",
       "      <td>93744</td>\n",
       "      <td>93665</td>\n",
       "      <td>127016</td>\n",
       "      <td>93665</td>\n",
       "      <td>93718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>feature_wisdom34</td>\n",
       "      <td>95404</td>\n",
       "      <td>95340</td>\n",
       "      <td>120342</td>\n",
       "      <td>95340</td>\n",
       "      <td>95382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>feature_wisdom35</td>\n",
       "      <td>100407</td>\n",
       "      <td>100338</td>\n",
       "      <td>100337</td>\n",
       "      <td>100338</td>\n",
       "      <td>100388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>feature_wisdom36</td>\n",
       "      <td>99587</td>\n",
       "      <td>99521</td>\n",
       "      <td>103610</td>\n",
       "      <td>99521</td>\n",
       "      <td>99569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>feature_wisdom37</td>\n",
       "      <td>99941</td>\n",
       "      <td>99869</td>\n",
       "      <td>102209</td>\n",
       "      <td>99869</td>\n",
       "      <td>99920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>feature_wisdom38</td>\n",
       "      <td>100147</td>\n",
       "      <td>100079</td>\n",
       "      <td>101374</td>\n",
       "      <td>100079</td>\n",
       "      <td>100129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>feature_wisdom39</td>\n",
       "      <td>100147</td>\n",
       "      <td>100079</td>\n",
       "      <td>101374</td>\n",
       "      <td>100079</td>\n",
       "      <td>100129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>feature_wisdom40</td>\n",
       "      <td>99127</td>\n",
       "      <td>99054</td>\n",
       "      <td>105472</td>\n",
       "      <td>99054</td>\n",
       "      <td>99101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>feature_wisdom41</td>\n",
       "      <td>98750</td>\n",
       "      <td>98674</td>\n",
       "      <td>106980</td>\n",
       "      <td>98674</td>\n",
       "      <td>98730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>feature_wisdom42</td>\n",
       "      <td>99587</td>\n",
       "      <td>99521</td>\n",
       "      <td>103610</td>\n",
       "      <td>99521</td>\n",
       "      <td>99569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>feature_wisdom43</td>\n",
       "      <td>100049</td>\n",
       "      <td>99981</td>\n",
       "      <td>101768</td>\n",
       "      <td>99981</td>\n",
       "      <td>100029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>feature_wisdom44</td>\n",
       "      <td>99127</td>\n",
       "      <td>99054</td>\n",
       "      <td>105472</td>\n",
       "      <td>99054</td>\n",
       "      <td>99101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>feature_wisdom45</td>\n",
       "      <td>97081</td>\n",
       "      <td>97015</td>\n",
       "      <td>113637</td>\n",
       "      <td>97015</td>\n",
       "      <td>97060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>feature_wisdom46</td>\n",
       "      <td>100310</td>\n",
       "      <td>100244</td>\n",
       "      <td>100729</td>\n",
       "      <td>100244</td>\n",
       "      <td>100281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>target</td>\n",
       "      <td>25016</td>\n",
       "      <td>100053</td>\n",
       "      <td>251677</td>\n",
       "      <td>100045</td>\n",
       "      <td>25017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feature    0.00    0.25    0.50    0.75    1.00\n",
       "0      feature_intelligence1  100407  100338  100337  100338  100388\n",
       "1      feature_intelligence2  100406  100337  100343  100337  100385\n",
       "2      feature_intelligence3  100406  100337  100343  100337  100385\n",
       "3      feature_intelligence4  100407  100338  100337  100338  100388\n",
       "4      feature_intelligence5  100404  100333  100357  100333  100381\n",
       "5      feature_intelligence6  100404  100333  100357  100333  100381\n",
       "6      feature_intelligence7  100404  100333  100357  100333  100381\n",
       "7      feature_intelligence8  100407  100338  100337  100338  100388\n",
       "8      feature_intelligence9   99558   99496  103720   99496   99538\n",
       "9     feature_intelligence10   99558   99496  103720   99496   99538\n",
       "10    feature_intelligence11  100407  100338  100337  100338  100388\n",
       "11    feature_intelligence12  100404  100333  100357  100333  100381\n",
       "12         feature_charisma1  100066   99997  101714   99997  100034\n",
       "13         feature_charisma2   90119   90058  141478   90058   90095\n",
       "14         feature_charisma3   91446   91369  136204   91369   91420\n",
       "15         feature_charisma4   92051   91981  133767   91981   92028\n",
       "16         feature_charisma5   78943   78862  186222   78862   78919\n",
       "17         feature_charisma6  100082  100006  101661  100006  100053\n",
       "18         feature_charisma7   82751   82681  170970   82681   82725\n",
       "19         feature_charisma8   68183   68112  229244   68112   68157\n",
       "20         feature_charisma9  100334  100272  100610  100272  100320\n",
       "21        feature_charisma10   97491   97412  112025   97412   97468\n",
       "22        feature_charisma11   94493   94430  123983   94430   94472\n",
       "23        feature_charisma12   94705   94639  123140   94639   94685\n",
       "24        feature_charisma13   92874   92802  130479   92802   92851\n",
       "25        feature_charisma14   91050   90982  137772   90982   91022\n",
       "26        feature_charisma15   68183   68112  229244   68112   68157\n",
       "27        feature_charisma16   91446   91376  136187   91376   91423\n",
       "28        feature_charisma17   92051   91981  133767   91981   92028\n",
       "29        feature_charisma18  100108  100027  101564  100027  100082\n",
       "30        feature_charisma19  100066   99997  101714   99997  100034\n",
       "31        feature_charisma20   94561   94493  123719   94493   94542\n",
       "32        feature_charisma21   93928   93862  126245   93862   93911\n",
       "33        feature_charisma22   66675   66600  235279   66600   66654\n",
       "34        feature_charisma23   89447   89378  144181   89378   89424\n",
       "35        feature_charisma24   90119   90058  141478   90058   90095\n",
       "36        feature_charisma25   56561   56498  275708   56498   56543\n",
       "37        feature_charisma26   92679   92606  131257   92606   92660\n",
       "38        feature_charisma27   66754   66689  234946   66689   66730\n",
       "39        feature_charisma28   95331   95258  120654   95258   95307\n",
       "40        feature_charisma29   93023   92953  129878   92953   93001\n",
       "41        feature_charisma30   95168   95092  121315   95092   95141\n",
       "42        feature_charisma31   99547   99475  103787   99475   99524\n",
       "43        feature_charisma32   76228   76156  197062   76156   76206\n",
       "44        feature_charisma33   91050   90982  137772   90982   91022\n",
       "45        feature_charisma34  100035   99962  101839   99962  100010\n",
       "46        feature_charisma35   91446   91376  136187   91376   91423\n",
       "47        feature_charisma36   93928   93862  126245   93862   93911\n",
       "48        feature_charisma37   98019   97947  109905   97947   97990\n",
       "49        feature_charisma38   95168   95092  121315   95092   95141\n",
       "50        feature_charisma39   89447   89378  144181   89378   89424\n",
       "51        feature_charisma40  100108  100040  101535  100040  100085\n",
       "52        feature_charisma41   72756   72682  210957   72682   72731\n",
       "53        feature_charisma42   91735   91668  135024   91668   91713\n",
       "54        feature_charisma43   99479   99414  104043   99414   99458\n",
       "55        feature_charisma44   98059   97986  109742   97986   98035\n",
       "56        feature_charisma45   91446   91369  136204   91369   91420\n",
       "57        feature_charisma46   99816   99753  102699   99753   99787\n",
       "58        feature_charisma47   56561   56498  275708   56498   56543\n",
       "59        feature_charisma48   76228   76156  197062   76156   76206\n",
       "60        feature_charisma49   66604   66531  235563   66531   66579\n",
       "61        feature_charisma50   92874   92802  130479   92802   92851\n",
       "62        feature_charisma51   99547   99475  103787   99475   99524\n",
       "63        feature_charisma52   91620   91546  135502   91546   91594\n",
       "64        feature_charisma53   95331   95258  120654   95258   95307\n",
       "65        feature_charisma54  100082  100006  101661  100006  100053\n",
       "66        feature_charisma55  100035   99962  101839   99962  100010\n",
       "67        feature_charisma56   67508   67446  231924   67446   67484\n",
       "68        feature_charisma57  100407  100338  100337  100338  100388\n",
       "69        feature_charisma58   94493   94430  123983   94430   94472\n",
       "70        feature_charisma59   72756   72682  210957   72682   72731\n",
       "71        feature_charisma60   66675   66600  235279   66600   66654\n",
       "72        feature_charisma61  100108  100040  101535  100040  100085\n",
       "73        feature_charisma62   91620   91546  135502   91546   91594\n",
       "74        feature_charisma63   99982   99907  102054   99907   99958\n",
       "75        feature_charisma64   94561   94493  123719   94493   94542\n",
       "76        feature_charisma65   67508   67446  231924   67446   67484\n",
       "77        feature_charisma66   99816   99753  102699   99753   99787\n",
       "78        feature_charisma67   92679   92606  131257   92606   92660\n",
       "79        feature_charisma68   88528   88450  147885   88450   88495\n",
       "80        feature_charisma69  100334  100272  100610  100272  100320\n",
       "81        feature_charisma70   99479   99414  104043   99414   99458\n",
       "82        feature_charisma71   93023   92953  129878   92953   93001\n",
       "83        feature_charisma72   82751   82681  170970   82681   82725\n",
       "84        feature_charisma73   66604   66531  235563   66531   66579\n",
       "85        feature_charisma74   98059   97986  109742   97986   98035\n",
       "86        feature_charisma75   91735   91668  135024   91668   91713\n",
       "87        feature_charisma76  100108  100027  101564  100027  100082\n",
       "88        feature_charisma77   66754   66689  234946   66689   66730\n",
       "89        feature_charisma78   97491   97412  112025   97412   97468\n",
       "90        feature_charisma79   78943   78862  186222   78862   78919\n",
       "91        feature_charisma80   94705   94639  123140   94639   94685\n",
       "92        feature_charisma81   98019   97947  109905   97947   97990\n",
       "93        feature_charisma82   88528   88450  147885   88450   88495\n",
       "94        feature_charisma83  100407  100338  100337  100338  100388\n",
       "95        feature_charisma84   95291   95220  120810   95220   95267\n",
       "96        feature_charisma85   99982   99907  102054   99907   99958\n",
       "97        feature_charisma86   95291   95220  120810   95220   95267\n",
       "98         feature_strength1   99871   99807  102474   99807   99849\n",
       "99         feature_strength2   91505   91432  135960   91432   91479\n",
       "100        feature_strength3  100145  100078  101383  100078  100124\n",
       "101        feature_strength4   99871   99807  102474   99807   99849\n",
       "102        feature_strength5   92103   92031  133560   92031   92083\n",
       "103        feature_strength6   64881   64815  242436   64815   64861\n",
       "104        feature_strength7   71990   71911  214029   71911   71967\n",
       "105        feature_strength8   99897   99816  102411   99816   99868\n",
       "106        feature_strength9   99750   99690  102949   99690   99729\n",
       "107       feature_strength10  100094  100016  101621  100016  100061\n",
       "108       feature_strength11   98250   98172  108986   98172   98228\n",
       "109       feature_strength12   92710   92633  131145   92633   92687\n",
       "110       feature_strength13   92103   92031  133560   92031   92083\n",
       "111       feature_strength14   99233   99160  105051   99160   99204\n",
       "112       feature_strength15   99850   99767  102597   99767   99827\n",
       "113       feature_strength16   98008   97941  109930   97941   97988\n",
       "114       feature_strength17   64881   64815  242436   64815   64861\n",
       "115       feature_strength18   86431   86352  156272   86352   86401\n",
       "116       feature_strength19  100145  100078  101383  100078  100124\n",
       "117       feature_strength20   26153   26069  397393   26069   26124\n",
       "118       feature_strength21   98250   98172  108986   98172   98228\n",
       "119       feature_strength22   99750   99690  102949   99690   99729\n",
       "120       feature_strength23   98008   97941  109930   97941   97988\n",
       "121       feature_strength24   89026   88963  145854   88963   89002\n",
       "122       feature_strength25   93012   92951  129902   92951   92992\n",
       "123       feature_strength26   73888   73814  206429   73814   73863\n",
       "124       feature_strength27   99850   99767  102597   99767   99827\n",
       "125       feature_strength28   99897   99816  102411   99816   99868\n",
       "126       feature_strength29   89026   88963  145854   88963   89002\n",
       "127       feature_strength30   92710   92633  131145   92633   92687\n",
       "128       feature_strength31   93012   92951  129902   92951   92992\n",
       "129       feature_strength32   91505   91432  135960   91432   91479\n",
       "130       feature_strength33   73888   73814  206429   73814   73863\n",
       "131       feature_strength34   99233   99160  105051   99160   99204\n",
       "132       feature_strength35   71990   71911  214029   71911   71967\n",
       "133       feature_strength36  100094  100016  101621  100016  100061\n",
       "134       feature_strength37   86431   86352  156272   86352   86401\n",
       "135       feature_strength38   26153   26069  397393   26069   26124\n",
       "136       feature_dexterity1   99814   99737  102730   99737   99790\n",
       "137       feature_dexterity2   99860   99791  102526   99791   99840\n",
       "138       feature_dexterity3  100406  100337  100342  100337  100386\n",
       "139       feature_dexterity4  100407  100338  100337  100338  100388\n",
       "140       feature_dexterity5  100405  100333  100356  100333  100381\n",
       "141       feature_dexterity6  100404  100333  100357  100333  100381\n",
       "142       feature_dexterity7  100407  100338  100337  100338  100388\n",
       "143       feature_dexterity8  100406  100337  100342  100337  100386\n",
       "144       feature_dexterity9   99814   99737  102730   99737   99790\n",
       "145      feature_dexterity10   99860   99791  102526   99791   99840\n",
       "146      feature_dexterity11  100404  100333  100357  100333  100381\n",
       "147      feature_dexterity12  100404  100333  100357  100333  100381\n",
       "148      feature_dexterity13  100405  100333  100356  100333  100381\n",
       "149      feature_dexterity14  100404  100333  100357  100333  100381\n",
       "150    feature_constitution1   94282   94203  124870   94203   94250\n",
       "151    feature_constitution2   95936   95868  118220   95868   95916\n",
       "152    feature_constitution3   96073   96001  117682   96001   96051\n",
       "153    feature_constitution4  100005   99932  101956   99932   99983\n",
       "154    feature_constitution5   92401   92328  132373   92328   92378\n",
       "155    feature_constitution6   92006   91926  133971   91926   91979\n",
       "156    feature_constitution7   99942   99866  102219   99866   99915\n",
       "157    feature_constitution8   92805   92731  130766   92731   92775\n",
       "158    feature_constitution9   99944   99869  102206   99869   99920\n",
       "159   feature_constitution10   92006   91926  133971   91926   91979\n",
       "160   feature_constitution11   96134   96064  117441   96064   96105\n",
       "161   feature_constitution12  100160  100090  101331  100090  100137\n",
       "162   feature_constitution13   99340   99265  104614   99265   99324\n",
       "163   feature_constitution14   92583   92507  131660   92507   92551\n",
       "164   feature_constitution15   95249   95184  120972   95184   95219\n",
       "165   feature_constitution16   98965   98899  106103   98899   98942\n",
       "166   feature_constitution17   92805   92731  130766   92731   92775\n",
       "167   feature_constitution18   92276   92202  132879   92202   92249\n",
       "168   feature_constitution19   92938   92863  130235   92863   92909\n",
       "169   feature_constitution20   95756   95687  118944   95687   95734\n",
       "170   feature_constitution21   88738   88665  147025   88665   88715\n",
       "171   feature_constitution22  100015   99942  101918   99942   99991\n",
       "172   feature_constitution23   96073   96001  117682   96001   96051\n",
       "173   feature_constitution24   99972   99893  102108   99893   99942\n",
       "174   feature_constitution25  100015   99942  101918   99942   99991\n",
       "175   feature_constitution26   95756   95687  118944   95687   95734\n",
       "176   feature_constitution27   99942   99866  102219   99866   99915\n",
       "177   feature_constitution28   96134   96064  117441   96064   96105\n",
       "178   feature_constitution29  100160  100090  101331  100090  100137\n",
       "179   feature_constitution30   89726   89655  143062   89655   89710\n",
       "180   feature_constitution31   91585   91512  135648   91512   91551\n",
       "181   feature_constitution32   99827   99759  102658   99759   99805\n",
       "182   feature_constitution33   99944   99869  102206   99869   99920\n",
       "183   feature_constitution34  100247  100170  101002  100170  100219\n",
       "184   feature_constitution35   99979   99907  102048   99907   99967\n",
       "185   feature_constitution36  100247  100170  101002  100170  100219\n",
       "186   feature_constitution37   95249   95184  120972   95184   95219\n",
       "187   feature_constitution38   98853   98790  106542   98790   98833\n",
       "188   feature_constitution39   92276   92202  132879   92202   92249\n",
       "189   feature_constitution40   98965   98899  106103   98899   98942\n",
       "190   feature_constitution41   91528   91465  135839   91465   91511\n",
       "191   feature_constitution42   89726   89655  143062   89655   89710\n",
       "192   feature_constitution43  100262  100190  100932  100190  100234\n",
       "193   feature_constitution44   89404   89337  144354   89337   89376\n",
       "194   feature_constitution45  100213  100138  101119  100138  100200\n",
       "195   feature_constitution46   99278   99206  104862   99206   99256\n",
       "196   feature_constitution47  100213  100138  101119  100138  100200\n",
       "197   feature_constitution48  100014   99938  101928   99938   99990\n",
       "198   feature_constitution49  100005   99932  101956   99932   99983\n",
       "199   feature_constitution50  100160  100090  101331  100090  100137\n",
       "200   feature_constitution51   92583   92507  131660   92507   92551\n",
       "201   feature_constitution52  100149  100078  101385  100078  100118\n",
       "202   feature_constitution53   99426   99354  104271   99354   99403\n",
       "203   feature_constitution54  100265  100204  100888  100204  100247\n",
       "204   feature_constitution55   89404   89337  144354   89337   89376\n",
       "205   feature_constitution56  100182  100111  101251  100111  100153\n",
       "206   feature_constitution57   99827   99759  102658   99759   99805\n",
       "207   feature_constitution58   99881   99809  102451   99809   99858\n",
       "208   feature_constitution59   99172   99103  105284   99103   99146\n",
       "209   feature_constitution60   95770   95687  118918   95687   95746\n",
       "210   feature_constitution61   92193   92130  133187   92130   92168\n",
       "211   feature_constitution62   94282   94203  124872   94203   94248\n",
       "212   feature_constitution63   99288   99225  104805   99225   99265\n",
       "213   feature_constitution64  100018   99946  101902   99946   99996\n",
       "214   feature_constitution65   99288   99225  104805   99225   99265\n",
       "215   feature_constitution66   89443   89365  144221   89365   89414\n",
       "216   feature_constitution67   98676   98611  107258   98611   98652\n",
       "217   feature_constitution68   99881   99809  102451   99809   99858\n",
       "218   feature_constitution69  100149  100078  101385  100078  100118\n",
       "219   feature_constitution70   88738   88665  147025   88665   88715\n",
       "220   feature_constitution71   99426   99354  104271   99354   99403\n",
       "221   feature_constitution72   92075   92003  133672   92003   92055\n",
       "222   feature_constitution73   95936   95868  118220   95868   95916\n",
       "223   feature_constitution74   92401   92328  132373   92328   92378\n",
       "224   feature_constitution75  100182  100109  101255  100109  100153\n",
       "225   feature_constitution76   98949   98885  106157   98885   98932\n",
       "226   feature_constitution77  100014   99938  101928   99938   99990\n",
       "227   feature_constitution78   92938   92863  130235   92863   92909\n",
       "228   feature_constitution79   99340   99265  104614   99265   99324\n",
       "229   feature_constitution80   94282   94203  124870   94203   94250\n",
       "230   feature_constitution81   99172   99103  105284   99103   99146\n",
       "231   feature_constitution82   99972   99893  102108   99893   99942\n",
       "232   feature_constitution83   98966   98901  106092   98901   98948\n",
       "233   feature_constitution84   94282   94203  124872   94203   94248\n",
       "234   feature_constitution85  100262  100190  100932  100190  100234\n",
       "235   feature_constitution86   98119   98045  109511   98045   98088\n",
       "236   feature_constitution87   95770   95687  118918   95687   95746\n",
       "237   feature_constitution88   92519   92456  131877   92456   92500\n",
       "238   feature_constitution89   98949   98885  106157   98885   98932\n",
       "239   feature_constitution90   92519   92456  131877   92456   92500\n",
       "240   feature_constitution91   99250   99172  104986   99172   99228\n",
       "241   feature_constitution92   99824   99749  102688   99749   99798\n",
       "242   feature_constitution93   89443   89365  144221   89365   89414\n",
       "243   feature_constitution94   98119   98045  109511   98045   98088\n",
       "244   feature_constitution95  100265  100204  100888  100204  100247\n",
       "245   feature_constitution96   92193   92130  133187   92130   92168\n",
       "246   feature_constitution97   91871   91801  134481   91801   91854\n",
       "247   feature_constitution98  100018   99946  101902   99946   99996\n",
       "248   feature_constitution99   99824   99749  102688   99749   99798\n",
       "249  feature_constitution100   98966   98901  106092   98901   98948\n",
       "250  feature_constitution101  100160  100090  101331  100090  100137\n",
       "251  feature_constitution102   99250   99172  104986   99172   99228\n",
       "252  feature_constitution103   92075   92003  133672   92003   92055\n",
       "253  feature_constitution104   91585   91512  135648   91512   91551\n",
       "254  feature_constitution105   99979   99907  102048   99907   99967\n",
       "255  feature_constitution106  100182  100109  101255  100109  100153\n",
       "256  feature_constitution107   91871   91801  134481   91801   91854\n",
       "257  feature_constitution108   91528   91465  135839   91465   91511\n",
       "258  feature_constitution109   98046   97968  109802   97968   98024\n",
       "259  feature_constitution110  100182  100111  101251  100111  100153\n",
       "260  feature_constitution111   98676   98611  107258   98611   98652\n",
       "261  feature_constitution112   99278   99206  104862   99206   99256\n",
       "262  feature_constitution113   98046   97968  109802   97968   98024\n",
       "263  feature_constitution114   98853   98790  106542   98790   98833\n",
       "264          feature_wisdom1  100407  100338  100337  100338  100388\n",
       "265          feature_wisdom2   99813   99738  102731   99738   99788\n",
       "266          feature_wisdom3  100049   99981  101768   99981  100029\n",
       "267          feature_wisdom4   97081   97015  113637   97015   97060\n",
       "268          feature_wisdom5   98750   98674  106980   98674   98730\n",
       "269          feature_wisdom6   89026   88962  145856   88962   89002\n",
       "270          feature_wisdom7   99813   99738  102731   99738   99788\n",
       "271          feature_wisdom8   98840   98764  106618   98764   98822\n",
       "272          feature_wisdom9  100349  100270  100597  100270  100322\n",
       "273         feature_wisdom10   98119   98045  109511   98045   98088\n",
       "274         feature_wisdom11   89026   88962  145856   88962   89002\n",
       "275         feature_wisdom12  100310  100244  100729  100244  100281\n",
       "276         feature_wisdom13   95404   95340  120342   95340   95382\n",
       "277         feature_wisdom14  100407  100338  100337  100338  100388\n",
       "278         feature_wisdom15  100150  100085  101359  100085  100129\n",
       "279         feature_wisdom16   97081   97015  113637   97015   97060\n",
       "280         feature_wisdom17  100407  100338  100337  100338  100388\n",
       "281         feature_wisdom18   99178   99099  105285   99099   99147\n",
       "282         feature_wisdom19   98119   98045  109511   98045   98088\n",
       "283         feature_wisdom20  100407  100338  100337  100338  100388\n",
       "284         feature_wisdom21   97693   97623  111202   97623   97667\n",
       "285         feature_wisdom22  100349  100270  100597  100270  100322\n",
       "286         feature_wisdom23   73440   73369  208214   73369   73416\n",
       "287         feature_wisdom24   93744   93665  127016   93665   93718\n",
       "288         feature_wisdom25   99178   99099  105285   99099   99147\n",
       "289         feature_wisdom26   98840   98764  106618   98764   98822\n",
       "290         feature_wisdom27  100150  100085  101359  100085  100129\n",
       "291         feature_wisdom28   97693   97623  111202   97623   97667\n",
       "292         feature_wisdom29  100407  100338  100337  100338  100388\n",
       "293         feature_wisdom30   97081   97015  113637   97015   97060\n",
       "294         feature_wisdom31   99941   99869  102209   99869   99920\n",
       "295         feature_wisdom32   73440   73369  208214   73369   73416\n",
       "296         feature_wisdom33   93744   93665  127016   93665   93718\n",
       "297         feature_wisdom34   95404   95340  120342   95340   95382\n",
       "298         feature_wisdom35  100407  100338  100337  100338  100388\n",
       "299         feature_wisdom36   99587   99521  103610   99521   99569\n",
       "300         feature_wisdom37   99941   99869  102209   99869   99920\n",
       "301         feature_wisdom38  100147  100079  101374  100079  100129\n",
       "302         feature_wisdom39  100147  100079  101374  100079  100129\n",
       "303         feature_wisdom40   99127   99054  105472   99054   99101\n",
       "304         feature_wisdom41   98750   98674  106980   98674   98730\n",
       "305         feature_wisdom42   99587   99521  103610   99521   99569\n",
       "306         feature_wisdom43  100049   99981  101768   99981  100029\n",
       "307         feature_wisdom44   99127   99054  105472   99054   99101\n",
       "308         feature_wisdom45   97081   97015  113637   97015   97060\n",
       "309         feature_wisdom46  100310  100244  100729  100244  100281\n",
       "310                   target   25016  100053  251677  100045   25017"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_cnt_df = pd.DataFrame(data=val_cnt, columns=['feature','0.00','0.25','0.50','0.75','1.00'])\n",
    "value_cnt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MIKE\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.8085115469825217, 0.008696752441807207]]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Trial Using Random Forest###\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train = pd.read_parquet('X_train_080.gzip')\n",
    "X_test = pd.read_parquet('X_test_080.gzip')\n",
    "y_train = pd.read_pickle('y_train_080.pkl')\n",
    "y_test = pd.read_pickle('y_test_080.pkl')\n",
    "\n",
    "y_train = y_train.map({0.00:0, 0.25:1,0.50:2,0.75:3,1.00:4})\n",
    "y_test = y_test.map({0.00:0, 0.25:1,0.50:2,0.75:3,1.00:4})\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100,max_depth=9,class_weight=\"balanced\")\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "y_train_pred = pd.Series(y_train_pred)\n",
    "y_test_pred = pd.Series(y_test_pred)\n",
    "\n",
    "y_train_copy = y_train.copy()\n",
    "y_test_copy = y_test.copy()\n",
    "y_train_copy.reset_index(drop=True,inplace=True)\n",
    "y_test_copy.reset_index(drop=True,inplace=True)\n",
    "\n",
    "result=[]\n",
    "result.append([y_train_pred.corr(y_train_copy),y_test_pred.corr(y_test_copy)])\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03668479, 0.00253887, 0.00417715, 0.04377532, 0.0022244 ,\n",
       "       0.00263468, 0.00224495, 0.053721  , 0.00246782, 0.00475729,\n",
       "       0.01868307, 0.00201967, 0.00238041, 0.00220077, 0.00214972,\n",
       "       0.00230596, 0.00184013, 0.0020602 , 0.00196286, 0.00193081,\n",
       "       0.00230848, 0.00236357, 0.00277119, 0.00197197, 0.00215969,\n",
       "       0.00233149, 0.00189117, 0.002208  , 0.00236757, 0.00196624,\n",
       "       0.00214455, 0.00223689, 0.00280272, 0.00178128, 0.00226889,\n",
       "       0.00241804, 0.00188985, 0.00220722, 0.00199148, 0.0025376 ,\n",
       "       0.00213841, 0.0022176 , 0.0019444 , 0.00208435, 0.00225152,\n",
       "       0.00215866, 0.00216627, 0.00455311, 0.00177028, 0.00215759,\n",
       "       0.00178226, 0.00224132, 0.00207719, 0.00242065, 0.00255807,\n",
       "       0.00220677, 0.00247467, 0.00232015, 0.00193794, 0.00232066,\n",
       "       0.00197273, 0.00199869, 0.00213727, 0.00235981, 0.0023149 ,\n",
       "       0.00179141, 0.00188259, 0.00190503, 0.002217  , 0.00257069,\n",
       "       0.0022962 , 0.00218935, 0.00205031, 0.00189568, 0.00276154,\n",
       "       0.0024449 , 0.00225459, 0.00243649, 0.00191435, 0.00204946,\n",
       "       0.00247438, 0.00214206, 0.00198839, 0.0018714 , 0.00223432,\n",
       "       0.00209175, 0.0020358 , 0.0019836 , 0.0025161 , 0.00253747,\n",
       "       0.00242025, 0.00236679, 0.00177522, 0.00206644, 0.00243054,\n",
       "       0.00201706, 0.00267266, 0.00196914, 0.00210963, 0.00170421,\n",
       "       0.00430714, 0.00209796, 0.0026017 , 0.00206788, 0.00249503,\n",
       "       0.00190813, 0.00246658, 0.00423372, 0.00202477, 0.00427463,\n",
       "       0.00339897, 0.00268701, 0.00225379, 0.00240772, 0.00226773,\n",
       "       0.00198176, 0.0049282 , 0.00185031, 0.00193733, 0.00203969,\n",
       "       0.00277769, 0.00273157, 0.00282722, 0.00240105, 0.00221016,\n",
       "       0.00217127, 0.00344691, 0.0021114 , 0.00403768, 0.00235112,\n",
       "       0.00290924, 0.00283086, 0.00274295, 0.00268899, 0.00251466,\n",
       "       0.00143646, 0.00239329, 0.00455034, 0.00307772, 0.00479359,\n",
       "       0.00439508, 0.01025377, 0.00294166, 0.00372593, 0.00293943,\n",
       "       0.00270867, 0.01892262, 0.00795079, 0.00277547, 0.00419405,\n",
       "       0.00198359, 0.01117059, 0.00268062, 0.00233578, 0.00198159,\n",
       "       0.00243536, 0.00214522, 0.00203704, 0.00207817, 0.00233262,\n",
       "       0.00225663, 0.00407174, 0.00212118, 0.00222938, 0.0024828 ,\n",
       "       0.00235748, 0.00257894, 0.00206034, 0.00170686, 0.00216685,\n",
       "       0.00214311, 0.00158202, 0.00221784, 0.00210865, 0.00232157,\n",
       "       0.00245544, 0.00206232, 0.00200201, 0.00345751, 0.00218958,\n",
       "       0.00628276, 0.00204511, 0.00200483, 0.00318007, 0.00169624,\n",
       "       0.00350195, 0.00247664, 0.00219109, 0.00216351, 0.00224196,\n",
       "       0.00316218, 0.00238395, 0.00221812, 0.00507739, 0.00425723,\n",
       "       0.00215711, 0.0029546 , 0.00207518, 0.00228553, 0.00225267,\n",
       "       0.00227431, 0.00272756, 0.00185022, 0.00438139, 0.00984556,\n",
       "       0.00272186, 0.00205596, 0.00207829, 0.00209585, 0.00195184,\n",
       "       0.00213094, 0.0018234 , 0.00885444, 0.00175416, 0.00237077,\n",
       "       0.00255084, 0.0026325 , 0.00185269, 0.002389  , 0.00221038,\n",
       "       0.00236522, 0.00308096, 0.0034018 , 0.00206406, 0.00186179,\n",
       "       0.00242164, 0.00209885, 0.00186251, 0.00235646, 0.00267837,\n",
       "       0.00220772, 0.00175506, 0.00250936, 0.00234853, 0.00255657,\n",
       "       0.00217319, 0.00185898, 0.00225668, 0.00245677, 0.00324834,\n",
       "       0.00249373, 0.002047  , 0.00463122, 0.00212501, 0.00217697,\n",
       "       0.00230004, 0.00195195, 0.00194285, 0.00174562, 0.00211189,\n",
       "       0.00298601, 0.00222258, 0.00270261, 0.00458532, 0.00457102,\n",
       "       0.00243083, 0.00219164, 0.00426141, 0.00289496, 0.00193996,\n",
       "       0.00281121, 0.00204775, 0.00156889, 0.00227021, 0.00256408,\n",
       "       0.00236786, 0.00197523, 0.00301643, 0.00257172, 0.00231965,\n",
       "       0.00591512, 0.00285183, 0.00207257, 0.00670544, 0.00199288,\n",
       "       0.0020789 , 0.00340429, 0.01336006, 0.00440009, 0.00330616,\n",
       "       0.00201209, 0.00221686, 0.002363  , 0.00275836, 0.00252178,\n",
       "       0.0026094 , 0.0026109 , 0.00227539, 0.00231173, 0.00235012,\n",
       "       0.00252544, 0.00261387, 0.00492267, 0.00180434, 0.00226863,\n",
       "       0.00246571, 0.00224077, 0.00718761, 0.01222421, 0.00251493,\n",
       "       0.00215516, 0.00271886, 0.00255339, 0.00225703, 0.00222947,\n",
       "       0.00221446, 0.00209726, 0.00206083, 0.00197589, 0.00649955])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 5, 7, 8, 10, 11, 12, 17, 19, 22]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_remove = []\n",
    "\n",
    "for i,v in enumerate(importance):\n",
    "    if v <=0:\n",
    "        to_remove.append(i)\n",
    "        \n",
    "to_remove[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feature_intelligence1', 'feature_intelligence2',\n",
       "       'feature_intelligence3', 'feature_intelligence4',\n",
       "       'feature_intelligence5', 'feature_intelligence6',\n",
       "       'feature_intelligence7', 'feature_intelligence8',\n",
       "       'feature_intelligence9', 'feature_intelligence10',\n",
       "       ...\n",
       "       'feature_wisdom37', 'feature_wisdom38', 'feature_wisdom39',\n",
       "       'feature_wisdom40', 'feature_wisdom41', 'feature_wisdom42',\n",
       "       'feature_wisdom43', 'feature_wisdom44', 'feature_wisdom45',\n",
       "       'feature_wisdom46'],\n",
       "      dtype='object', length=310)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 5, 7, 8, 10, 11, 12, 17, 19, 22]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_remove[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_intelligence1</th>\n",
       "      <th>feature_intelligence2</th>\n",
       "      <th>feature_intelligence4</th>\n",
       "      <th>feature_intelligence5</th>\n",
       "      <th>feature_intelligence7</th>\n",
       "      <th>feature_intelligence10</th>\n",
       "      <th>feature_charisma2</th>\n",
       "      <th>feature_charisma3</th>\n",
       "      <th>feature_charisma4</th>\n",
       "      <th>feature_charisma5</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_wisdom30</th>\n",
       "      <th>feature_wisdom33</th>\n",
       "      <th>feature_wisdom34</th>\n",
       "      <th>feature_wisdom36</th>\n",
       "      <th>feature_wisdom37</th>\n",
       "      <th>feature_wisdom39</th>\n",
       "      <th>feature_wisdom41</th>\n",
       "      <th>feature_wisdom42</th>\n",
       "      <th>feature_wisdom43</th>\n",
       "      <th>feature_wisdom44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_intelligence1  feature_intelligence2  feature_intelligence4  \\\n",
       "0                   1.00                    0.0                   1.00   \n",
       "1                   0.75                    0.5                   0.75   \n",
       "\n",
       "   feature_intelligence5  feature_intelligence7  feature_intelligence10  \\\n",
       "0                   0.25                   0.75                    0.50   \n",
       "1                   0.00                   1.00                    0.25   \n",
       "\n",
       "   feature_charisma2  feature_charisma3  feature_charisma4  feature_charisma5  \\\n",
       "0                0.5               0.25                1.0               0.50   \n",
       "1                1.0               0.25                0.5               0.75   \n",
       "\n",
       "   ...  feature_wisdom30  feature_wisdom33  feature_wisdom34  \\\n",
       "0  ...              1.00              0.25              0.50   \n",
       "1  ...              0.25              0.75              0.25   \n",
       "\n",
       "   feature_wisdom36  feature_wisdom37  feature_wisdom39  feature_wisdom41  \\\n",
       "0              0.75              0.75              0.75               0.5   \n",
       "1              1.00              0.75              1.00               0.0   \n",
       "\n",
       "   feature_wisdom42  feature_wisdom43  feature_wisdom44  \n",
       "0               1.0              0.25              0.25  \n",
       "1               1.0              0.75              0.25  \n",
       "\n",
       "[2 rows x 155 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_remove = X.drop([x for x in X.columns[to_remove]],axis=1)\n",
    "X_remove.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 155)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_remove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (37500, 155)\n",
      "X_test:  (12500, 155)\n",
      "y_train:  (37500,)\n",
      "y_test:  (12500,)\n"
     ]
    }
   ],
   "source": [
    "#Train test split for feature importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_remove,y,test_size=0.25,random_state=123)\n",
    "\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.0040872\n",
      "Feature: 1, Score: 0.0007981\n",
      "Feature: 2, Score: -0.0130611\n",
      "Feature: 3, Score: 0.0079184\n",
      "Feature: 4, Score: 0.0052890\n",
      "Feature: 5, Score: 0.0052934\n",
      "Feature: 6, Score: -0.0026201\n",
      "Feature: 7, Score: -0.0030831\n",
      "Feature: 8, Score: 0.0059887\n",
      "Feature: 9, Score: 0.0032196\n",
      "Feature: 10, Score: 0.0042475\n",
      "Feature: 11, Score: -0.0105375\n",
      "Feature: 12, Score: 0.0022922\n",
      "Feature: 13, Score: 0.0147688\n",
      "Feature: 14, Score: -0.0067868\n",
      "Feature: 15, Score: 0.0059500\n",
      "Feature: 16, Score: 0.0010565\n",
      "Feature: 17, Score: 0.0007373\n",
      "Feature: 18, Score: 0.0045443\n",
      "Feature: 19, Score: -0.0088946\n",
      "Feature: 20, Score: -0.0023270\n",
      "Feature: 21, Score: 0.0047372\n",
      "Feature: 22, Score: 0.0003996\n",
      "Feature: 23, Score: 0.0036968\n",
      "Feature: 24, Score: 0.0055813\n",
      "Feature: 25, Score: 0.0041812\n",
      "Feature: 26, Score: 0.0082822\n",
      "Feature: 27, Score: -0.0059268\n",
      "Feature: 28, Score: 0.0059988\n",
      "Feature: 29, Score: -0.0004139\n",
      "Feature: 30, Score: 0.0012923\n",
      "Feature: 31, Score: 0.0038176\n",
      "Feature: 32, Score: 0.0070394\n",
      "Feature: 33, Score: -0.0000371\n",
      "Feature: 34, Score: 0.0077044\n",
      "Feature: 35, Score: 0.0059315\n",
      "Feature: 36, Score: -0.0034521\n",
      "Feature: 37, Score: 0.0041618\n",
      "Feature: 38, Score: -0.0015890\n",
      "Feature: 39, Score: 0.0063667\n",
      "Feature: 40, Score: -0.0054597\n",
      "Feature: 41, Score: 0.0032373\n",
      "Feature: 42, Score: 0.0032683\n",
      "Feature: 43, Score: 0.0000207\n",
      "Feature: 44, Score: -0.0013739\n",
      "Feature: 45, Score: 0.0092488\n",
      "Feature: 46, Score: 0.0019480\n",
      "Feature: 47, Score: -0.0020268\n",
      "Feature: 48, Score: -0.0000204\n",
      "Feature: 49, Score: 0.0117311\n",
      "Feature: 50, Score: 0.0060257\n",
      "Feature: 51, Score: -0.0062144\n",
      "Feature: 52, Score: -0.0076937\n",
      "Feature: 53, Score: 0.0010558\n",
      "Feature: 54, Score: 0.0050427\n",
      "Feature: 55, Score: -0.0022641\n",
      "Feature: 56, Score: 0.0154955\n",
      "Feature: 57, Score: -0.0025055\n",
      "Feature: 58, Score: 0.0135783\n",
      "Feature: 59, Score: -0.0043776\n",
      "Feature: 60, Score: -0.0045940\n",
      "Feature: 61, Score: -0.0006932\n",
      "Feature: 62, Score: 0.0058981\n",
      "Feature: 63, Score: 0.0067746\n",
      "Feature: 64, Score: -0.0004465\n",
      "Feature: 65, Score: -0.0066370\n",
      "Feature: 66, Score: -0.0009864\n",
      "Feature: 67, Score: 0.0018471\n",
      "Feature: 68, Score: 0.0024013\n",
      "Feature: 69, Score: 0.0179259\n",
      "Feature: 70, Score: -0.0087989\n",
      "Feature: 71, Score: 0.0022339\n",
      "Feature: 72, Score: -0.0095133\n",
      "Feature: 73, Score: -0.0203941\n",
      "Feature: 74, Score: -0.0123062\n",
      "Feature: 75, Score: 0.0054913\n",
      "Feature: 76, Score: 0.0020181\n",
      "Feature: 77, Score: -0.0090157\n",
      "Feature: 78, Score: 0.0062851\n",
      "Feature: 79, Score: 0.0058891\n",
      "Feature: 80, Score: -0.0041779\n",
      "Feature: 81, Score: 0.0024920\n",
      "Feature: 82, Score: 0.0067314\n",
      "Feature: 83, Score: -0.0024002\n",
      "Feature: 84, Score: 0.0024810\n",
      "Feature: 85, Score: 0.0021801\n",
      "Feature: 86, Score: -0.0048772\n",
      "Feature: 87, Score: -0.0063659\n",
      "Feature: 88, Score: -0.0008722\n",
      "Feature: 89, Score: 0.0043235\n",
      "Feature: 90, Score: -0.0005407\n",
      "Feature: 91, Score: -0.0006954\n",
      "Feature: 92, Score: -0.0018563\n",
      "Feature: 93, Score: -0.0044635\n",
      "Feature: 94, Score: -0.0082073\n",
      "Feature: 95, Score: -0.0047582\n",
      "Feature: 96, Score: -0.0013685\n",
      "Feature: 97, Score: -0.0009034\n",
      "Feature: 98, Score: 0.0087458\n",
      "Feature: 99, Score: -0.0039489\n",
      "Feature: 100, Score: -0.0055876\n",
      "Feature: 101, Score: 0.0113470\n",
      "Feature: 102, Score: -0.0039998\n",
      "Feature: 103, Score: -0.0137401\n",
      "Feature: 104, Score: -0.0071318\n",
      "Feature: 105, Score: 0.0065583\n",
      "Feature: 106, Score: 0.0131389\n",
      "Feature: 107, Score: 0.0048638\n",
      "Feature: 108, Score: -0.0038211\n",
      "Feature: 109, Score: 0.0137560\n",
      "Feature: 110, Score: -0.0055388\n",
      "Feature: 111, Score: 0.0002743\n",
      "Feature: 112, Score: 0.0033615\n",
      "Feature: 113, Score: -0.0051573\n",
      "Feature: 114, Score: 0.0041881\n",
      "Feature: 115, Score: -0.0027330\n",
      "Feature: 116, Score: 0.0014276\n",
      "Feature: 117, Score: 0.0030249\n",
      "Feature: 118, Score: -0.0003844\n",
      "Feature: 119, Score: -0.0047628\n",
      "Feature: 120, Score: 0.0002417\n",
      "Feature: 121, Score: 0.0036104\n",
      "Feature: 122, Score: -0.0030379\n",
      "Feature: 123, Score: 0.0054689\n",
      "Feature: 124, Score: 0.0096138\n",
      "Feature: 125, Score: 0.0050030\n",
      "Feature: 126, Score: 0.0239183\n",
      "Feature: 127, Score: -0.0029906\n",
      "Feature: 128, Score: 0.0046945\n",
      "Feature: 129, Score: 0.0044758\n",
      "Feature: 130, Score: 0.0070316\n",
      "Feature: 131, Score: -0.0200896\n",
      "Feature: 132, Score: 0.0037135\n",
      "Feature: 133, Score: 0.0015820\n",
      "Feature: 134, Score: 0.0047425\n",
      "Feature: 135, Score: 0.0012367\n",
      "Feature: 136, Score: -0.0030013\n",
      "Feature: 137, Score: 0.0089527\n",
      "Feature: 138, Score: -0.0050066\n",
      "Feature: 139, Score: 0.0050094\n",
      "Feature: 140, Score: 0.0077813\n",
      "Feature: 141, Score: -0.0011833\n",
      "Feature: 142, Score: 0.0002430\n",
      "Feature: 143, Score: -0.0043897\n",
      "Feature: 144, Score: 0.0006796\n",
      "Feature: 145, Score: -0.0051781\n",
      "Feature: 146, Score: 0.0141102\n",
      "Feature: 147, Score: 0.0054276\n",
      "Feature: 148, Score: 0.0015516\n",
      "Feature: 149, Score: 0.0003835\n",
      "Feature: 150, Score: 0.0103434\n",
      "Feature: 151, Score: 0.0002663\n",
      "Feature: 152, Score: 0.0019655\n",
      "Feature: 153, Score: -0.0027263\n",
      "Feature: 154, Score: 0.0024456\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# linear regression feature importance\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# get importance\n",
    "importance = lr_model.coef_\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.7f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodness of Fit of Model \tTrain Dataset\n",
      "Explained Variance (R^2) \t: 0.007987962712952212\n",
      "Mean Squared Error (MSE) \t: 0.04993419457001569\n",
      "\n",
      "Goodness of Fit of Model \tTest Dataset\n",
      "Explained Variance (R^2) \t: -0.00030117413425201356\n",
      "Mean Squared Error (MSE) \t: 0.04898125744625658\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_train_pred = lr_model.predict(X_train)\n",
    "y_test_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", lr_model.score(X_train, y_train))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_train, y_train_pred))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", lr_model.score(X_test, y_test))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_test, y_test_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_intelligence1</th>\n",
       "      <th>feature_intelligence2</th>\n",
       "      <th>feature_intelligence5</th>\n",
       "      <th>feature_intelligence7</th>\n",
       "      <th>feature_intelligence10</th>\n",
       "      <th>feature_charisma4</th>\n",
       "      <th>feature_charisma5</th>\n",
       "      <th>feature_charisma7</th>\n",
       "      <th>feature_charisma10</th>\n",
       "      <th>feature_charisma13</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_wisdom26</th>\n",
       "      <th>feature_wisdom29</th>\n",
       "      <th>feature_wisdom33</th>\n",
       "      <th>feature_wisdom34</th>\n",
       "      <th>feature_wisdom36</th>\n",
       "      <th>feature_wisdom37</th>\n",
       "      <th>feature_wisdom39</th>\n",
       "      <th>feature_wisdom41</th>\n",
       "      <th>feature_wisdom42</th>\n",
       "      <th>feature_wisdom44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_intelligence1  feature_intelligence2  feature_intelligence5  \\\n",
       "0                   1.00                    0.0                   0.25   \n",
       "1                   0.75                    0.5                   0.00   \n",
       "\n",
       "   feature_intelligence7  feature_intelligence10  feature_charisma4  \\\n",
       "0                   0.75                    0.50                1.0   \n",
       "1                   1.00                    0.25                0.5   \n",
       "\n",
       "   feature_charisma5  feature_charisma7  feature_charisma10  \\\n",
       "0               0.50                0.0                0.25   \n",
       "1               0.75                0.0                0.00   \n",
       "\n",
       "   feature_charisma13  ...  feature_wisdom26  feature_wisdom29  \\\n",
       "0                 0.5  ...              0.25              0.25   \n",
       "1                 0.5  ...              1.00              0.00   \n",
       "\n",
       "   feature_wisdom33  feature_wisdom34  feature_wisdom36  feature_wisdom37  \\\n",
       "0              0.25              0.50              0.75              0.75   \n",
       "1              0.75              0.25              1.00              0.75   \n",
       "\n",
       "   feature_wisdom39  feature_wisdom41  feature_wisdom42  feature_wisdom44  \n",
       "0              0.75               0.5               1.0              0.25  \n",
       "1              1.00               0.0               1.0              0.25  \n",
       "\n",
       "[2 rows x 91 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_remove = []\n",
    "\n",
    "for i,v in enumerate(importance):\n",
    "    if v <=0:\n",
    "        to_remove.append(i)\n",
    "\n",
    "X_remove = X_remove.drop([x for x in X_remove.columns[to_remove]],axis=1)\n",
    "X_remove.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 91)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_remove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.0084291\n",
      "Feature: 1, Score: -0.0153125\n",
      "Feature: 2, Score: 0.0053503\n",
      "Feature: 3, Score: 0.0057808\n",
      "Feature: 4, Score: 0.0106949\n",
      "Feature: 5, Score: 0.0036535\n",
      "Feature: 6, Score: 0.0049118\n",
      "Feature: 7, Score: 0.0030028\n",
      "Feature: 8, Score: 0.0093506\n",
      "Feature: 9, Score: 0.0104816\n",
      "Feature: 10, Score: 0.0074146\n",
      "Feature: 11, Score: 0.0031595\n",
      "Feature: 12, Score: -0.0007127\n",
      "Feature: 13, Score: 0.0049645\n",
      "Feature: 14, Score: 0.0012325\n",
      "Feature: 15, Score: 0.0014318\n",
      "Feature: 16, Score: -0.0063212\n",
      "Feature: 17, Score: 0.0034420\n",
      "Feature: 18, Score: 0.0013283\n",
      "Feature: 19, Score: 0.0122041\n",
      "Feature: 20, Score: -0.0026919\n",
      "Feature: 21, Score: 0.0023933\n",
      "Feature: 22, Score: 0.0090996\n",
      "Feature: 23, Score: 0.0056440\n",
      "Feature: 24, Score: -0.0033755\n",
      "Feature: 25, Score: 0.0067564\n",
      "Feature: 26, Score: 0.0019552\n",
      "Feature: 27, Score: -0.0010166\n",
      "Feature: 28, Score: 0.0024053\n",
      "Feature: 29, Score: -0.0005160\n",
      "Feature: 30, Score: 0.0032758\n",
      "Feature: 31, Score: 0.0047343\n",
      "Feature: 32, Score: 0.0012837\n",
      "Feature: 33, Score: 0.0019362\n",
      "Feature: 34, Score: 0.0115575\n",
      "Feature: 35, Score: 0.0064688\n",
      "Feature: 36, Score: -0.0004016\n",
      "Feature: 37, Score: 0.0126733\n",
      "Feature: 38, Score: 0.0043170\n",
      "Feature: 39, Score: 0.0034245\n",
      "Feature: 40, Score: 0.0020467\n",
      "Feature: 41, Score: 0.0071867\n",
      "Feature: 42, Score: -0.0026875\n",
      "Feature: 43, Score: -0.0004512\n",
      "Feature: 44, Score: -0.0138627\n",
      "Feature: 45, Score: -0.0036885\n",
      "Feature: 46, Score: -0.0002836\n",
      "Feature: 47, Score: 0.0067241\n",
      "Feature: 48, Score: 0.0040280\n",
      "Feature: 49, Score: 0.0005243\n",
      "Feature: 50, Score: 0.0006842\n",
      "Feature: 51, Score: -0.0021585\n",
      "Feature: 52, Score: -0.0039334\n",
      "Feature: 53, Score: -0.0004129\n",
      "Feature: 54, Score: -0.0032303\n",
      "Feature: 55, Score: 0.0114006\n",
      "Feature: 56, Score: 0.0008688\n",
      "Feature: 57, Score: 0.0066143\n",
      "Feature: 58, Score: 0.0014607\n",
      "Feature: 59, Score: 0.0001071\n",
      "Feature: 60, Score: 0.0036207\n",
      "Feature: 61, Score: -0.0021983\n",
      "Feature: 62, Score: 0.0025107\n",
      "Feature: 63, Score: 0.0022984\n",
      "Feature: 64, Score: -0.0101003\n",
      "Feature: 65, Score: 0.0109777\n",
      "Feature: 66, Score: -0.0002148\n",
      "Feature: 67, Score: -0.0013466\n",
      "Feature: 68, Score: 0.0121016\n",
      "Feature: 69, Score: 0.0081978\n",
      "Feature: 70, Score: 0.0073132\n",
      "Feature: 71, Score: 0.0047051\n",
      "Feature: 72, Score: -0.0064106\n",
      "Feature: 73, Score: -0.0115380\n",
      "Feature: 74, Score: 0.0059667\n",
      "Feature: 75, Score: -0.0048696\n",
      "Feature: 76, Score: -0.0114686\n",
      "Feature: 77, Score: -0.0067964\n",
      "Feature: 78, Score: 0.0034233\n",
      "Feature: 79, Score: 0.0063195\n",
      "Feature: 80, Score: 0.0033220\n",
      "Feature: 81, Score: -0.0008000\n",
      "Feature: 82, Score: 0.0056693\n",
      "Feature: 83, Score: 0.0093061\n",
      "Feature: 84, Score: 0.0094903\n",
      "Feature: 85, Score: 0.0054481\n",
      "Feature: 86, Score: 0.0048159\n",
      "Feature: 87, Score: 0.0053695\n",
      "Feature: 88, Score: -0.0004200\n",
      "Feature: 89, Score: 0.0015486\n",
      "Feature: 90, Score: 0.0058684\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Train test split for feature importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_remove,y,test_size=0.25,random_state=21)\n",
    "\n",
    "# linear regression feature importance\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# get importance\n",
    "importance = lr_model.coef_\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.7f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodness of Fit of Model \tTrain Dataset\n",
      "Explained Variance (R^2) \t: 0.005107807527517161\n",
      "Mean Squared Error (MSE) \t: 0.04966652248100393\n",
      "\n",
      "Goodness of Fit of Model \tTest Dataset\n",
      "Explained Variance (R^2) \t: -0.0008838552512260289\n",
      "Mean Squared Error (MSE) \t: 0.050278006837865284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_train_pred = lr_model.predict(X_train)\n",
    "y_test_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", lr_model.score(X_train, y_train))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_train, y_train_pred))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", lr_model.score(X_test, y_test))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_test, y_test_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.00262\n",
      "Feature: 1, Score: 0.00220\n",
      "Feature: 2, Score: 0.00294\n",
      "Feature: 3, Score: 0.00374\n",
      "Feature: 4, Score: 0.00290\n",
      "Feature: 5, Score: 0.00294\n",
      "Feature: 6, Score: 0.00290\n",
      "Feature: 7, Score: 0.00370\n",
      "Feature: 8, Score: 0.00263\n",
      "Feature: 9, Score: 0.00268\n",
      "Feature: 10, Score: 0.00285\n",
      "Feature: 11, Score: 0.00290\n",
      "Feature: 12, Score: 0.00308\n",
      "Feature: 13, Score: 0.00290\n",
      "Feature: 14, Score: 0.00298\n",
      "Feature: 15, Score: 0.00304\n",
      "Feature: 16, Score: 0.00415\n",
      "Feature: 17, Score: 0.00336\n",
      "Feature: 18, Score: 0.00305\n",
      "Feature: 19, Score: 0.00314\n",
      "Feature: 20, Score: 0.00312\n",
      "Feature: 21, Score: 0.00355\n",
      "Feature: 22, Score: 0.00301\n",
      "Feature: 23, Score: 0.00335\n",
      "Feature: 24, Score: 0.00334\n",
      "Feature: 25, Score: 0.00325\n",
      "Feature: 26, Score: 0.00266\n",
      "Feature: 27, Score: 0.00312\n",
      "Feature: 28, Score: 0.00277\n",
      "Feature: 29, Score: 0.00344\n",
      "Feature: 30, Score: 0.00305\n",
      "Feature: 31, Score: 0.00307\n",
      "Feature: 32, Score: 0.00355\n",
      "Feature: 33, Score: 0.00273\n",
      "Feature: 34, Score: 0.00342\n",
      "Feature: 35, Score: 0.00318\n",
      "Feature: 36, Score: 0.00262\n",
      "Feature: 37, Score: 0.00320\n",
      "Feature: 38, Score: 0.00206\n",
      "Feature: 39, Score: 0.00319\n",
      "Feature: 40, Score: 0.00328\n",
      "Feature: 41, Score: 0.00350\n",
      "Feature: 42, Score: 0.00307\n",
      "Feature: 43, Score: 0.00262\n",
      "Feature: 44, Score: 0.00345\n",
      "Feature: 45, Score: 0.00254\n",
      "Feature: 46, Score: 0.00380\n",
      "Feature: 47, Score: 0.00347\n",
      "Feature: 48, Score: 0.00328\n",
      "Feature: 49, Score: 0.00291\n",
      "Feature: 50, Score: 0.00294\n",
      "Feature: 51, Score: 0.00331\n",
      "Feature: 52, Score: 0.00307\n",
      "Feature: 53, Score: 0.00299\n",
      "Feature: 54, Score: 0.00274\n",
      "Feature: 55, Score: 0.00346\n",
      "Feature: 56, Score: 0.00305\n",
      "Feature: 57, Score: 0.00325\n",
      "Feature: 58, Score: 0.00294\n",
      "Feature: 59, Score: 0.00338\n",
      "Feature: 60, Score: 0.00280\n",
      "Feature: 61, Score: 0.00299\n",
      "Feature: 62, Score: 0.00365\n",
      "Feature: 63, Score: 0.00270\n",
      "Feature: 64, Score: 0.00287\n",
      "Feature: 65, Score: 0.00315\n",
      "Feature: 66, Score: 0.00277\n",
      "Feature: 67, Score: 0.00301\n",
      "Feature: 68, Score: 0.00344\n",
      "Feature: 69, Score: 0.00288\n",
      "Feature: 70, Score: 0.00281\n",
      "Feature: 71, Score: 0.00349\n",
      "Feature: 72, Score: 0.00318\n",
      "Feature: 73, Score: 0.00325\n",
      "Feature: 74, Score: 0.00309\n",
      "Feature: 75, Score: 0.00323\n",
      "Feature: 76, Score: 0.00294\n",
      "Feature: 77, Score: 0.00326\n",
      "Feature: 78, Score: 0.00334\n",
      "Feature: 79, Score: 0.00306\n",
      "Feature: 80, Score: 0.00302\n",
      "Feature: 81, Score: 0.00296\n",
      "Feature: 82, Score: 0.00305\n",
      "Feature: 83, Score: 0.00291\n",
      "Feature: 84, Score: 0.00383\n",
      "Feature: 85, Score: 0.00286\n",
      "Feature: 86, Score: 0.00252\n",
      "Feature: 87, Score: 0.00339\n",
      "Feature: 88, Score: 0.00260\n",
      "Feature: 89, Score: 0.00363\n",
      "Feature: 90, Score: 0.00258\n",
      "Feature: 91, Score: 0.00299\n",
      "Feature: 92, Score: 0.00328\n",
      "Feature: 93, Score: 0.00300\n",
      "Feature: 94, Score: 0.00340\n",
      "Feature: 95, Score: 0.00264\n",
      "Feature: 96, Score: 0.00278\n",
      "Feature: 97, Score: 0.00255\n",
      "Feature: 98, Score: 0.00328\n",
      "Feature: 99, Score: 0.00302\n",
      "Feature: 100, Score: 0.00389\n",
      "Feature: 101, Score: 0.00327\n",
      "Feature: 102, Score: 0.00336\n",
      "Feature: 103, Score: 0.00280\n",
      "Feature: 104, Score: 0.00327\n",
      "Feature: 105, Score: 0.00304\n",
      "Feature: 106, Score: 0.00291\n",
      "Feature: 107, Score: 0.00296\n",
      "Feature: 108, Score: 0.00315\n",
      "Feature: 109, Score: 0.00422\n",
      "Feature: 110, Score: 0.00299\n",
      "Feature: 111, Score: 0.00313\n",
      "Feature: 112, Score: 0.00322\n",
      "Feature: 113, Score: 0.00369\n",
      "Feature: 114, Score: 0.00321\n",
      "Feature: 115, Score: 0.00385\n",
      "Feature: 116, Score: 0.00337\n",
      "Feature: 117, Score: 0.00348\n",
      "Feature: 118, Score: 0.00296\n",
      "Feature: 119, Score: 0.00353\n",
      "Feature: 120, Score: 0.00309\n",
      "Feature: 121, Score: 0.00283\n",
      "Feature: 122, Score: 0.00334\n",
      "Feature: 123, Score: 0.00385\n",
      "Feature: 124, Score: 0.00373\n",
      "Feature: 125, Score: 0.00302\n",
      "Feature: 126, Score: 0.00321\n",
      "Feature: 127, Score: 0.00288\n",
      "Feature: 128, Score: 0.00272\n",
      "Feature: 129, Score: 0.00338\n",
      "Feature: 130, Score: 0.00340\n",
      "Feature: 131, Score: 0.00332\n",
      "Feature: 132, Score: 0.00379\n",
      "Feature: 133, Score: 0.00344\n",
      "Feature: 134, Score: 0.00313\n",
      "Feature: 135, Score: 0.00332\n",
      "Feature: 136, Score: 0.00304\n",
      "Feature: 137, Score: 0.00277\n",
      "Feature: 138, Score: 0.00324\n",
      "Feature: 139, Score: 0.00381\n",
      "Feature: 140, Score: 0.00364\n",
      "Feature: 141, Score: 0.00311\n",
      "Feature: 142, Score: 0.00341\n",
      "Feature: 143, Score: 0.00311\n",
      "Feature: 144, Score: 0.00313\n",
      "Feature: 145, Score: 0.00262\n",
      "Feature: 146, Score: 0.00298\n",
      "Feature: 147, Score: 0.00340\n",
      "Feature: 148, Score: 0.00323\n",
      "Feature: 149, Score: 0.00291\n",
      "Feature: 150, Score: 0.00338\n",
      "Feature: 151, Score: 0.00329\n",
      "Feature: 152, Score: 0.00312\n",
      "Feature: 153, Score: 0.00333\n",
      "Feature: 154, Score: 0.00404\n",
      "Feature: 155, Score: 0.00302\n",
      "Feature: 156, Score: 0.00343\n",
      "Feature: 157, Score: 0.00377\n",
      "Feature: 158, Score: 0.00359\n",
      "Feature: 159, Score: 0.00332\n",
      "Feature: 160, Score: 0.00287\n",
      "Feature: 161, Score: 0.00284\n",
      "Feature: 162, Score: 0.00358\n",
      "Feature: 163, Score: 0.00300\n",
      "Feature: 164, Score: 0.00311\n",
      "Feature: 165, Score: 0.00333\n",
      "Feature: 166, Score: 0.00288\n",
      "Feature: 167, Score: 0.00284\n",
      "Feature: 168, Score: 0.00349\n",
      "Feature: 169, Score: 0.00304\n",
      "Feature: 170, Score: 0.00334\n",
      "Feature: 171, Score: 0.00385\n",
      "Feature: 172, Score: 0.00270\n",
      "Feature: 173, Score: 0.00275\n",
      "Feature: 174, Score: 0.00332\n",
      "Feature: 175, Score: 0.00357\n",
      "Feature: 176, Score: 0.00343\n",
      "Feature: 177, Score: 0.00290\n",
      "Feature: 178, Score: 0.00346\n",
      "Feature: 179, Score: 0.00368\n",
      "Feature: 180, Score: 0.00337\n",
      "Feature: 181, Score: 0.00323\n",
      "Feature: 182, Score: 0.00364\n",
      "Feature: 183, Score: 0.00277\n",
      "Feature: 184, Score: 0.00300\n",
      "Feature: 185, Score: 0.00352\n",
      "Feature: 186, Score: 0.00283\n",
      "Feature: 187, Score: 0.00282\n",
      "Feature: 188, Score: 0.00330\n",
      "Feature: 189, Score: 0.00304\n",
      "Feature: 190, Score: 0.00336\n",
      "Feature: 191, Score: 0.00371\n",
      "Feature: 192, Score: 0.00319\n",
      "Feature: 193, Score: 0.00350\n",
      "Feature: 194, Score: 0.00396\n",
      "Feature: 195, Score: 0.00366\n",
      "Feature: 196, Score: 0.00305\n",
      "Feature: 197, Score: 0.00317\n",
      "Feature: 198, Score: 0.00432\n",
      "Feature: 199, Score: 0.00284\n",
      "Feature: 200, Score: 0.00306\n",
      "Feature: 201, Score: 0.00246\n",
      "Feature: 202, Score: 0.00347\n",
      "Feature: 203, Score: 0.00378\n",
      "Feature: 204, Score: 0.00375\n",
      "Feature: 205, Score: 0.00295\n",
      "Feature: 206, Score: 0.00298\n",
      "Feature: 207, Score: 0.00314\n",
      "Feature: 208, Score: 0.00295\n",
      "Feature: 209, Score: 0.00386\n",
      "Feature: 210, Score: 0.00372\n",
      "Feature: 211, Score: 0.00313\n",
      "Feature: 212, Score: 0.00328\n",
      "Feature: 213, Score: 0.00325\n",
      "Feature: 214, Score: 0.00295\n",
      "Feature: 215, Score: 0.00360\n",
      "Feature: 216, Score: 0.00347\n",
      "Feature: 217, Score: 0.00412\n",
      "Feature: 218, Score: 0.00335\n",
      "Feature: 219, Score: 0.00233\n",
      "Feature: 220, Score: 0.00317\n",
      "Feature: 221, Score: 0.00275\n",
      "Feature: 222, Score: 0.00354\n",
      "Feature: 223, Score: 0.00334\n",
      "Feature: 224, Score: 0.00238\n",
      "Feature: 225, Score: 0.00394\n",
      "Feature: 226, Score: 0.00323\n",
      "Feature: 227, Score: 0.00358\n",
      "Feature: 228, Score: 0.00308\n",
      "Feature: 229, Score: 0.00414\n",
      "Feature: 230, Score: 0.00366\n",
      "Feature: 231, Score: 0.00354\n",
      "Feature: 232, Score: 0.00353\n",
      "Feature: 233, Score: 0.00379\n",
      "Feature: 234, Score: 0.00406\n",
      "Feature: 235, Score: 0.00291\n",
      "Feature: 236, Score: 0.00326\n",
      "Feature: 237, Score: 0.00345\n",
      "Feature: 238, Score: 0.00279\n",
      "Feature: 239, Score: 0.00439\n",
      "Feature: 240, Score: 0.00324\n",
      "Feature: 241, Score: 0.00371\n",
      "Feature: 242, Score: 0.00324\n",
      "Feature: 243, Score: 0.00357\n",
      "Feature: 244, Score: 0.00287\n",
      "Feature: 245, Score: 0.00330\n",
      "Feature: 246, Score: 0.00335\n",
      "Feature: 247, Score: 0.00317\n",
      "Feature: 248, Score: 0.00334\n",
      "Feature: 249, Score: 0.00316\n",
      "Feature: 250, Score: 0.00256\n",
      "Feature: 251, Score: 0.00375\n",
      "Feature: 252, Score: 0.00290\n",
      "Feature: 253, Score: 0.00310\n",
      "Feature: 254, Score: 0.00331\n",
      "Feature: 255, Score: 0.00303\n",
      "Feature: 256, Score: 0.00322\n",
      "Feature: 257, Score: 0.00383\n",
      "Feature: 258, Score: 0.00299\n",
      "Feature: 259, Score: 0.00339\n",
      "Feature: 260, Score: 0.00289\n",
      "Feature: 261, Score: 0.00306\n",
      "Feature: 262, Score: 0.00323\n",
      "Feature: 263, Score: 0.00365\n",
      "Feature: 264, Score: 0.00374\n",
      "Feature: 265, Score: 0.00279\n",
      "Feature: 266, Score: 0.00324\n",
      "Feature: 267, Score: 0.00330\n",
      "Feature: 268, Score: 0.00282\n",
      "Feature: 269, Score: 0.00294\n",
      "Feature: 270, Score: 0.00358\n",
      "Feature: 271, Score: 0.00289\n",
      "Feature: 272, Score: 0.00348\n",
      "Feature: 273, Score: 0.00370\n",
      "Feature: 274, Score: 0.00356\n",
      "Feature: 275, Score: 0.00303\n",
      "Feature: 276, Score: 0.00363\n",
      "Feature: 277, Score: 0.00321\n",
      "Feature: 278, Score: 0.00411\n",
      "Feature: 279, Score: 0.00319\n",
      "Feature: 280, Score: 0.00358\n",
      "Feature: 281, Score: 0.00397\n",
      "Feature: 282, Score: 0.00351\n",
      "Feature: 283, Score: 0.00332\n",
      "Feature: 284, Score: 0.00294\n",
      "Feature: 285, Score: 0.00343\n",
      "Feature: 286, Score: 0.00304\n",
      "Feature: 287, Score: 0.00347\n",
      "Feature: 288, Score: 0.00357\n",
      "Feature: 289, Score: 0.00309\n",
      "Feature: 290, Score: 0.00301\n",
      "Feature: 291, Score: 0.00327\n",
      "Feature: 292, Score: 0.00376\n",
      "Feature: 293, Score: 0.00363\n",
      "Feature: 294, Score: 0.00325\n",
      "Feature: 295, Score: 0.00442\n",
      "Feature: 296, Score: 0.00318\n",
      "Feature: 297, Score: 0.00279\n",
      "Feature: 298, Score: 0.00289\n",
      "Feature: 299, Score: 0.00300\n",
      "Feature: 300, Score: 0.00365\n",
      "Feature: 301, Score: 0.00302\n",
      "Feature: 302, Score: 0.00379\n",
      "Feature: 303, Score: 0.00314\n",
      "Feature: 304, Score: 0.00307\n",
      "Feature: 305, Score: 0.00291\n",
      "Feature: 306, Score: 0.00337\n",
      "Feature: 307, Score: 0.00345\n",
      "Feature: 308, Score: 0.00332\n",
      "Feature: 309, Score: 0.00256\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.10363882810193803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MIKE\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MIKE\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.005423385892145749\n"
     ]
    }
   ],
   "source": [
    "#Train test split for feature importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=21)\n",
    "\n",
    "# linear regression feature importance\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xg_model = XGBRegressor(max_depth=5, learning_rate=0.01, \\\n",
    "                     n_estimators=2000, colsample_bytree=0.1)\n",
    "xg_model.fit(X_train, y_train)\n",
    "\n",
    "print(xg_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
